--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/Basics.html ---
TITLE: DistributedSystemModels/Basics.html

DistributedSystemModels/Basics.html Distributed Algorithms Contents Index A Model of Distributed Systems This page describes a simple model and notation for distributed algorithms.    The model is adequate for describing a collection of algorithms.    Other models are introduced later. Introduction Distributed systems are complex.    A banking information system supports actions in ATM machines, branch offices, and fraud analysis centers.    An earthquake monitoring system has thousands of sensors and agents carrying out complex calculations. A model of a distributed system is an abstraction that ignores some features.    The choice of a model is an engineering decision: We work with a model that is adequate to solve our problem.    Different models are used to design algorithms in different settings;    for example, a model of a system in which messages may be corrupted is different from one in which messages are incorruptible. We begin with a simple actor model and notation .    The model and its mathematical properties are critical for describing and proving the correctness of algorithms; the programming notation is not important but is necessary to provide examples. Examples of some distributed algorithms are given in Python using a simulator and using software libraries such as a Python implementation of the Advanced Message Queuing Protocol (AMQP). A Simple Model: A Network of Agents and Channels A distributed system consists of a set of agents and a set of channels.    A channel is directed from exactly one agent to exactly one agent. The ordered pair (P, Q) represents the channel directed from P to Q .    A channel (P, Q) is called an output of P and an input of Q .    An agent can send messages on its output channels and receive messages on its input channels.    The sender and receiver of a channel (P, Q) are P and Q , respectively. The system has a channel (P, Q) for all agents P , Q of the system.    There is a channel from each agent to itself    So, if there are \(N\) agents then there are \(N^{2}\) channels.    An agent can send messages to any agent including itself.    In almost all algorithms described in this course very few of the \(N^{2}\) channels are used. A distributed system is initiated with sets of agents and channels that remain unchanged.    Agents and channels are not created or deleted during a computation. Message Communication: Channels The state of a channel is a queue consisting of the sequence of messages in the channel -- these are the messages that have been sent on the channel and that have not been received. An agent sends a message by appending the message to the tail (rear) of the queue.    A message from a nonempty queue is delivered to an agent by removing the message from the head (front) of the queue, and calling a function of the agent. Messages are not lost or modified in channels. Every message sent is received. Message delays are arbitrary. Channels have the following properties: Messages are delivered in the order sent. For all \(n\), the \(n\)-th message received on a channel is the \(n\)-th message sent on the channel. A message is received only after it is sent. The \(n\)-th message is received on a channel only after the \(n\)-th message is sent on the channel. There is no limit to the size of the queue of messages in a channel.    An agent can append a message to a channel independent of the size of the channel. Messages Sent on Different Channels may be Delivered out of Order Messages sent on the same channel are delivered in the order sent. Messages sent on different channels may not be delivered in the order sent. The following scenario is possible. An agent \(A\) sends message \(m_{1}\) to an agent \(C\). Later, an agent \(B\) (different from \(A\)) sends message \(m_{2}\) to an agent \(C\). Agent \(C\) receives \(m_{2}\) from \(B\) before \(C\) receives \(m_{1}\) from \(A\). Agents An agent is an object that sends and receives messages.    An agent is either waiting to receive a message or is processing a message that it has received.    An agent that is waiting starts processing a message when the agent receives a message.    An agent that is processing a message transitions to the waiting state when the agent finishes processing the message. Each agent has a set of variables.    An agent's variables are local to the agent -- they cannot be accessed by other agents.    The state of an agent is specified by the values of its variables. An agent is specified by (1) a program that initializes the agent's variables and (2) a function receive(message, sender) called a callback function in message queuing libraries. If a waiting agent u has a nonempty input channel then the system selects any nonempty channel (v, u) , removes the message m at the head of the channel from the channel, and calls the receive(message, sender) function of u where message is m and sender is v . A receive function must not be recursive: an agent cannot receive a new message while it is executing a receive on a previous message.    Every execution of receive must terminate. An agent may have many nonempty input channels but the agent processes only one message at a time. An agent is not interrupted while it is executing a receive . Messages that arrive while an agent is executing a receive remain in channels. After an agent completes execution of a receive the agent returns to waiting state. An agent may send messages in its receive function. An agent sends a message by executing send(message, receiver) The first parameter of send is the message that is sent, and the second paramenter is the agent to which the message is sent.    Execution of this statement places the message in the output channel directed from the sender to the receiver. See examples and see examples of code The remainder of this page consists of an example. Examples Example of a System A system consists of 4 agents, pos , neg , total , and X , and the channels between them. See "Figure Agents and Channels."    In this example, only 5 of the 16 channels are used.    The channels that are used are (pos, pos) , (neg, neg) , (pos, total) , (neg, total) , and (total, X) . The flow of messages is shown by a directed graph in which vertices represent agents and the directed edges represent the channels that are used. Figure Agents and Channels The system is started by specifying agents and initial channel states and then starting the system.    In this example there is a message "wakeup" in the channel from pos to itself and from neg to itself.    All other channels are empty. Example of an Agent This is an example of an agent, total , that receives messages from agents pos and neg , and sends messages to agent X .    See an example of an implementation in Python using an Agent class. The example below does not use classes so that the algorithm is easier to understand by readers who are not familiar with Python. The statements before the receive function specify the initial values of variables.    In this example, the initial state of total is given by sum = 0 . # Initialization sum = 0    # Callback function def receive(message, sender): if sender == pos: sum = sum + message else: sum = sum - message if sum < 0: sum = 0 send(sum, X) If the agent receives a message from agent pos then the agent increments sum by the contents of the message.    If the agent receives a message from neg the agent decrements sum by the contents of the message, and if the resulting value of sum is negative then sum is set to 0. The agent sends the resulting value of sum to the agent X . Example of an Agent This agent sends my_data[n] to agent total for each element in my_data . # Initial values of agent's variables. my_data = [3, 5] n = 0    # Callback function def receive(message, sender): send(message=my_data[n], receiver=total) n = n + 1 if n < len(my_data): send(message="wakeup", receiver=pos) The agent has variables my_data and n which are initially [3, 5] and 0 , respectively. When pos receives a message it sends my_data[n] to the agent total and then increments n .    If n is less than the number of elements in my_data then pos sends itself a wakeup message. The system is initialized with a message in the channel from pos to itself.    When pos receives the message it sends my_data[0] to agent total , increments n to 1 and pos sends a message to itself, and When pos receives the next message it sends my_data[1] to agent total , increments n to 2 and then waits. So pos sends 3 and then 5 to total and then pos waits forever. Agent neg is identical to pos except that it may have different values of my_data . Agent X has no variables. It merely prints messages that it receives. Next The next page defines states of a distributed system. Examples Examples: Code Frequenty Asked Questions Review material for this page K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/BasicsExamples.html ---
TITLE: DistributedSystemModels/BasicsEExamples.html

DistributedSystemModels/BasicsEExamples.html Distributed Algorithms Contents Index Basics: Examples Please look at the Python examples that use the Agent class in addition to the examples below. Basics: Examples Movies 10-second MP4 movie : Messages sent in different channels may be delivered out of order. Channels 1 A system has agents \(A\), \(B\), and \(C\).    Initially the channel from \(A\) to \(A\) contains a "wakeup" message.    All other channels are empty. Ignore the states of agents for the purposes of this question. Question Is the following scenario possible? Agent \(A\) receives a wakeup message and sends a message \(m_{1}\) to \(C\) and a wakeup to itself. Agent \(A\) receives a wakeup message and sends a message \(m_{2}\) to \(B\). Agent \(B\) receives \(m_{1}\) from \(A\) and sends a message \(m_{3}\) to \(C\). Agent \(C\) receives \(m_{3}\) from \(B\). Agent \(C\) receives \(m_{2}\) from \(A\). Answer Yes, the scenario is possible.    Messages sent on a channel are delivered in the order sent on that channel.    Messages sent on different channels may not be received in the order sent on those channels. Channels 2 A system has agents \(A\) and \(B\).    Initially the channel from \(A\) to \(A\) contains a "wakeup" message.    All other channels are empty. Ignore the states of agents for the purposes of this question. Question Is the following scenario possible? Agent \(A\) receives a wakeup message and sends a message \(m_{1}\) to \(B\) and a wakeup to itself. Agent \(A\) receives a wakeup message and sends a message \(m_{2}\) to \(B\) and a wakeup to itself. Agent \(B\) receives  \(m_{2}\) from \(A\) Agent \(B\) receives  \(m_{1}\) from \(A\) Answer No, the scenario is not possible.    Messages sent on a channel are delivered in the order sent on that channel.    So \(A\) receives \(m_{1}\) from \(B\) before it receives \(m_{2}\) from \(B\). Example of a System Consider the example given in the previous page. Assume that agent neg is the same as agent pos except that neg.my_data = [2, 4] At some point message 3 is in channel (pos, total) and message 2 is in channel (neg, total) , and these are the only messages in these channels.    There is a wakeup message in channel (pos, pos) and in channel (neg, neg) . See Figure Agents and Channels Example 1.1 Figure Agents and Channels Example 1.1 Question What changes occur if agent total receives the message from pos and this is the first message that total receives? Answer The message 3 on channel (pos, total) is removed from the channel. Agent total 's variable sum becomes 3 and channel (total, X) contains message 3. See Figure Agents and Channels Example 1.2 Figure Agents and Channels Example 1.2 Question Same initial state as in the previous question.    What changes occur if agent total receives the message from neg and this is the first message that total receives? Answer The message 2 on channel (neg, total) is removed from the channel. Agent total 's variable sum becomes 0 and channel (total, X) contains message 0. See Figure Agents and Channels Example 1.3 Figure Agents and Channels Example 1.3 Question Same starting state as in the previous two questions.    What changes occur if agent total receives the message from pos and then from neg ? Answer After agent total receives the message from pos and then from neg the channels from pos and neg to total are empty, and the channel from total to X contains message 3 followed by message 1, and agent total 's variable sum is 1. See Figure Agents and Channels Example 1.4 Figure Agents and Channels Example 1.4 Question What changes occur if agent total receives its first message from neg and its second from pos ? Answer After agent total receives the message from neg and then from pos the channels from pos and neg to total are empty, and the channel from total to X contains message 0 followed by message 3, and agent total 's variable, sum , is 3. See Figure Agents and Channels Example 1.5 Figure Agents and Channels Example 1.5 Question Agent X prints the messages that it receives. What does X print? Answer X may print 3, 8, 6, 2. If total receives 3, 5 from pos and then receives 2, 4 from neg . 3, 1, 6, 2. If total receives 3 from pos , then 2 from neg , then 5 from pos , then 4 from neg 3, 1, 0, 5. If total receives 3 from pos , then 2 from neg , then 4 from neg , then 5 from pos . 0, 3, 8, 4. If total receives 2 from neg , then 3 from pos , then 5 from pos , then 4 from neg . 0, 3, 0, 5. If total receives 2 from neg , then 3 from pos , then 4 from neg , then 5 from pos . 0, 0, 3, 8. If total receives 2 from neg , then 4 from neg , then 3 from pos , then 5 from pos . Next The next page defines states of a distributed system. Examples Frequenty Asked Questions Review material for this page K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/BasicsFAQ.html ---
TITLE: DistributedSystemModels/BasicsFAQ.html

DistributedSystemModels/BasicsFAQ.html Distributed Algorithms Contents Index Basics: FAQ What is a model? A model of a system is an abstraction that ignores aspects of the system but which helps in developing algorithms. What model does this course use? The choice of a model is an engineering decision, and we use different models to solve different problems.    We begin with a simple actor model. What are weaknesses and limitations of the model? The model has many weaknesses, only some of which are described here. Model Limitations: Fairness and Progress In the model, a computation progresses by delivering a message on any channel.    This allows for infinite computations in which some messages remain in a channel forever. Consider an example of two agents sending tokens to each other.    Each agent sends a token that it holds to the other agent.    So there is a computation in which tokens go back and forth between the agents forever.    Let's call this distributed system D . Now, consider a system consisting of two identical, and totally independent, copies of D .    There is no connection between the two copies.    Surely, the behavior of D shouldn't change because of the presence of a completely independent network of agents.    But, with our model, it does. A computation progresses by delivering a message from any nonempty channel.    So, there is an infinite computation in which messages are delivered in channels in one copy of D , and no messages are delivered from nonempty channels in the other copy The problem is that the selection of the nonempty channel in each iteration of the while loop may be unfair -- the same set of channels could be selected forever while other nonempty channels are never selected.    The model has no provision for ensuring that a message in a channel will be delivered eventually.    We will introduce fair selection, eventuality , and temporal logic later in the course. Model Limitations: No Construct for Time The only representation of time in our model is that some events occur after others.    An event in which a message is received occurs after an event in which that message is sent.    Time plays a critical role in the performance of algorithms even though we never use time in proving the correctness of algorithms. There are many algorithms in which an agent sends itself a Timeout(T) message where ideally the message would be received approximately T seconds after it is sent.    Though we never use T in proving the correctness of algorithms we will use timeout messages in analyzing their performance. Agents can maintain accurate clocks by using atomic clocks, Precision Time Protocols (PTP) in local area networks, and Network Time Protocol (NTP) servers.    Accurate clocks have the property that the time at which an event is sent, as determined by the sender's clock, is (almost always) earlier than the time of the event in which the message is received.    We do not, however, rule out the possibility that clocks drift apart so that the sender's clock is far ahead of the receiver's. Some algorithms for systems with perfect clocks are simpler than those with imperfect clocks, as we shall see. Model Limitations: Start Up, Shutdown, Failure The model assumes that all agents and channels are initialized and then agents start receiving messages.    The model has a barrier between the point at which initialization takes place and the point at which messages are delivered.    The barrier isn't necessary in most algorithms, though it assuming its existence helps us to focus on more important parts of the algorithm. The model does not specify how termination is detected if the computation does terminate.    Nor does the notation have primitives for shutting down agents and channels gracefully so that they don't continue to hold resources after computation has terminated.    Protocols such as AMQP do have primitives for starting up and shutting down distributed systems, but we won't discuss them here. We will describe algorithms that execute on faulty systems in which messages may be lost, duplicated, or delivered out of order, and where agents may stop forever or halt and restart.    We also describe algorithms with Byzantine agents.    These algorithms are based on models that are different from those given so far. Model Limitations: Discrete State Space The state space is discrete in most of the algorithms described here.    The state space of some distributed systems has both discrete and continuous components.    The state space of a fleet of drones has continuous components. Later, we study algorithms in which the state space is continuous.    Systems with continuous state spaces may have discrete or continuous state transitions. Model Limitations: Static The network of agents and messages in the model is static.    In contrast, distributed systems evolve; agents and channels may be added and deleted; agents may change; channel protocols may be modified. Model Limitations: Simple Channels The model only considers channels in which messages are delivered in the order sent.    Some distributed systems have channels in which messages may be duplicated and delivered out of order. Many models deal with channels in which senders are blocked when a channel gets full.    Our model has no concept of a channel being full. Model Limitations: Summary Models and notations in this course are not comprehensive -- they do not capture most aspects of distributed systems. We use a model that is appropriate for describing the algorithm at hand. The choice of a model is an engineering decision. Why use such a simplistic model? The model is indeed simplistic; however, it is adequate for describing and reasoning about many of the algorithms described in the first part of this course.    We introduce other models later.    We use the simplest model adequate for the problem at hand. How many channels are there in a system? In the model there is a channel from every agent to every agent.    So, if there are \(N\) agents there are \(N^{2}\) channels.    With a thousand agents there are a million channels.    That's a lot of channels! The model allows channels between every pair of agents.    In practice very few of these channels are used.    When we implement an algorithm using AMQP, for instance, we will declare channels. Can you describe channels in more detail? Our basic description of channels is found here. Channels in our model are asynchronous (non-blocking) and unidirectional.    A sender can send messages on a channel regardless of how many messages have been sent in the past and how many messages have been received on that channel.    The model assumes that the queue of messages in the channel has infinite capacity. A channel is unidirectional.    It is represented by a directed edge in a directed graph.    Messages can be sent by an agent P to an agent Q along a channel (P, Q) .    Agent Q cannot send a message to agent P along channel (P, Q) . A system may have a channel (P, Q) and may or may not have a channel (Q, P) .    Some systems have bidirectional channels but our model does not allow for bidirectional channels. In our model, a channel is directed from exactly one agent to exactly one agent.    In some systems, multiple agents can send messages on the same channel, and multiple agents can receive messages on the same channel.    Our model does not allow for such channels. Can an agent refuse to receive a message? In this model an agent cannot refuse to receive a message.    If a channel is not empty then a message from the channel can be delivered to the agent independent of the state of the agent . Suppose you want to design an algorithm in which an agent X refuses to receive messages from an agent Z until it first receives a message from an agent Y .    How would you use this model? In our model, agent X has to receive the message from Z in every state of X . Agent X can copy the message from Z into a local queue -- a local variable of X -- and process the message only after receiving the message from Y . Can a full channel block a sender from sending more messages? In the model a sender is never blocked from sending a message. Our model assumes that channels have unlimited capacity.    We can represent a situation in which channels have limited capacity in the following way.    An agent has a local output queue of unlimited size.    The agent puts messages into this queue when it cannot send messages on a channel because the channel is full.    Messages from this queue are sent on the channel when the channel stops being full. Can you represent systems in which agents are created and deleted in the model? The model doesn't have features that allow agents to be created and deleted. A work around for the case in which agents are created or deleted a finite number of times is as follows.    The network of agents in the model is made large enough to include agents that have not been created as yet and also include agents that have been deleted. An agent that has not been created is represented by an agent that is idle, i.e., one is waiting for a message. It never receives a message until the agent is created. The message is created by the operating system sending a "create" message to the agent and informing other agents that this agent has been created. An agent this is deleted is represented in the same way.    The operating system deletes an agent by sending a "delete" message to the agent.    A deleted agent discards messages that it receives without taking action. Can an agent process background jobs that are interrupted when messages arrive? No, there are no interruptions in the model.    When an agent is executing a receive it is not interrupted. There are systems in which messages have different priorities, and the arrival of high-priority messages interrupts the execution of low-priority messages.    Our model does not allow for interruptions. How do you represent channels that are not first in first out? We use queues to represent states of first in first out channels, and we use other data structures -- such as multisets -- to represent states of other types of channels. Later we describe algorithms with different types of channels.    For example, the state of a channel in which messages may overtake each other is a multiset or bag.    A message is sent on a channel by adding the message to the multiset.    A nonempty multiset may deliver any message in the mutliset to the receiving agent. Lossy channels, and channels in which messages have priorities, are also modeled by defining channel states appropriately. Can the model represent sequential composition of distributed computations? Yes. There are problems in which we would like to start a distributed computation P ; wait for P to finish, and then start another distributed computation Q .    We want a barrier between P and Q . A barrier can be implemented in several ways.    An agent, say a coordinator agent, sends messages to all agents to start P .    The coordinator then detects termination of P ; we discuss termination detection algorithms later.    After detecting termination of P the coordinator sends messages to all agents to start Q . Can the model represent agents that make state transitions without receiving messages? No, the model does not represent agents that make state transitions without receiving messages.    The effect of a state transition without receiving a message can be simulated by an agent sending itself a message and carrying out the transition when it receives a message from itself. For example, an agent that is computing using a set of files may transition to a state in which it no longer needs those files; this transition occurs without the agent receiving a message.    We model this event by having the agent send itself a message when it starts using the set of files, and it transits to a state in which it no longer needs the files when it receives the message from itself. Representing internal state changes in this way is an artifice; however, the artifice allows us to use a very simple model in which a state change occurs when, and only when, a message is delivered. What is an agent? In our model, an agent is an object that sends and receives messages. Some papers refer to an agent as an actor or as a process . What is a simple example of the notation? See an example of the notation . Local clocks can be synchronized using NTP and other protocols. Why do you assume that clocks aren't synchronized? Local clocks can, indeed, be synchronized very accurately; however, we do not assume that they are perfect. We use agents' local clocks for evaluating algorithm performance but not for proving correctness because even a small drift can cause race conditions. Consider an algorithm in which one agent carries out a computation starting at 1pm and another agent carries out a computation starting at 2pm.    When we prove the correctness of our algorithms, we allow for the unlikely possibility that that the agent starting its computation at 2pm does so before the agent that starts a 1pm.    For evaluating performance, however, we assume that the agent that starts a 1pm usually does so before the agent that starts at 2pm. What are other examples of models? The model we use is an actor model. For more general asynchronous models of concurrent systems see UNITY and TLA . Perhaps the most widely used model is CSP -- Communicating Sequential Processes . An overview of models used in parallel programming describes models used in shared-memory and distributed computing. Next States of a Distributed System. Review material for this page K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/BasicsReview.html ---
TITLE: DistributedSystemModels/BasicsReview.html

DistributedSystemModels/BasicsReview.html Distributed Algorithms Contents Index Basics: Review Answer these questions to review the webpage on Basics. A distributed system consists of a set of agents and a set of channels. What is an agent? Give an example. What is the state of an agent in the example? What is a channel? What is the state of a channel? When does the state of an agent change? Describe how the state of a channel changes. What are the restrictions on a receive function of an agent? The parameters of a receive function are the message that arrived and the sender of the message. Why is it helpful for the receiver to have information about the sender of the message? Next States of a Distributed System. Frequenty Asked Questions K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/BasicsStates.html ---
TITLE: DistributedSystemModels/BasicsStates.html

DistributedSystemModels/BasicsStates.html Distributed Algorithms Contents Index States of a Distributed System This page describes the state of a system and changes to a system state.    The model uses a simple abstraction of state and state transitions. States The state of a distributed system is given by the states of its agents and channels.    A system state is a tuple with an element of the tuple for each agent and each channel. The state of a channel is a queue consisting of the sequence of messages sent on the channel that have not been delivered.    The state of an agent is given by the values of its variables. State Transitions The state of a system changes when, and only when, a message is delivered to an agent. Execution of a receive is Atomic We ignore the changes in the state of an agent while it is executing a receive .    We only consider an agent's state before it starts, and after it completes, executing a receive .    We treat execution of a receive as an atomic operation. A state transition occurs when one agent gets one message on one of its input channels and executes its receive function on that message. Event: Specification of the Change in State during a State Transition The change in state that occurs when an agent u receives a message, msg , from an agent v is specified by the 4-tuple: u 's state s before it executes the receive . The sender, v , of the message, and the message, msg , that is received, u 's state s' after it completes execution of the receive . A list of ordered pairs (m, w) , where m is the message sent to agent w , during the execution of the receive . The 4-tuple is called an event. The first two elements of the tuple are called the inputs to the event , and the last two elements are the outputs of the event . The State Transition Caused by an Event The event specified by the above 4-tuple can be executed in a state S if the inputs to the event are as specified by S , i.e., in state S the state of u is s , and the message at the head of the channel (v, u) is msg . The occurrence of the event causes a transition to a state S' which is specified as follows. The state of u in S' is s' . The change in the states of u 's output channels are specified by the list in part 4 of the 4-tuple: message m is appended to the tail of the sequence of messages in channel (v, w) , for all (m, w) in the list. The states of other agents and channels are the same in S and S' . Each execution of an agent's receive function is specified by an event.    We say that an agent u "executes event e", or "event e occurs at agent u " to mean that the agent executes a receive that is specified by e . If multiple agents change state concurrently then we treat the state changes as occurring one at a time in any order. Events and State Transitions An event is a 4-tuple that specifies the change in state during a state transition.    An event provides no information about the agents and channels that do not change state in the state transition. An event is different from a state transition because a state transition specifies the states, before and after the transition, of all agents and channels, including the states of agents and channels that remain unchanged in the transition. For example, when an online customer deposits money into an account, the event describing the action specifies the amount in the account before and after the transition, the check that is deposited, and the acknowledgment that is sent.    The event does not describe the states of all the other accounts in the bank. Example of an Event This is an example of an event at agent, pos .    In this example, the state of pos before the event is given by the values of its variables my_data = [3, 5] and n = 0 .    In the event, pos receives a "wakeup" message from itself. pos 's state after the event is my_data = [3, 5] and n  = 1 .    During the event pos sends a "wakeup" message to itself and 3 to agent total .    The event is specified by the following tuple: pos 's state before it executes the receive is given by the values of its variables my_data = [3, 5] and n = 0 . The sender of the message that is received is pos , and the message is "wakeup". pos 's state after it completes execution of the receive is given by my_data = [3, 5] and n = 1 . The messages sent during the execution of receive are (i) "wakeup" to pos and  (ii) 3 to total . Next The next page discusses computations of distributed systems. Examples Frequenty Asked Questions K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/BasicsStatesExamples.html ---
TITLE: DistributedSystemModels/BasicsStatesExamples.html

DistributedSystemModels/BasicsStatesExamples.html Distributed Algorithms Contents Index States: Examples A Simple Example Two children, X and Y, are tossing balloons to each other.    A balloon that has been tossed by X, while in the air to Y, is a message in the channel (X, Y).    When a child gets a balloon it tosses the balloon back immediately.    Initially there is a balloon tossed by X on its way to Y and there is also a balloon tossed by Y on its way to X. Each child has a countdown of the number of times it tosses balloons.    Each time a child tosses a balloon it decrements its countdown value.    After a child's countdown reaches 0 the child pops balloons that it receives (and doesn't toss popped balloons).    Let nX and nY be the countdown values of X and Y, respectively. Figure State 1: Initial State Figure State 2. Y receives balloon. nY becomes 1 Figure State 3. X receives balloon. nX becomes 0 Figure State 4.  Y receives balloon. nY becomes 0 Figure State 5. X pops balloon. nX becomes 1 Figure State 6. X pops balloon. nX becomes 0 Question How is the state specified for this system? Answer The state of a channel is the number of balloons in it.    The states of agent X and Y are the countdown values nX and nY, respectively. For simplicity we will abuse notation and use (X, Y) to represent both the channel and the state of the channel, i.e., the number of messages in the channel.    So the state of the system is the tuple: [nX, nY, (X, Y), (Y, X)]. Algorithm for X # Initial State nX = 1    # Callback function def receive(message=m, sender=Y): if nX > 0: nX = nX - 1 send(message=m, receiver=Y) The algorithm for Y is identical except that initially nY = 2. Question A computation is specified as a sequence of states with a transition from each state to the next. What is the sequence of states corresponding to the diagrams: Figure State 1 to Figure State 6? Answer The sequence of states corresponding to the diagrams is as follows. Initial State : Channel (X, Y) has one balloon and channel (Y, X) has one balloon. And the countdown for X is 2 and the countdown for Y is 3. We represent this state by: nX = 1, nY = 2, (X, Y) = 1, (Y, X) = 1 The sequence of steps from the initial state are as follows. Y receives a balloon and sends it back. So the state becomes: nX = 1, nY = 1, (X, Y) = 0, (Y, X) = 2 X receives a balloon and  sends it back. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 1 Y receives a balloon and sends it back. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 2 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 1 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 0 There are no further steps in this computation. Question What is the event that causes the first state transition? This is the event in which Y receives a balloon for the first time. Answer Event: Y receives a balloon for the first time This event is specified by the 4-tuple: Y's state before the event is nY = 2 The message that is received is 1 (balloon) and the message is from X. Y's state after the event is nY = 1 The message that is sent in the event is 1 (balloon) and the message is to X. Question Specify the state transition caused by the event in which Y receives a balloon for the first time. Answer The execution of this event at Y causes a state transition from nX = 1, nY = 2, (X, Y) = 1, (Y, X) = 1 to nX = 1, nY = 1, (X, Y) = 0, (Y, X) = 2 Question In what states can the event in which Y receives the balloon for the first time be executed? Answer This event can be executed in any state S in which the inputs to the event are specified by the state, i.e., in S: Y's state in S is nY = 2 The channel (X, Y) has a message 1 at its head. Question Specify the event in which X receives a balloon for the first time. Answer This event is specified by the 4-tuple: X's state before the event is nX = 1 The message that is received is 1 (balloon) and the message is from Y. X's state after the event is nX = 0 The message that is sent in the event is 1 (balloon) and the message is to Y. Question What is the state transition caused by the event in which X receives a balloon for the first time? Answer The execution of this event at X causes a state transition from nX = 1, nY = 1, (X, Y) = 0, (Y, X) = 2 to nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 1 Example from Previous Pages Question about State Transitions What transitions are possible from the state shown in the following diagram from the example given earlier? Figure State S_0 There are four transitions possible corresponding to the four non-empty channels.    The transitions from state S_0 are to states S_1, S_2, S_3, S_4 shown below in Figure State S_1, Figure State S_2, Figure State S_3, and Figure State S_4, respectively.    They are shown in the following diagrams. Figure State S_1: event total receives 3 from pos Figure State S_2: event total receives 2 from neg Figure State S_3: event pos receives wakeup from pos Figure State S_4: event neg receives wakeup from neg Next Computations of a Distributed System. Review material for this page K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/BasicsStatesFAQ.html ---
TITLE: DistributedSystemModels/BasicsStatesFAQ.html

DistributedSystemModels/BasicsStatesFAQ.html Distributed Algorithms Contents Index States: FAQ Exactly what is a state? The future behavior of a system, given its state, is independent of the past behavior of the system.    A system may enter the same state by executing different behaviors, but the future behavior of a system, given its state, doesn't depend on what happened before the state was entered. See the definition of state in our model. See a comprehensive description of states in computer systems. When do state transitions occur? In our model, the state of a system changes when, and only when, a message is delivered to an agent. What is an event? Don't agents change states continuously? Yes, agent states may change continuously.    The complete state of an agent includes its program counter which points to the next statement to be executed by the agent.    Our model ignores continuous changes in state of an agent while it is executing a receive and restricts attention to the state of an agent when it is waiting. In our model, an agent is waiting for a message or processing a message that it received.    We only deal with the state of the agent after it has finished processing the message and is back in the waiting state.    The changes that occur while a receive is being executed are ignored by the model. What happens if an agent goes to sleep during a receive ? An example that helps to answer this question is as follows. def receive(message, sender): send ("hello", receiver_1) time.sleep(1000) send ("world", receiver_2) The agent sends a message "hello" to receiver_1 then sleeps for 1000 seconds and then sends a message to receiver_2 .    We may expect enough time to elapse between the messages to allow receiver_1 to send a message to receiver_2 before the "world" message gets to receiver_2 . Our model does not deal with time. It treats the execution of the receive as an atomic operation.    The effect of the following receive with the sleep removed is the same as the previous receive . def receive(message, sender): send ("hello", receiver_1) send ("world", receiver_2) Time is important in the behavior of distributed systems.    We don't use time in reasoning about the correctness of distributed systems because it's safer not to depend on clock accuracy. Can two agents receive messages at exactly the same time? Won't that result in a state transition in which two agents change state? If two agents receive messages at exactly the same time then the events at which the messages are received are independent and so they can be executed in arbitrary order. Suppose agent \(v\) receives a message \(m\) from agent \(u\) at exactly the same time that \(u\) receives a message \(m'\) from \(v\).    Then before the steps, the channel from \(v\) to \(u\) contained message \(m\) and the channel from \(u\) to \(v\) contained message \(m'\). If \(u\) receives \(m'\) first it makes no difference to \(m\) being at the head of the channel from \(v\) to \(u\). So, the order in which the steps occur is irrelevant. Many agents are changing state and sending and receiving messages concurrently.    We ignore these concurrent changes and restrict attention state changes in which one agent receives one message.    We can analyze systems with concurrent changes using our simple model. Can an agent receive multiple messages in a single state transition? Can an agent send multiple messages to another agent in a single state transition? Our model only allows one message to be received in a state transition and one message to be sent to an agent in the transition. Extending the model to allow a sequence of messages to be sent to an agent in a single transition isn't necessary for the algorithms that we discuss; however, extending the model to do so is straightforward and you should try to do so. The model does not fully capture reality.    A model is an engineering choice. It is an abstraction of reality that helps us develop algorithms. Next States of a Distributed System. Review material for this page K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/BasicsStatesReview.html ---
TITLE: DistributedSystemModels/BasicsStatesReview.html

DistributedSystemModels/BasicsStatesReview.html Distributed Algorithms Contents Index States: Review Answer these questions to review the webpage on States. A distributed system consists of a set of agents and a set of channels. What is the state of a distributed system? When does the state of a distributed system change? Consider an example in which an agent sleeps for some time when it processes a message. Does the amount of time that the agent sleeps change the state transitions of the system? When does the state of an agent change? Describe how the state of a channel changes. What are the restrictions on a receive function of an agent? The parameters of a receive function are the message that arrived and the sender of the message. Why is it helpful for the receiver to have information about the sender of the message? Next States of a Distributed System. Frequenty Asked Questions K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/Computations.html ---
TITLE: DistributedSystemModels/Computations.html

DistributedSystemModels/Computations.html Distributed Algorithms Contents Index Computations A computation of a system is a sequence of states of the system where there exists an event of the system that causes a transition from each state in the sequence to the next.    We use techniques for proving sequential programs to prove properties of computations. Definition A computation is a sequence of states, where there exists an event that causes a transition from each state in the sequence to the next. A computation may be finite or infinite.    A computation may start in any state.    We will often prove properties of computations that start in an initial state of the system; however, a computation is not restricted to starting in an initial system state. A computation \([S_{0}, S_{1}, S_{2}, \ldots]\) can also be specified by the initial state, \(S_{0}\), of the computation and a sequence of events \([e_{0}, e_{1}, \ldots, ]\) where execution of \(e_{i}\) causes a transition from \(S_{i}\)  to \(S_{i+1}\). A step of the computation is an execution of a single event in this sequence.    The same event can occur multiple times in a computation.    Each occurrence of an event is a separate step of the computation. A Sequential Programming Representation of Computations Consider a sequential program consisting of an initialization and the following while loop. n = 0 S[n] is an initial state    while there exists an event that can be executed: # state is S[n] execute any executable event n = n + 1 The loop terminates when there are no executable events.    The selection of which event to execute in an iteration is nondeterministic -- any executable event can be selected. States in the Loop and in a Computation The sequence of states S[0], S[1], S[2], ...S[k] that occur in the loop, for any k \(\geq\) 0, is a computation.    The n -th iteration of the loop is the n -th step in the computation, and this step causes a transition from state S[n] to state S[n+1] , for n \(\geq\) 0. Properties of Loops and Distributed Systems A benefit of using the states in a while loop to represent the states of a computation is that we can use familiar techniques --- loop invariant and loop variants --- for reasoning about loops in sequential programming to reason about distributed algorithms too.    See Effective Theories in Programming Practice for examples of these techniques Next The next webpage discusses data flow in computations . Examples Frequenty Asked Questions K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/ComputationsExamples.html ---
TITLE: DistributedSystemModels/ComputationsExamples.html

DistributedSystemModels/ComputationsExamples.html Distributed Algorithms Contents Index Computation: Examples Examples of computations: Simple examples of balloons tossed between two children. Example from previous pages. Examples of invariants, loop variants, and termination condition: Balloon example. Distributed Greatest Common Divisor. A Simple Example: Tossing Balloons  (continued) This example is a continuation from the example in States .    Two children, X and Y, are tossing balloons to each other.    A balloon that has been tossed by X, while in the air to Y, is a message in the channel (X, Y\).    When a child gets a balloon it tosses the balloon back immediately.    Initially there is a balloon tossed by X on its way to Y and there is also a balloon tossed by Y on its way to X. Each child has a countdown of the number of times it tosses balloons.    Each time a child tosses a balloon it decrements its countdown value.    After a child's countdown reaches 0 the child pops balloons that it receives (and doesn't toss popped balloons). Question How is a state of this system specified? Answer The state of a channel is the number of balloons in it.    The state of an agent (X or Y) is the countdown value nX or nY, respectively.    The state of the system is given by the states of its agents and channels. Question What is an example of a computation of the system? Answer An example of a computation is shown in the diagrams below where the computation is State 1 to State 2 to .. State 6. A Computation shown as a Sequence of Diagrams Figure State 1: Initial State Figure State 2. Y receives balloon. nY becomes 1 Figure State 3. X receives balloon. nX becomes 0 Figure State 4.  Y receives balloon. nY becomes 0 Figure State 5. X pops balloon. nX becomes 1 Figure State 6. X pops balloon. nX becomes 0 Question Specify the computation which is shown above as a sequence of diagrams as a sequence of states. Answer The sequence of states, shown below, is the computation shown in the diagrams above. You can verify that there exists a transition from each state in the sequence to the next. Also see that each transition is caused by exactly one agent receiving exactly one message on one of the agent's input channels. Initial State : Channel (X, Y) has one balloon and channel (Y, X) has one balloon. And the countdown for X is 2 and the countdown for Y is 3. We represent this state by: nX = 1, nY = 2, (X, Y) = 1, (Y, X) = 1 The sequence of steps from the initial state are as follows. Y receives a balloon and sends it back. So the state becomes: nX = 1, nY = 1, (X, Y) = 0, (Y, X) = 2 X receives a balloon and  sends it back. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 1 Y receives a balloon and sends it back. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 2 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 1 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 0 There are no further steps in this computation. Question What are other transitions from the initial state of the computation? Answer Let's look at the event in step 2 of the above computation. The event is as follows. Event: X receives a balloon for the first time This event is specified by the 4-tuple: X's state before the event is nX = 1 The message that is received is 1 (balloon) and the message is from Y. X's state after the event is nX = 0 The message that is sent in the event is 1 (balloon) and the message is to Y. This event can be executed in any state S which satisfies the inputs to this event: X's state before the event is nX = 1 The message at the head of channel (Y, X) is 1. So, this event can be executed in the initial state. The execution of this event causes a transition from the initial state to a state shown in the following diagram: Figure Another Transition from the Initial State Question Can you give examples of other computations starting in the same state? Answer Initial State : Channel (X, Y) has one balloon and channel (Y, X) has one balloon. And the countdown for X is 2 and the countdown for Y is 3. We represent this state by: nX = 1, nY = 2, (X, Y) = 1, (Y, X) = 1 X receives a balloon and sends it back. So the state becomes: nX = 0, nY = 2, (X, Y) = 2, (Y, X) = 0 Y receives a balloon and  sends it back. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 1 X receives a balloon and pops it. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 0 Y receives a balloon sends it back. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 1 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 0 There are no further steps in this computation. Some states (e.g. State 2) in the first example of a computation don't occur in the second example, and vice versa. A Computation of the System from Previous Pages Question What is an example of a computation, starting from the initial state, of the example ? Answer The following sequence of diagrams shows a computation of the example. Each diagram shows a state of the system. There is a transition from state S_k to state S_(k+1) Figure State S_0: Initial State Figure State S_1 Figure State S_2 Figure State S_3 Figure State S_4 Figure State S_5 Figure State S_6 Figure State S_7 Figure State S_8 Figure State S_9 Invariants, Loop Variants and Termination in the Simple Balloon Example Question Give an example of an invariant for the balloon example. Answer An invariant of the system is: Number of balloons is at most 2 which is equivalent to: (X, Y) + (Y, X) <= 2 (Here we are abusing notation using (X, Y) for a channel and also for the state of the channel.) Question How do you prove that this condition is invariant? Answer To prove that this predicate (Boolean condition) is an invariant we prove that (1) it holds initially and (2) and for all state transitions, if the invariant holds in the state before the transition then it holds in the state after the transition. Initially: (X, Y) = 1 and (Y, X) = 1 So, the predicate holds initially. A state transition in which a balloon is returned does not change the value of (X, Y) + (Y, X) . A state transition in which a balloon is popped decreases (X, Y) + (Y, X) . Therefore if the predicate holds before a state transition then it holds after the transition. Question Is the following an invariant of the system? ((X, Y) + (Y, X) = 2) or (nX = 0) or (nY = 0) Answer Yes, this predicate is an invariant. To prove that this predicate is an invariant we prove that (1) it holds initially and (2) and for all state transitions, if the invariant holds in the state before the transition then it holds in the state after the transition. Initially, (X, Y) = 1 and (Y, X) = 1 .    Therefore the predicate holds initially. Let S be the state before a transition to a state S'. We will prove that if the predicate holds in S then the predicate holds in S'. Consider two cases: nX = 0 or nY = 0 in S. Because nX and nY do not increase, and nX and nY do not become negative, in the execution of an event, it follows that nX = 0 or nY = 0 in S'. Therefore the predicate holds in S'. nX > 0 and nY > 0 in S. Because the invariant holds in S it follows that (X, Y) + (Y, X) = 2 in S. Because nY > 0 the execution of an event in which Y receives a balloon leaves (X, Y) + (Y, X) unchanged. Because nX > 0 the execution of an event in which X receives a balloon leaves (X, Y) + (Y, X) unchanged. Therefore (X, Y) + (Y, X) = 2 in S'. So, the predicate holds in S'. Example of a Loop Variant Question How do you prove that the algorithm terminates? Answer To prove that the algorithm terminates we use the loop variant: nX + nY + (X, Y) + (Y, X) The loop variant is a function of the state (i.e. variables) of the system.    In this example, the loop variant maps states of the program to integers. We must show that  (1) the loop variant is bounded below and we can carry out induction on the values of the loop variant, i.e., it can decrease only a finite number of times before it reaches a lower bound, and (2) the executions of all steps in all computations that start at initial states reduce the value of the loop variant.    The specific lower bound is irrelevant for the proof of termination. In this example, 0 is (obviously) a lower bound.    Next we show that the execution of any event in any state reduces the value of the loop variant. When Y receives a balloon if nY is positive then nY decreases which the loop variant, and if nY is 0 then (X, Y) which decreases the loop variant. Similarly every event in which X receives a balloon also reduces the loop variant. Thus the executions of all events reduce the loop variant. Therefore the algorithm terminates execution. Question What can you prove about the state of the system when the computation terminates?    We have shown that computations terminate and we given examples of invariants. Answer At termination all channels are empty.    Let's prove that nX or nY is 0 at termination. From the invariants if: (X, Y) + (Y, X) \(\neq\) 2 then nX or nY is 0. At termination, (X, Y) + (Y, X) \(=\) 0, and the result follows. More Examples of Invariants and Loop Variants We reason about the correctness of many distributed algorithms in in the same way that we reason about sequential while loops, by using invariants and loop variants. Example: GCD using a While Loop A loop invariant is an assertion about the state of the program that holds before and after each iteration of the loop.    You can look up many examples of loop invariants on the web. Example: Invariant A loop invariant in the following greatest common divisor (gcd) program is shown in the body of the loop as the assertion gcd(x, y) = gcd(X, Y) . x, y = X, Y while x != y: # assertion: gcd(x, y) = gcd(X, Y) if x > y: x = x - y else: y = y - x Invariant of a Distributed System for GCD An invariant of a distributed system is a predicates that holds in all states reachable from initial states.    An invariant of a distributed system is the loop invariant of the following while loop.    An invariant Inv is shown as an assertion in the body of the loop. while there exists a nonempty input channel in the system: # assertion: Inv select a nonempty channel (u, v) in the system let the head of channel (u, v) be msg v executes receive(msg, u) Example of a Distributed GCD We are given a strongly connected network of agents -- i.e., there is a path from each agent to every other agent.    Each agent has a local variable n , which is initialized as a positive integer.    Let GCD be the gcd (greatest commond divisor) of the initial values of X.n of all agents X.n .    The following distributed algorithm terminates and at termination X.n = GCD for all agents X.n .    In the code, successors is the list of successor agents in a network of agents, and the agent only sends messages to its successors. def receive(message, sender): if n != message: n = gcd(n, message) for successor in successors: send(n, successor) An invariant of the distributed algorithm is as follows. The gcd of: all messages in channels and X.n for all agents X is GCD. Proof The proof that the assertion holds initially is trivial.    Prove that if the assertion holds before any event then it continues to hold after the event. Let the event be agent A receiving a message m . After the event, m is no longer in the channel; n = gcd(n, m) ; and messages with the new value of n are in the output channels from A . The proof that the assertion continues to hold in the post-event state is straightforward. Example of an Invariant Another invariant for the gcd example, given earlier, is as follows. For all channels (X, Y) in the network: Channel (X, Y) is empty and X.n is a multiple of Y.n , or The last message in channel (X, Y) is m where m = X.n . Proof The assertion holds initially because the second condition holds.    Prove that if the assertion holds before any event then it continues to hold after the event. When agent X executes a receive that changes X.n the agent sends a message m to Y where m = X.n , and so the second condition holds. When agent Y receives m the agent sets Y.n = gcd(Y.n, m) , and so m is a multiple of the new value of Y.n .    If channel (X, Y) remains nonempty then the second condition holds.    If (X, Y) becomes empty then the first condition holds because m = X.n and m is a multiple of Y.n . Loop Variant Question about Loop Variant in the Sequential GCD What is an example of a loop variant for the following loop? x, y = X, Y while x != y: # assertion: gcd(x, y) = gcd(X, Y) if x > y: x = x - y else: y = y - x Answer f(x, y) = x + y is an example of a loop variant for the following reasons. f is a function of the state of the program. f has integer values. f is bounded below. The bound is 2 because x and y are bounded below because of the invariants x \(\geq\) 1, and y \(\geq\) 1. The precise bounds don't matter. Each execution of the loop decreases f . We can carry out an induction on f because f has integer values and is bounded below. Question about Loop Variants in Distributed Algorithms Let's look at the example of the distributed algorithm given earlier? The example is repeated below. We are given a strongly connected network of agents -- i.e., there is a path from each agent to every other agent.    Each agent has a local variable n , which is initialized as a positive integer.    Let GCD be the gcd (greatest commond divisor) of the initial values of X.n of all agents X.n .    In the code, successors is the list of successor agents in a network of agents, and the agent only sends messages to its successors. def receive(message, sender): if n != message): n = gcd(n, message) for successor in successors: send(n, successor) Question What is an example of a loop variant for the distributed algorithm? Answer Let f be the tuple (N, M) where N is the sum of X.n for all agents X , and M is the total number of messages in channels. Comparisons of tuples are made lexicographically.    For example (2, 1) > (1, 10), and (2, 1) < (2, 2). f is bounded below by (0, 0). An induction can be carried out on a tuple of integers.    Next we show that the execution of each event reduces f . When an agent X receives a message m , if X.n \(\neq\) m then X.n becomes gcd(X.n, m) , and so the new value of X.n is less than its previous value, and so execution of the event decreases N which decreases f . if X.n \(=\) m then the event removes message m from a channel and does not add messages to channels. So the event decreases M which decreases f . Termination Condition of a While Loop What can we say about the state at termination of the while loop in the gcd example: x, y = X, Y while x != y: # assertion: gcd(x, y) = gcd(X, Y) if x > y: x = x - y else: y = y - x The while loop terminates when x = y . From the invariant, at termination: gcd(x, y) = gcd(x, x) = x = gcd(X, Y) Therefore x and y are gcd(X, Y) at termination of the while loop. Termination Condition of a Distributed Algorithm What is the termination condition of the distributed gcd algorithm in which the receive of each agent is as follows? def receive(message, sender): if n != message: n = gcd(n, message) for successor in successors: send(n, successor) At termination all channels are empty.    From the invariant, if channel (X, Y) is empty then X.n is a multiple of Y.n. Therefore when all channels are empty, for every channel (X, Y) in the system X.n is a multiple of Y.n.    Because the directed graph of agents and edges specified as successors of agents is strongly connected: for all agents X, Y in the system: X.n is a multiple of Y.n Therefore X.n = Y.n for all agents X, Y. From the invariant, X.n is GCD. Next The next webpage discusses data flow in computations . Frequenty Asked Questions K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/ComputationsFAQ.html ---
TITLE: DistributedSystemModels/BasicsFAQ.html

DistributedSystemModels/BasicsFAQ.html Distributed Algorithms Contents Index Computations: FAQ Exactly what is the difference between an event and a step of a computation? An event is a 4-tuple which specifies a state transition.    The same event can occur multiple times in a computation.    Each occurrence of the event is a separate step of the computation.    The following example illustrates the difference between a step and an event. Consider an agent that receives numbers on an input channel and sends squares of the numbers on an output channel.    The agent may receive the message 3 and send the message 9 multiple times in a computation.    The specification of an execution of a receive function which receives 3 and sends 9 is specified by an event -- a 4-tuple.    Each execution in which the agent receives 3 and sends 9 is the execution of the same event.    Each execution in which the agent receives 3 and sends 9 is a different step of the computation. Don't computations have to start in an initial state of the system? We define computations as a sequence of state transitions that can start in any state.    When we prove properties of a system we prove properties of computations that start in the initial state of the system.    Some papers on distributed systems restrict computations to start in an initial state of the system but we don't do so in this course. What is a loop invariant? Read See Effective Theories in Programming Practice by Jayadev Misra for many beautiful examples. See the Wikipedia page and links from the page to sources on the web for a definition and many examples. A loop invariant is a predicate (a boolean formula) that holds at the beginning and end of each step of a computation.    The following example illustrates the concept. The algorithm computes the GCD (greatest common divisor) of positive integers X and Y . x, y = X, Y # gcd(x, y) = gcd(X, Y)    while x != y: # gcd(x, y) = gcd(X, Y)    if x > y: x = x- y if y > x: y = y - x    # gcd(x, y) = gcd(X, Y)    return x The invariant is: gcd(x, y) = gcd(X, Y) It holds before each step. If the algorithm terminates then we have x == y and so at termination: gcd(x, y) = gcd(x, x) = x = gcd(X, Y) How does the idea of loop invariant work for a distributed computation when we don't know which event will be executed at each step? The loop invariant for a distributed computation has the form set up initial state of the system # loop invariant holds    while there exists an event that can be executed: # loop invariant holds execute any executable event # loop invariant holds So, we have to prove that the invariant holds in all initial states, and if the invariant holds before any event that is executable then it continues to hold after the event is executed. What is a loop variant? As with loop invariants please read the link to Wikipedia and links in the Wikipedia page. See Effective Theories in Programming Practice by Jayadev Misra for many beautiful examples.    A loop variant is used to prove that execution of a loop terminates.    More generally, we use the idea of loop variants to prove that a computation eventually reaches a goal. A loop variant is a function of the state (variables) of a program. The value of the function decreases at each iteration of a loop. The function is bounded below, and so the value of the function cannot decrease forever. Therefore the loop terminates. Let's look at the example given earlier to compute gcd(X, Y) . A loop variant is x + y .    Each iteration of the loop decreases x + y .    It is bounded below by 2 -- the bound doesn't matter as long as there is a bound. Because it is bounded below and cannot decrease forever the loop terminates. Next Computations shows how a while loop of a sequential program can be used to analyze distributed algorithms. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/ComputationsReview.html ---
TITLE: DistributedSystemModels/ComputationsReview.html

DistributedSystemModels/ComputationsReview.html Distributed Algorithms Contents Index Computations: Review Answer these questions to review the webpage on computations. A computation is a central concept in describing and analyzing distributed algorithms.    The relationship between computations and dataflow helps us understand many algorithms. What is the relationship between a single event and an iteration of the sequential program abstraction of a distributed system. What is the change in state caused by execution of a single iteration of the while loop representation of a distributed system? What is the relationship between this change in state and the change in state specified by an event? What is a computation? What is the relationship between a computation and the sequence of states of the while loop abstraction of a distributed system? Review sequential programming: What is an invariant of a while loop? How do you prove invariants? Review sequential programming: What is a loop variant of a while loop? Review sequential programming: Review your earlier courses on proving properties of loops. Give and prove an algorithm for computing the all-points shortest paths in graphs. Next The next webpage discusses the concepts of past and future in computations and dataflow. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/Model.html ---
TITLE: DistributedSystemModels/Models.html

DistributedSystemModels/Models.html Distributed Algorithms Contents Index Data Flow in Computations A dataflow graph of a computation is a labeled directed acyclic graph that shows the flow of data between agents during the computation.    All topological sorts of a dataflow graph are computations. Dataflow Graph A dataflow graph of a computation is a labeled, directed, acyclic graph  that shows the flow of data between agents during the computation.    The vertices of the graph represent steps of the computation. Example of a Vertex in a Dataflow Graph Figure Example of a Vertex in a Dataflow Graph The edges of a dataflow graph are as follows. There is an edge from a step at an agent to the next step at that agent; this edge is labeled with the state of the agent between the events and is called an agent edge . There is an edge from a step in which a message is sent to the step at which the message is received; this edge is called a message edge . The edge is labeled with a pair \((m, w)\) where \(m\) is the message and \(w\) is the sender of the message. Representing Initial and Final States by Fictitious Steps A computation is specified by its initial state and a sequence of events.    For convenience, we represent the initial state of an agent \(u\) and the initial states of \(u\)'s output channels be a fictitious step, \(u_{init}\).    The vertex representing this step has no inputs. The agent edge from this step is labeled with \(u\)'s initial state.    The message edges from this step to steps of an agent \(v\) are labeled with the messages in the channel \((u, v)\) in the initial state of the computation. Figure Example of an Initial Vertex of a Dataflow Graph The figure shows an example of an initial vertex, u_init at agent u of a dataflow graph.    The vertex has an output agent edge labeled u1 which is the initial state of agent u in the computation.    The vertex has an output message edge labeled m2 ; this edge is to a step in agent v and shows that the initial state of the channel (u, v) consists of the single message m2 . By symmetry, we use a fictitious step \(u_{fini}\) to represent the final state of \(u\) and the final states of channels to \(u\).    With the introduction of fictitious initial and final steps for each agent we can treat a computation as a sequence of steps where the initial state is specified by initial steps. Figure Example of a Final Vertex of a Dataflow Graph We adopt the convention that agent edges are horizontal.    So, all edges of the same agent are on the same horizontal line. We use step of a computation and vertex of its dataflow graph interchangeably, with the meaning understood by context. Example of a Dataflow Graph Figure Example of a Dataflow Graph The figure shows the dataflow graph for a computation of a system consisting of two agents u and v , and with two channels (u, v) and (v, u) .    The computation is defined by its initial state and event sequence [1, 2, 3, 4]. The initial states at agents u and v are represented by outputs of steps u_init and v_init , respectively, and final states by inputs to u_fini and v_fini , respectively. The top horizontal edges represent data flow between steps at agent u and the lower horizontal edges represent data flow between steps at agent v .    For example, the labels u1, u2, u3 are the initial state of agent u , the state of u between steps 1 and 4, and the state of u after step 4, respectively.    Likewise, the labels v1, v2, v3 are the states of agent v initially and after steps 2 and 3, respectively. Message edges are labeled m1, m2, m3, m4, m5 .    Initially channel (u, v) contains message m2 and channel (v, u) contains message m1 .    Message m3 is sent in step 1 and received in step 3, and message m4 is sent in step 3 and received in step 4. Vertex 1 in the graph, see figure 1 -- example of a vertex in a dataflow graph -- represents the execution of a step at agent u . This step is the execution of an event specified by the following 4-tuple: The state of \(u\) before the event is u1 . The message received in the event is m1 from agent v . The state  of \(u\) after the event is u2 . A single message m3 is sent in the event and this message is  sent to agent v . The input and output edges of the vertex are the inputs and outputs (respectively) of the event. Dataflow Graphs are Acyclic A dataflow graph of a computation is acyclic because each edge is directed from a step to a later step of the computation. Flow of Data in a Computation The edges of the dataflow graph of a computation show the flow of data into and out of each step of a computation.    Data -- in the form of the agent's state -- flows from a step of an agent to the next step at that agent.    Data -- in the form of message contents -- flows from a step in which a message is sent to the step in which the message is received. The Relation: "data flows from" between Steps of a Computation We define a relation "data flows from" between steps of a computation as follows: for steps \(x, y\) of a computation, data flows from \(x\) to \(y\) exactly when there is a path in the computation's dataflow graph from \(x\) to \(y\). The set of steps of a computation with the relation "data flows from" is a strict partial order .    We say that steps \(x\) and \(y\) are independent if data does not flow from  \(x\) to \(y\) or from \(y\) to \(x\). Example of data flows from a step to a step The figure "Example -- Data Flows from Step 2 to Step 4" shows examples of data flow as red edges in the graph.    Steps 1 and 2 are independent because there is no path from step 1 to step 2, and there is no path from step 2 to step 1. Figure Example -- Data Flows from Step 2 to Step 4 Computations and Dataflow Graphs Let a computation be specified by a sequence of steps \(E\), and let \(E'\) be any permutation of \(E\). Data flows forwards in \(E\) means that for all steps \(x\) and \(y\) in \(E\): If data flows from \(x\) to \(y\) in \(E\) then \(x\) appears before \(y\) in \(E'\). Next we prove properties about sequences of steps in which data flows forwards.    We start with the following lemma. Lemma: Switching Order of Adjacent Independent Steps in a Computation Let a computation be specified by  a sequence of steps \(E\), and let \(E'\) be any permutation of \(E\) obtained by switching the order of a pair of adjacent elements in \(E\).    If data flows forward in \(E'\) then \(E'\) is a computation. Proof Assume that the order of adjacent steps \(e_{i}\) and \(e_{i+1}\) are switched in \(E\) to get \(E'\).    Because \(e_{i}\) precedes \(e_{i+1}\) in \(E\) there is no data flow from \(e_{i+1}\) to \(e_{i}\). Because data flows forwards in \(E'\) there is no data flow from \(e_{i}\) to \(e_{i+1}\). Therefore \(e_{i}\) and \(e_{i+1}\) are adjacent independent steps. So, the inputs to \(e_{i}\) and \(e_{i+1}\) remain the same regardless of the order in which they are executed, and so \(E'\) is also a computation. Example of Switching Adjacent Independent Steps The Figure "Example of Switching Adjacent Independent Steps" shows two diagrams with identical dataflow graphs. The upper and diagrams are representations of computations starting at the same state and step sequences [1, 2, 3, 4], and [2, 1, 3, 4]. The order in which vertices 1 and 2 appear, from left to right, in the diagrams have been switched. The graphs, however, are identical. The inputs to step 1 remain the same whether step 2 is executed before or after step 1. Likewise, the inputs to step 2 remain the same whether step 1 is executed before or after step 2. Figure Example of Switching Adjacent Independent Steps Theorem: Permutations of Computations in which Data Flows Forwards Given a computation specifed by a sequence of steps \(E\), all permutations of \(E\) in which data flows forwards are also computations. Proof Let \(E'\) be a permutation of \(E\) where data flows forwards in \(E'\).    The theorem holds trivially if \(E\) and \(E'\) are identical. If \(E\) and \(E'\) are not identical then there exists an adjacent pair of steps \(x, y\) in \(E\) where \(x\) occurs before \(y\) in \(E\), and \(y\) occurs before \(x\) in \(E'\). Because \(E\) is a computation, data flows forwards in \(E\) and therefore there is no data flow from \(y\) to \(x\). We are given that data flows forwards in \(E'\). So there is no data flow from \(x\) to \(y\). Therefore \(x\) and \(y\) are independent. Let \(H\) be the sequence of steps obtained from \(E\) by switching the order of \(x\) and \(y\).    From the lemma "Switching Order of Independent Adjacent Steps" it follows that \(H\) is also a computation. The number of out of order pairs between \(H\) and \(E'\) is less than that between \(E\) and \(E'\).    By repeatedly switching of independent adjacent out of order pairs the sequence \(E'\) is reached. Relationship to Topological Sorts The theorem on permutations of event sequences can be expressed in terms of topological sorts.    A topological sort of a directed acyclic graph is a sequence of vertices of the graph where for every edge \((x, y)\) in the graph, \(x\) appears before \(y\) in the sequence. Theorem: Topological Sorts of Dataflow All topological sorts of a dataflow graph are computations. Next The next pages describes Cuts in Dataflow Graphs which are used in developing detection algorithms such as termination detection and deadlock detection. Examples Frequenty Asked Questions Review K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/ModelExamples.html ---
TITLE: DistributedSystemModels/ModelExamples.html

DistributedSystemModels/ModelExamples.html Distributed Algorithms Contents Index Dataflow: Examples A Simple Example (continued) This example is a continuation from the example in States .    Two children, X and Y, are tossing balloons to each other.    A balloon that has been tossed by X, while in the air to Y, is a message in the channel (X, Y).    When a child gets a balloon it tosses the balloon back immediately.    Initially there is a balloon tossed by X on its way to Y and there is also a balloon tossed by Y on its way to X. Each child has a countdown of the number of times it tosses balloons.    Each time a child tosses a balloon it decrements its countdown value.    After a child's countdown reaches 0 the child pops balloons that it receives (and doesn't toss popped balloons). State The state of a channel is the number of balloons in it.    The state of an agent (X or Y) is the countdown value nX or nY, respectively. A Computation: A Sequence of States An example of a sequence of state changes is as follows. Initial State : Channel (X, Y) has one balloon and channel (Y, X) has one balloon. And the countdown for X is 2 and the countdown for Y is 3. We represent this state by: nX = 1, nY = 2, (X, Y) = 1, (Y, X) = 1 The sequence of steps from the initial state are as follows. Y receives a balloon and sends it back. So the state becomes: nX = 1, nY = 1, (X, Y) = 0, (Y, X) = 2 X receives a balloon and  sends it back. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 1 Y receives a balloon and sends it back. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 2 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 1 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 0 There are no further steps in this computation. Dataflow of the Computation The dataflow graph of the computation is shown in the figure. Figure The Dataflow Graph for the Example Agent X has a fictitious step, X_init, that initializes X's state and X's output channels. X also steps 2, 4, and 5 in the above computation. X also has a fictitious final step, X_fini, that identifies X's final state and the final state of X's input channels. Likewise, agent Y has a fictitious step, Y_init, that initializes Y's state and Y's output channels. Y also steps 3, and 5 in the above computation. Y also has a fictitious final step, Y_fini, that identifies Y's final state and the final state of Y's input channels. Agent Edges for Agent X The horizontal line consisting of steps at X consists of the following directed edges. X_init to step 2 with label nX = 1. The label is the initial state of X Step 2 to step 4 with label nx = 0. Step 4 to step 5 with label nx = 0. Step 5 to X_fini with label nx = 0. This label is the final state of X in the computation. Agent Edges for Agent Y Likewise the horizontal line cconsisting of steps at Y and consists of the following directed edges. Y_init to step 1 with label nY = 2. The label is the initial state of Y Step 1 to step 3 with label nY = 1. Step 3 to Y_fini with label nY = 0. This label is the final state of Y in the computation. Message Edges for Channel (X, Y) The message edges representing messages on channel (X, Y) are as follows. All the messages have label "1" because each message represents a single balloon. X_init to step 1. This is the message in the channel in the initial state of the computation. Step 2 to step 3. There are no message edges from steps at X to Y_fini because the channel (X, Y) is empty in the final state. Message Edges for Channel (Y, X) The message edges representing messages on channel (Y, X) are as follows. All the messages have label "1" because each message represents a single balloon. Y_init to step 2. This is the message in the channel in the initial state of the computation. Step 1 to step 4. Step 2 to step 5. There are no message edges to X_fini because the channel (Y, X) is empty in the final state. Example from Previous Pages The following dataflow diagram is for the computation given in examples of computations .    The computation starting at the initial state executes steps p1 , n1 , t1 , p2 , t2 , n2 , t3 , X1 where the steps are shown in the dataflow diagram. Figure The Dataflow Diagram In the dataflow diagram, p1 and p2 are steps at agent pos ; n1 and n2 are steps at agent neg , t1, t2, t3 are steps at agent total , and X1 is an step at agent X . Steps p0, n0, t0, X0 are the fictitious initial steps at agents pos, neg, total, X (respectively) that specify the initial state of the computation.    Likewise, steps p*, n*, t*, X* are the fictitious final steps that specify the final state of the computation. Let's look at p0 as an example of an initial step.    There is an agent edge from p0 to p1 labeled with the state of agent pos in the initial state of the computation.    The state of pos is given by its variable n which is initially 2; so the edge from p0 to p1 is labeled n = 2 which is abbreviated to 2. Agent X has no state; it merely prints messages that it receives.    So agent edges at X have no label (or equivalently the empty label). Let's look at X* as an example of a final step.    There are message edges labeled 1, 0, and 5 from steps at total to X* .    This represents the state of channel (total, X*) in the final state of the computation. Let's look at step p1 at agent pos .    The state of pos changes from n = 2 to n = 1 .    So the output agent edge from p1 is labeled n = 1 . In step p1 , pos sends a message 3 to total and a wakeup message to itself.    So the output message edges from step p1 are labeled wakeup (shown as a star) and 3; these message edges are to steps step p2 and step t1 , respectively, because the messages are received in those steps. Next The next page describes Cuts in Dataflow Graphs which are used in developing detection algorithms such as termination detection and deadlock detection. Examples Frequenty Asked Questions K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/ModelFAQ.html ---
TITLE: DistributedSystemModels/ModelFAQ.html

DistributedSystemModels/ModelFAQ.html Distributed Algorithms Contents Index Dataflow: FAQ What are the edges incident on a vertex in a dataflow graph? Does each vertex have two input edges and two output edges? A vertex, other than a vertex representing a fictitious initialization step or a final step, has one input agent edge which is labeled with the state of the agent before the event, and one input message edge which is labeled with the pair (m, w) where m is the message received in the event and m is the sender of the message, and the number of output message edges is 0 if the step sends no messages. A vertex have any number of output message edges. It has one output message edge for each message sent in the event. An initialization vertex has no input edges; it only has output edges.    The output edges of an initialization vertex are exactly the same as the output edges of the vertices that represent real (as opposed to fictional) steps. A final vertex has no output edges; it only has input edges.    The input edges of a final vertex are exactly the same as the input edges of the vertices that represent real (as opposed to fictional) steps. Exactly how are initial states of channels represented? If there are two messages m1, m2 in a channel from u to v and the messages are received by v in steps 1 and 2 then how is this represented in a dataflow graph? The initial states of channels from an agent u are represented by message edges from the vertex representing the fictitious initialization step of agent u. In the example, there are two message edges from the initialization vertex of u. The first message edge is to the vertex representing step 1 of v, and this edge is labeled m1. The second message is to the vertex representing step 1 of v. How many dataflow graphs are associated with a computation? How many computations are associated with a dataflow graph? A computation has exactly one dataflow graph that shows the flow of data in the computation. All topological sorts of dataflow graphs are computations.    The number of computations that a dataflow graph represents is the number of topological sorts of the dataflow graph. What is the number of topological sorts of a dataflow graph? That depends on the graph.    You can construct a graph with 1 topological sort and a graph with n! topological sorts where n is the number of vertices. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/ModelReview.html ---
TITLE: DistributedSystemModels/ModelReview.html

DistributedSystemModels/ModelReview.html Distributed Algorithms Contents Index Dataflow: Review Answer these questions to review the webpage on dataflow. We use dataflow in analyzing several algorithms.    We use timelines to discuss performance of a few algorithms.    This review emphasizes dataflow. What is an event? How is an event related to an execution of a receive statement by an agent? What are the inputs and outputs of an event? What are the vertices of a dataflow graph? What are the edges of a dataflow graph? How do edges of a dataflow graph of a computation represent the flow of data between steps of the computation? What is the concept of time in dataflow? What is the difference between event and step ? What is the relationship between computations and dataflow graphs? What is a topological sort of a directed acyclic graph? What is the key theorem relating computations and dataflow graphs? Next The next pages describes Cuts in Dataflow Graphs which are used in developing detection algorithms such as termination detection and deadlock detection. Examples Frequenty Asked Questions Review K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/Timelines.html ---
TITLE: DistributedSystemModels/Timelines.html

DistributedSystemModels/Timelines.html Distributed Algorithms Contents Index Cuts of Dataflow Graphs This page introduces the concept of a cut of a dataflow graph and relates a cut to the only notions of time -- past and future -- in dataflow.    A cut separates past from future.    Cuts of dataflow are central to understanding detection algorithms such as deadlock detection and for global snapshot algorithms that determine states of distributed systems. A cut of a dataflow graph is a subset of vertices of the graph where all paths to vertices in the cut are from vertices in the cut. Equivalently, a cut of a computation is a subset of steps such that for every step \(e\) in the cut, all steps from which data flows to \(e\) are also in the cut. A cut of a dataflow graph is an instance of a cut of a flow network . Example The top diagram of figure 1 shows a cut in which vertices in cut are colored red and vertices not in cut are green.    The curved black line is the boundary separating cut from vertices outside it. Fig.1: Example - A Cut of a Dataflow Graph Theorem: Computations and Cuts Let \(E\) be a computation and \(C\) be a cut of the computation.    There exists a computation \(E'\), which is a permutation of \(E\), in which all steps in the cut are executed before any step that is not in the cut. Proof Obtain \(E'\) from \(E\) as follows.    Let pre be the sequence of steps obtained from \(E\) by deleting all steps in the cut.    Let post be the sequence of steps obtained from \(E\) by deleting all steps not in the cut.    Then \(E'\) consists of pre followed by post . The proof that data flows forwards in \(E'\) is straightforward. Theorem: State at a Cut The state after execution of steps in a cut and before execution of steps that are not in cut steps is given by the labels of edges from vertices in the cut to vertices outside the cut. See the lower diagram in figure 1. The state S* after the cut is shown as final vertices (which are labeled N ) of cut and S* is shown as as initial vertices (which are labeled 0 ) of steps outside cut . Next The properties of cuts in dataflow, and the concepts of before - after, past - future are central for algorithms by which agents record the states of distributed systems discussed in the next chapter. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/TimelinesExamples.html ---
TITLE: DistributedSystemModels/TimelinesExamples.html

DistributedSystemModels/TimelinesExamples.html Distributed Algorithms Contents Index Dataflow: Examples A Simple Example (continue) This example is a continuation from the example in States .    Two children, X and Y, are tossing balloons to each other.    A balloon that has been tossed by X, while in the air to Y, is a message in the channel (X, Y\).    When a child gets a balloon it tosses the balloon back immediately.    Initially there is a balloon tossed by X on its way to Y and there is also a balloon tossed by Y on its way to X. Each child has a countdown of the number of times it tosses balloons.    Each time a child tosses a balloon it decrements its countdown value.    After a child's countdown reaches 0 the child pops balloons that it receives (and doesn't toss popped balloons). State The state of a channel is the number of balloons in it.    The state of an agent (X or Y) is the countdown value nX or nY, respectively. A Computation: A Sequence of States An example of a sequence of state changes is as follows. Initial State: Channel (X, Y) has one balloon and channel (Y, X) has one balloon. And the countdown for X is 2 and the countdown for Y is 3. We represent this state by: nX = 1, nY = 2, (X, Y) = 1, (Y, X) = 1 Y receives a balloon and sends it back. So the state becomes: nX = 1, nY = 1, (X, Y) = 0, (Y, X) = 2 X receives a balloon and  sends it back. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 1 Y receives a balloon and sends it back. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 2 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 1 Y receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 0 There are no further steps in this computation Another Computation What are other computations of the system? Let's look at the event in step 3 of the above computation. The event is as follows. Event: X receives a balloon for the first time This event is specified by the 4-tuple: X's state before the event is nX = 1 The message that is received is 1 (balloon) and the message is from Y. X's state after the event is nX = 0 The message that is sent in the event is 1 (balloon) and the message is to Y. This event can be executed in any state S which satisfies the inputs to this event: X's state before the event is nX = 1 The message at the head of channel (Y, X) is 1. So, this event can be executed in the initial state. You can now construct the following computation. Initial State: Channel (X, Y) has one balloon and channel (Y, X) has one balloon. And the countdown for X is 2 and the countdown for Y is 3. We represent this state by: nX = 1, nY = 2, (X, Y) = 1, (Y, X) = 1 X receives a balloon and sends it back. So the state becomes: nX = 0, nY = 2, (X, Y) = 2, (Y, X) = 0 Y receives a balloon and  sends it back. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 1 X receives a balloon and pops it. So the state becomes nX = 0, nY = 1, (X, Y) = 1, (Y, X) = 0 Y receives a balloon sends it back. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 1 X receives a balloon and pops it. So the state becomes nX = 0, nY = 0, (X, Y) = 0, (Y, X) = 0 There are no further steps in this computation A system may have many computations.    All the states of the computations of the system are states in the while loop: Initial State    while there exists an executable event: execute any executable event In this example, after the initial state there were two executable events: an event at X and an event at Y. Either of these two events could have been selected as the next event to be executed. Invariant An invariant of this system is: Number of balloons is at most 2 which is equivalent to: nX + nY + (X, Y) + (Y, X) <= 2 (Here we are abusing notation using (X, Y) for a channel and also for the state of the channel.) To prove that this predicate (Boolean formula on variables of the program) is an invariant we prove that (1) this predicate holds initially (i.e., the formula is true initially) and (2) if it holds before any step then it holds after the step. Loop Variant To prove that the function terminates we use the loop variant: nX + nY + (X, Y) + (Y, X) The loop variant is a function of the variables of the system.    We can carry out an induction on this function because it returns integers and is bounded below.    The bound is not important. In our example, a bound is 0. We prove that the computation terminates by showing that each step reduces the variant function. Next States of a Distributed System. Review material for this page K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/TimelinesFAQ.html ---
TITLE: DistributedSystemModels/TimelinesFAQ.html

DistributedSystemModels/TimelinesFAQ.html Distributed Algorithms Contents Index Timelines: FAQ Which agent starts a global snapshot algorithm? The algorithm is started by any one or more agents.    The agents that start the algorithm isn't specified. The agent that should initiate a snapshot algorithm is usually self evident from the application of the algorithm.    For example, an agent that has been waiting for a long time for a message may obtain a global snapshot to determine if the agent is in a deadlock. Can the snapshot algorithm be used to record the states and channels of a subset of agents, or does the algorithm have to span all agents and channels? The snapshot algorithm can be used to record the states of a connected subset of agents.    An agent doesn't propagate markers to agents outside the set of interest.    The recorded states of the subset of agents and channels forms a part of a global snapshot.    Some algorithms only used snapshots of subsets of agents. Is "every message received in past is sent in past " equivalent to "every message sent in future is received in future "? Yes Note that a message may be received in the final state. Next Chapter on Snapshots and Clocks: Global Snapshots. Properties of Dataflow K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DISTRIBUTED_SYSTEM_MODELS/TimelinesReview.html ---
TITLE: DistributedSystemModels/TimelinesReview.html

DistributedSystemModels/TimelinesReview.html Distributed Algorithms Contents Index Past, Future and Cuts in Dataflow: Review Answer these questions to review the webpage on past, future and cuts in dataflow. What is the concept of time in dataflow? What do before and after mean in a dataflow graph? What is a cut in a dataflow graph? What is the relationship between a cut in a dataflow graph and a cut in a flow network? What is the state of a cut? Draw a dataflow graph. Identify two or more cuts in the graph. For the cuts in the previous example, give examples of dataflows consisting only of past events, and only of future events. For the cuts in the previous example, give examples of computations in which past events precede future events. Give an example of a partition of the set of vertices of a dataflow graph into subsets past and future where a message from future is received in past . Explain why this partition is not a cut. A property of a cut is that for each channel \(c\), the number of messages sent on the channel in past is at least the number of messages received on the channel. Consider a partition (past, future) of the set of vertices, specified by a vector \(n\) where past consists of the first \(n[k]\) events of agent \(k\). Is this partition necessarily a cut if the total number of messages sent in past is at least the total number of messages received in past ? Next The properties of cuts in dataflow, and the concepts of before - after, past - future are central for algorithms by which agents record the states of distributed systems discussed in the next chapter. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/ChannelSnapshots.html ---
TITLE: ChannelSnapshots/ChannelSnapshots.html

ChannelSnapshots/ChannelSnapshots.html Distributed Algorithms Contents Index A Global Snapshot Algorithm A global snapshot algorithm records a state of the system that can occur during a computation.    The state obtained by the algorithm is called a global snapshot.    Systems are monitored by taking repeated global snapshots.    When a transient error is detected, a rollback and recovery algorithm restarts the computation from the most recent snapshot instead of starting it from the initial state. Global Snapshot A global snapshot algorithm records a state of the system that occurs during a computation of the system.    A state obtained by the algorithm is called a global snapshot. A state of the system is a tuple with an element of the tuple for each agent and each channel.    A system state is also called a global state to distinguish it from states of agents and states of channels. An algorithm to record the state of a system is not instantaneous because the algorithm records the states of multiple agents and channels.    The algorithm starts at some point and terminates at a later point.    A global snapshot is a state that occurs in a computation from the state in which the algorithm starts to the state in which the algorithm ends. The global snapshot algorithm is an example of an algorithm that is executed by a distributed operating system (OS) on behalf of a client.    Next, we describe features of the OS that are relevant to the snapshot algorithm. A Distributed Operating System Each client agent has an OS agent that supervises it.    OS agents use the same processors and channels as clients do.    OS agents can record, but not modify, states of their clients.    OS agents can send and receive OS messages that are not seen by clients. Figure 1 is a representation of two OS agents that manage their client agents.    Messages sent by a client are recorded by the OS and passed through to destination clients.    The OS sends messages on the same channels as clients, but the OS traps these messages so that the client does not see them. Fig.1: OS and Clients use the same Channels Execution of an OS agent on a processor may delay a client's steps on the same processor, and thus change the order in which the client's steps are executed. The OS may change a client's computation -- the order of steps -- but the OS must not change the client's dataflow. One way to record a global snapshot is for the OS to stop a client computation, then take a global snapshot, and then  restart the client computation.    Our goal is to design an algorithm that does not stop the client. Hereafter, when we refer to an agent we mean an OS agent.    Likewise, by messages we mean those that are sent and received by the OS. Next, let's develop OS agents and OS messages to record a global snapshot. The Problem Let \(S_{init}\) and \(S_{fini}\) be the states in which the algorithm starts and finishes, respectively.    Design an algorithm that records a state \(S^{*}\) such that there exists a computation that starts at \(S_{init}\), then visits \(S^{*}\) and then visits \(S_{fini}\). How Should You Solve the Problem? Strategy A general strategy for designing algorithms dealing with intermediate states is to find a helpful property of cuts .    What property helps to determine \(S^{*}\)? The property "Computations of Past before Future," given below, tells us that \(S^{*}\) can be the state at any cut. Computations of Past before Future. Let computation \(X\) start in state \(S_{init}\) and end in state \(S_{fini}\).    Let \(S^{*}\) be the state at a cut (past, future) of \(X\).    There exists a computation \(Y\) that starts in \(S_{init}\), visits \(S^{*}\), and ends in \(S_{fini}\). Using this strategy, our tasks reduce to (1) identifying a cut, and (2) recording the state, \(S^{*}\), at the cut. Identifying a Cut Each agent has to record its own state because an agent's state is not accessible to other agents.    The state of an agent that it records is called a local snapshot . Define past as the set of steps at each agent before the agent takes its local snapshot, and define future as the set of steps at each agent after the agent takes its local snapshot. So, if a step \(x\) at an agent is in past then all steps at that agent before \(x\) are also in past . Let's use the following property of past , future and cuts: The partition (past, future) is a cut exactly when every message received in past is sent in past . Therefore, (past, future) is a cut exactly when: Global Snapshot Rule Each message received before the receiver takes its local snapshot is sent before the sender takes its local snapshot. Design an algorithm yourself before reading further, and compare your algorithm with the one given below. The Global Snapshot Algorithm A special OS message called a marker is used to distinguish pre-snapshot from post-snapshot messages.    Messages sent on a channel before a marker is sent on the channel are messages sent in the past -- i.e. before the sender takes its local snapshot -- and messages sent after the marker are sent in the future . The algorithm The algorithm begins by one or more agents taking their local snapshots. When an agent takes its local snapshot it sends a marker on each of its outgoing channels. When an agent receives a marker, the agent takes its local snapshot if it has not already done so. The snapshot of a channel is the sequence of messages received on the channel after the receiver takes its snapshot and before the receiver receives a marker on the channel. Proof of correctness From rule 3, each message received by an agent \(r\) on a channel \(c\) before \(r\) takes its local snapshot is a message received by \(r\) before \(r\) receives a marker on channel \(c\). Because channels are first in first out, each message received by \(r\) on \(c\) before \(r\) receives a marker on \(c\) is sent on \(c\) before a marker is sent on \(c\). From rule 2 each message sent on \(c\) before a marker is sent on \(c\) is sent before the sender takes its local snapshot. From the three paragraphs above it follows that the global snapshot rule holds for the algorithm. Proof about States of Channels The messages in a channel at the cut are the messages sent in past and received in future . These are messages sent before the sender takes its snapshot and received after the receiver takes its snapshot.    So, the state of a channel is the sequence of messages received along the channel after the receiver takes its snapshot and before the receiver receives a marker along the channel. Note: If an agent takes its local snapshot when it receives a marker along a channel, then the snapshot of the channel is the empty sequence of messages. Termination of the Algorithm After any agent \(v\) initiates the algorithm, all agents that are reachable from \(v\) will receive a marker and take their local snapshots.    If every agent is reachable from an initiator then all agents take local snapshots. Each agent takes its local snapshot at most once.    So, a marker is sent on a channel at most once.    The computation terminates when all markers are received. Collecting Local Snapshots to form Global Snapshots One way to collect local snapshots is to have an OS agent act as an observer.    Each agent sends its local snapshots to the observer which puts the local snapshots together to form the global snapshots.    Successive snapshots are disambiguated by using sequence numbers or timestamps. Some algorithms carry out distributed computations on local snapshots without using an observer to collect local snapshots.    Later, we give examples of such algorithms. Applications of Global Snapshots System Monitoring Systems can be monitored by taking global snapshots repeatedly.    Let \(S_{0}, S_{1}, S_{2}, \ldots, \) be the sequence of states recorded by the system.    From the property Computations through Increasing Cuts there exists a computation that visits each state \(S_{i}\) in order of increasing \(i\).    The system monitor checks the sequence of snapshots to determine if some action is required. Rollback and Recover Let \(S^{*}\) be the most recent snapshot recorded by a system monitor.    From the property, "Computations of Past before Future" there exists a computation that starts at the initial state and later visits \(S^{*}\).    So, if an error is detected in a computation then the computation can be restarted from \(S^{*}\) rather than rolling all the way back to the initial state. Detecting Stable Predicates A stable predicate is a predicate with the following property: If the predicate holds at any point in any computation then it continues to hold forever thereafter in that computation. Equivalently, if a stable predicate holds in a state \(s\) then it holds in all states reachable from \(s\). Examples of stable predicates are: "The computation has terminated," and "The computation is deadlocked."    If a computation has terminated at some point then it remains terminated.    Likewise if a computation has deadlocked then it remains deadlocked. Specification of Detection Algorithms An algorithm to detect a stable property \(P\) has the following specification. If \(P\) holds when the algorithm is initiated then the algorithm detects that \(P\) holds. If the algorithm detects that \(P\) holds then \(P\) holds when the algorithm terminates. General Detection Algorithms A general solution is for the operating system to monitor a client computation by taking repeated snapshots of the computation.    The OS checks whether a specified stable property holds in each snapshot.    From the property, "Computations of Past before Future" this general solution satisfies the specification of detection algorithms. Detection with Observers The OS uses an agent, the observer, to collect local snapshots and form a global snapshot.    The observer inspects the global snapshot to determine if the property holds in the snapshot.    The OS can also use multiple observers each of which collects local information from subnetworks; the OS then carries out a distributed algorithm on its collection of observers. The OS can also execute a distributed algorithm on local snapshots without having observers collect local information, as described next. Detection without Observers: Distributed Algorithms on Local Snapshots Distributed algorithms on local snapshots operate in two phases.    In the first phase a global snapshot algorithm is executed.    The local snapshot of each agent and its incoming channels are stored locally, at the agent, without sending the information to observers. In the second phase a distributed algorithm is executed to determine if the local information stored at agents satisfies a specified global property, such as "computation has deadlocked."    The algorithm in the second phase operates on unchanging data.    These algorithms are often distributed graph algorithms. The two phases can be executed concurrently in many applications. Next A code skeleton of the algorithm and examples of the global snapshot algorithm are provided here .    Next logical clocks . K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/ChannelSnapshotsDetails.html ---
TITLE: ChannelSnapshots/ChannelSnapshotsDetails.html

ChannelSnapshots/ChannelSnapshotsDetails.html Distributed Algorithms Contents Index A Global Snapshot Algorithm A global snapshot algorithm records a state of the system that can occur during a computation.    The state obtained by the algorithm is called a global snapshot.    Systems are monitored by taking repeated global snapshots.    When a transient error is detected, a rollback and recovery algorithm restarts the computation from the most recent snapshot instead of starting it from the initial state. Global Snapshot: Details This webpage gives a code outline for the global snapshot algorithm and gives examples of steps in the algorithm. Code Structure The code outline is given below in Python. channels_recorded is a dict (dictionary), where channels_recorded[sender] becomes True when the snapshot for the channel from this sender has finished being recorded. channel_snapshots is a dict where channel_snapshots[sender] is the ongoing recording of the snapshot of the channel from the sender. taken_local_snapshot = False channel_snapshots = {key: [] for key in predecessors} channels_recorded = {key: False for key in predecessors}    start() def receive(message, sender): if isinstance(message, Marker) and not taken_local_snapshot: local_snapshot = record_state() taken_local_snapshot = True channels_recorded[sender] = True output_message = Marker() for receiver in successors: send(output_message, receiver) elif isinstance(message, Marker) and taken_local_snapshot: channels_recorded[sender] = True else: if taken_local_snapshot and not channels_recorded[sender]: channel_snapshots[sender] = \\ channel_snapshots[sender].append(message) The remainder of this webpage consists of examples. Examples Example: Snapshots may change a Client's Computation This example shows that the OS algorithm may change a client's computation though it does not change the client's dataflow. Figure 2 is a representation of a computation with event sequence \([0, 1, 2, \ldots, ]\) and agents \(X, Y, Z\) without a concurrent OS algorithm, and figure 3 shows how the OS changes this computation.    Events later in the computation are placed to the right of earlier events. Fig.2: Representation of a Computation without Snapshots Figure 3 shows how a client's computation is changed when the OS takes snapshots.    The local snapshots taken by agents are shown as a yellow circle on the agents' timelines.    The OS delays event 3 so that it occurs after events 4, 5, 6, and 7, as shown in the figure.    The OS changes the computation, but it does not change the dataflow. Fig.3: The OS changes a Client's Computation In figure 3, the pre-snapshot events are 0, 1, 2, 4, 6.    There is only one message received in a pre-snapshot event, namely the message represented by the edge (0, 2).    So, every message received in a pre-snapshot event is sent in a pre-snapshot event.    The figure shows that the set of pre-snapshot events is closed. Example: Steps in a Global Snapshot Algorithm: Initiation Figure 4 illustrates the first step of the algorithm. Fig.4: Agent Sends Markers when it Takes its Local Snapshot Agent Y takes its local snapshot shown as a yellow vertex on Y's timeline.    When Y takes its snapshot it sends markers on its output channels.    The markers are shown as green edges in the figure. When agents X and Z each receive the markers, they take their local snapshots because they haven't taken snapshots earlier. Fig.5: Agents Take Local Snapshots when they Receive Markers The actions by X and Z of taking their snapshots are shown as yellow vertices on their timelines in figure 5. Example: Agents take Snapshots upon Receiving Markers When X and Z take their snapshots they send markers out on their output channels.    The markers sent by X are shown in figure 7.    The markers sent by Z are not shown in the figure. Fig.6: When an Agent takes its Snapshot it sends Markers. Example: Snapshot of a Channel Figure 8 shows how agent Y determines the state of the channel from X to Y in the global snapshot.    Y starts recording the messages it receives along this channel after Y takes its snapshot and stops the recording when it receives a marker on this channel    The only message in this interval is the message corresponding to edge (6, 7). Fig.7: Example: Recording a Channel State The message corresponding to edge \((0, 2)\) is from X to Y but is not in the snapshot of the channel because both \(0\) and \(2\) are pre-snapshot events.    Likewise, the message corresponding to edge \((12, 13)\) is from X to Y but is not in the snapshot of the channel because both \(12\) and \(13\) are post-snapshot events.    The message corresponding to edge \((6, 7)\) was sent in a pre-snapshot event and received in a post-snapshot event, and so it is in the snapshot of the channel. Next Next logical clocks . K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/ChannelSnapshotsFAQ.html ---
TITLE: ChannelSnapshots/ChannelSnapshotsFAQ.html

ChannelSnapshots/ChannelSnapshotsFAQ.html Distributed Algorithms Contents Index Global Snapshots: FAQ Which agent starts a global snapshot algorithm? Any one or more agents starts the algorithm.    The initiators are not specified.    The choice of initiators is usually evident from the application of the algorithm.    For example, an agent that has been waiting a long time for a message may initiate a snapshot algorithm to determine if the agent is in a deadlocked cycle of agents. Can the algorithm be used to detect the states of a subset of agents and channels, or does the algorithm necessarily have to obtain a snapshot that encompasses all agents? The algorithm can be modified to record states of subset \(S\) of agents and their incident channels.    Modify the algorithm in the obvious way: An agent does not send markers to agents that are not in \(S\). The subset of agent and channel states that are recorded are part of a global state.    Some algorithms only need states of subsets of agents. Can the algorithm be used to take repeated snapshots? Yes. Each initiation of the algorithm by an agent \(x\) at local time \(t\) is identified by the pair \(x, t\).    Every local snapshot and every marker is identified in this way.    So, different executions of the global snapshot algorithm can be disambiguated in this way. Next logical clocks . K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/ChannelSnapshotsReview.html ---
TITLE: ChannelSnapshots/ChannelSnapshotsReview.html

ChannelSnapshots/ChannelSnapshotsReview.html Distributed Algorithms Contents Index Global Snapshots: Review Answer these questions to review the webpage on the global snapshot algorithm. What can agents in a distributed operating system do? The global snapshot algorithm uses messages called markers. Are these messages visible to clients of the distributed OS? What is a global snapshot? How is it different from a local snapshot? Show how the global snapshot rule follows from properties of cuts. Consider a system consisting of two agents \(x\) and \(y\) and channels in both directions between them. What is the sequence of actions of the global snapshot algorithm if (i) only \(x\) initiates the algorithm and (ii) both \(x\) and \(y\) initiate the algorithm? Are the snapshots necessarily identical? Necessarily different? Let's look at the system in the previous question. Suppose an invariant of the system is that there is always a message in the channel \((x, y)\). If \(x\) initiates the algorithm and \(y\) takes its local snapshot when it receives a marker from \(x\) then the state of channel \((x, y)\) recorded by the algorithm is the empty sequence. Isn't that an error because the invariant tells us that the state of the channel cannot be the empty sequence? Next logical clocks . K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/LogicalClocks.html ---
TITLE: ChannelSnapshots/LogicalClocksNew.html

ChannelSnapshots/LogicalClocksNew.html Distributed Algorithms Contents Index Logical Clocks A logical clock algorithm assigns a value, called the logical time, to each step in a computation so that all sequences of steps in ascending logical time are computations. The Problem Design an algorithm that assigns a value,  called the logical time , to each step in a computation so that all sequences of steps in ascending logical time are computations. This definition is different from that given in the paper that introduces the concept. How Should You Solve the Problem? Strategy A strategy for assigning attributes to steps in computations is to find a property of computations that can help. We use the following property:    A computation is a sequence of steps in which for all edges \((e, e')\) in the dataflow graph corresponding to the computation: \(e\) occurs before \(e'\) in the sequence. This property suggests the following algorithm to assign logical time \(t(e)\) to step \(e\). The Logical Time Property For all edges \((e, e')\) of the dataflow graph: \(t(e) < t(e')\). Example: Logical Times of Steps Figure 1 shows the dataflow graph of a computation with agents \(A, B, C\) and an step sequence \([0, 1, 2, \ldots, ]\).    The numbers inside the vertices are the step ids which show the position of the step in the computation.    The red numbers outside the steps are logical times assigned to steps. Logical times are arbitrary provided every edge is directed from a lower to a higer logical time. Fig. 1: Logical Times of Steps: Edges Directed from Lower to Higher Logical Times Verify that every edge in figure 1 is from an step with a lower logical time to an step with a higher logical time. Steps in Increasing Order of Logical Time All sequences of steps in increasing order of logical time are computations. This result follows from the fact that all topological sorts of dataflow graphs are computations , and sequences of of steps in increasing logical time are topological sorts. For example, a sequence of steps in increasing logical time in figure 1 is: [1, 2, 4, 3, 5, 6, 7, 8, 9], and this sequence is a computation. A Logical Clock Algorithm The following algorithm is suggested by the logical time property.    Let \(t(e)\) be the logical time assigned to step \(e\).    A message sent in an step \(e\) is assigned a timestamp \(t(e)\). Let \(e'\) be the step immediately preceding an step \(e\) at an agent, and let the timestamp of the message received in \(e\) be \(T\). Set \(t(e)\) to be any value greater than max(t(e'), T). The correctness of the algorithm is self evident. Next Logical clocks are used to record global snapshots as described here. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/LogicalClocksSnapshots.html ---
TITLE: ChannelSnapshots/LogicalClocksSnapshots.html

ChannelSnapshots/LogicalClocksSnapshots.html Distributed Algorithms Contents Index Logical Clocks and Global Snapshots The state at which all agents are at the same logical time \(t\) is a global snapshot.    The state when local physical clocks of all agents are at the same time \(t\) may not be a global snapshot.    Combining physical and logical clocks results in clocks that tick forward and where the state when all local clocks are at the same time is a global snapshot.    Examples of algorithms that use such clocks are given later. Problem: Global Snapshots at Logical Times Design an algorithm that computes global snapshots using logical clocks. How Should You Solve the Problem? Strategy Use properties of logical times and computations. Sequences of steps in increasing logical time are computations.    Therefore, the sequence of steps with logical time at most  \(t\) is a computation, for all  \(t\).    This suggests the following definition of the state at logical time \(t\). State at Logical Time \(t\) The state of an agent \(A\) at logical time \(t\) is its state after steps with logical time \(t\) or less and before steps with logical time greater than \(t\). The state of a channel at logical time \(t\) is the sequence of messages sent along the channel in steps with logical time at most \(t\), but not received in these steps. Example: State at Logical Time \(t\) Figure 1 illustrates the state at logical time 6.5 of the computation shown in figure 1.    The curved purple line represents the cut.    The cut separates the past of the cut from its future.    Past steps are colored black while future steps are colored green.    The states of agents and channels at logical time \(t = 6.5\) are given by the labels of the edges that cut the purple line. Fig. 1: Cut at Logical Time 6.5. Past is Set of Steps with Logical Time at most 6.5 The point at which the purple line cuts the timeline for agent \(A\) can be thought of as the point in \(A\)'s computation at which the logical time is exactly 6.5.    This cut is on the edge from the step at \(A\) with logical time at most 6.5 to the step with logical time greater than 6.5.    In this example the cut is on the edge from step 3 to step 5. The message edge from step 3 to step 7 represents a message sent along the channel from \(A\) to \(B\) in the past that is received in the future.    In this example, the state of the channel \((A, B)\) is the sequence consisting of a single message which is the label of this edge. Global Snapshot Algorithm to Record the State at a Logical Time An algorithm to record the state at logical time \(t\) follows directly from the definition of the state at logical time \(t\). Each agent takes its local snapshot -- i.e. records its state -- after a step with logical time at most \(t\) and before a step with logical time greater than \(t\). An agent records the state of an input channel as the sequence of messages with timestamps atmost \(t\) that the agent receives when its logical clock exceeds \(t\). The purple line in figure 2 represents the global snapshot at logical time 6.5. Using Imperfect Clocks in Distributed Algorithms Intuition We will design some algorithms using logical time to play the role of real time. Figure 3 shows the computation in figure 2 with the horizontal axis representing real time. The position of a step with logical time \(t\) is at a distance of \(t\) units from the origin. Fig. 3: Computation with Logical Time as Real Time Think of logical time as continuous, just as real time is continuous. In this example, points at logical times \(6.5\) and \(6.6\), at agent \(A\), refer to the same edge.    It helps intuition, however, to think of the point at logical time \(6.6\) as a location to the right of the point at logical time \(6.5\) on the same edge.    Imagine that logical time \(6.6\) is 0.1 time units to the right of logical time \(6.5\). The cut at logical time \(6.5\) is represented by the vertical line at time \(6.5\). The left of the line is the past at logical time \(6.5\), and the right side of the line is the future at that time. Physical and Logical Clocks Operating systems maintain clocks. Some have atomic clocks or other high-fidelity clocks that use Precision or Network Time Protocols (PTP, NTP).    With high-fidelity clocks, a message sent when the sender's clock is at \(t\) will almost always be received when the receiver's clock is later than \(t\).    So physical clocks almost always obey the logical clock requirement. We cannot rule out the possibility that a message sent when the sender's clock is at \(t\) is received when the receiver's clock is earlier than \(t\) or equal to \(t\).    We can use physical clocks, but correct them so that messages are received only after they are sent, where the times are determined by corrected physical clocks. Such clocks have the following properties that we use in designing algorithms: Clocks tick forward forever: For all \(t\), there is a point in an infinite computation at which clocks of all agents exceed \(t\). Sequences of steps in ascending order of time are computations. Next The next few pages describe applications of global snapshots. We begin with Termination Detection . K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/TerminationDetection.html ---
TITLE: TerminationDetection

TerminationDetection Distributed Algorithms Contents Index Termination Detection A distributed computation has terminated when all agents are idle and all channels are empty.    A termination detection algorithm is executed by the operating system to determine whether a client computation has terminated. Problem Definition A computation terminates in states in which all channels are empty and all agents are waiting to receive messages.    An agent is said to be active while it is processing a message and idle while it is waiting to process a message.    A terminated state is one in which all agents are idle and all channels are empty. Let \(C_{s}\) and \(C_{r}\) be the numbers of messages sent and received (respectively) on channel \(C\).    A computation is in a terminated state exactly when: All agents are idle and for all channels \(C\):  \(\; C_{s} = C_{r}\). The problem is to design an algorithm that detects whether the computation is in a terminated state. How Should You Solve the Problem? Strategy A strategy to solve detection problems is to start with the general detection algorithm and then explore optimizations by using properties of cuts. Let's explore optimizations. The algorithm detects whether a channel is empty and it can do so given the numbers of messages sent and received on the channel without information about message contents.    What properties of cuts come to mind to help us design an algorithm based on message counts? We use "Cut based on Counts of Messages Sent and Received," which is given again below. There exists a cut (past, future) exactly when the following two conditions hold: For all \(C\):  \(\; C_{s} \geq C_{r}\), where \(C_{s}\) and \(C_{r}\) are the numbers of messages sent and received, respectively, on channel \(C\), in past . If a step \(x\) of an agent is in past then steps at that agent before \(x\) are also in past . The property suggests the following algorithm. A Termination Detection Algorithm Agent Actions When an agent changes state from active to idle the agent sends a message to the observer.    This message contains \(C_{s}\) for each output channel and \(C_{r}\) for each input channel of the agent. Observer Actions The observer keeps only the latest message that it receives from each agent.    For each channel \(C\), let \(C_{s}^{*}\) and \(C_{r}^{*}\) be the latest value of \(C_{s}\) and \(C_{r}\), respectively, that the observer has received. Initial Condition All agents are idle.    \(C_{s}^{*}\) and \(C_{r}^{*}\) are the numbers of messages sent and received (respectively) on channel \(C\) for all \(C\). Termination Detection The observer detects computation has terminated if for all channels \(C\): \(C_{s}^{*} = C_{r}^{*}\). Proof of Correctness We first prove that if the observer detects that the computation has terminated then the computation has indeed terminated. Since the observer has detected termination, for each channel \(C\), either \(C_{s}^{*} = C_{r}^{*}\) initially, or the observer received messages containing \(C_{s}^{*}\) and \(C_{r}^{*}\) such that \(C_{s}^{*} = C_{r}^{*}\). Let (past, future) be a partition of the steps of the computation where past consists of steps at an agent before the agent sent the messages to the observer containing \(C_{s}^{*}\) and \(C_{r}^{*}\) for channels \(C\) incident on the agent. (If the agent sends no messages to the observer then the agent has no steps in past .) From the property, "Cut based on Counts of Messages Sent and Received," (past, future) is a cut. From the definition of terminated state it follows that the state at this cut is a terminated state.    Termination is a stable property -- once computation has terminated it remains terminated.    So, if the state at a cut of the computation is a terminated state then all succeeding states are terminated states. Next we prove that if the computation terminates then the observer detects termination.    The last message sent by each agent has counts \(C_{s}^{*}\) and \(C_{r}^{*}\) of the numbers of messages sent and received (respectively) for each of its output channels \(C\).    Because these are the last messages sent when the algorithm terminates it follows that \(C_{s}^{*} = C_{r}^{*}\) for all \(C\). Next Next database deadlock detection K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/ChannelSnapshots/DatabaseDeadlockDetection.html ---
TITLE: No Title

Distributed Algorithms Contents Index Detecting Database Deadlocks A database deadlock occurs when each agent in a cycle remains waiting forever for a resource held and required by the next agent in the cycle.    A database deadlock detection algorithm is executed by the operating system to determine whether there exists a cycle of deadlocked agents. The Problem The problem described here is a simplification of the database deadlock problem.    The simplification focuses on the essentials of the problem. Agents in a system share a set of indivisible resources.    An example of such a resource is exclusive access to a file. A deadlock arises when there is a cycle of agents, \([x_{0}, x_{1}, \ldots, x_{n-1}, x_{0}]\) where for all \(i\): agent \(x_{i}\) holds a resource \(r_{i}\), and agent \(x_{i}\) requires resources \(r_{i}\) and \(r_{(i+1)}\) to continue executing. (Operations on indices of agents are taken mod \(n\) and \(n > 1\).) Example In the example, a resource is identified by its color.    A system has one red, one blue, and one green resource.    Agents \(x\), \(y\) and \(z\) are deadlocked in the following state. Agent \(x\) requires the red and blue resources to continue executing; \(x\) is holding the red resource and is waiting to acquire the blue resource. Agent \(y\) requires the blue and green resources to continue executing; \(y\) ; is holding the blue resource and is waiting to acquire the green resource. Agent \(z\) requires the green and red resources to continue executing; \(z\) holds the green resource and is waiting to acquire the red resource. Fig.2 - An Example of a Deadlock How Should You Solve the Problem? Strategy A strategy to solve detection problems is to start with the general detection algorithm and then explore optimizations by using properties of cuts. In the general detection algorithm, an observer gets global snapshots and determines if there is a cycle of waiting agents in the snapshot.    Algorithms for determining cycles are found here . Next let's explore optimizations ; see "Detection without Observers: Distributed Algorithms on Local Snapshots."    The optimized algorithm has two phases: (1) First a global snapshot algorithm is executed. (2) After the global snapshot algorithm terminates a distributed detection algorithm is executed on the local snapshots recorded by the global snapshots. The two phases can be merged for some problems, including this one. A Distributed Algorithm to Detect a Cycle of Waiting Agents Multiple detection algorithms and global snapshot algorithms may execute concurrently.    These algorithms are disambiguated by tagging each algorithm with the initiator and a sequence id.    Next we describe a single detection algorithm which is executed after a single global snapshot algorithm terminates. Local Constants In the detection algorithm, each agent v has the following local constants: v.waits is the set of resources that v has to acquire from other agents to start execution. v.holds is the set of resources that v holds and must continue to hold to start execution. Example In the example of the figure: x.waits = {blue}, x.holds = {red} y.waits = {green}, y.holds = {blue} z.waits = {red}, y.holds = {green} v.waits and v.holds are constant for all v in the detection algorithm  because these values are specified in the global snapshot. Messages The algorithm to detect waiting cycles is similar to the global snapshot algorithm.    Instead of the marker message used in global snapshots, a message in the detection identifies the set of resources for which the sender of the message is waiting. Each message m sent by an agent v has a field m.waits where: m.waits = v.waits . Initiating the Algorithm A waiting agent u initiates the algorithm by sending a message m on each of its output channels where m.waits = u.waits . Action by an Agent other than the Initiator When an agent v receives a message m : If v has already sent messages then v takes no action. If v has not sent messages, and if there is a resource common to m.waits and v.holds then v sends a  message m' on each of its output channels where m'.waits = v.waits . Cycle Detection If the initiator u receives a message m where there is a resource common to m.waits and u.holds then u detects a cycle of waiting agents. Proof of Correctness The proof outline is as follows.    An agent v sends messages only if there is a path of waiting processes from u to v .    So, u detects a cycle of waiting processes only if there exists a cycle of waiting processes. If there exists a cycle of waiting processes from u to u then messages are sent along one such cycle, and so u detects a cycle. The algorithm terminates because it sends at most one message on each channel. Example This example shows steps in the case of the cycle of waiting processes shown in figure 2.    The algorithm is initiated by agent x by broadcasting a message m where m.waits = x.waits = {blue} . When y receives a message m where m.waits = {blue} , there is a resource in both m.waits and y.holds , and so y broadcasts message m' where m'.waits = y.waits = {green} . When z receives a message m where m.waits = {blue} , z takes no action because there is no resource in both m.waits and z.holds . When z receives a message m where m.waits = {green} , z broadcasts message m' where m'.waits = z.waits = {red} . When the initiator x receives a message m where m.waits = {red} , x detects a deadlock because there is a resource common to m.waits and x.holds . Combining Cycle Detection and Snapshot Algorithms We can use a a marker in the snapshot algorithm as a message in cycle detection.    Modify a marker m to have the field m.waits used in cycle detection.    Then the snapshot algorithm is the same as the cycle detection algorithm except that the snapshot algorithm records states of channels which are not used in cycle detection. Write the algorithm for the combined algorithm as an exercise. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Paxos/ConsensusImpossible.html ---
TITLE: Paxos/ConsensusImpossible.html

Paxos/ConsensusImpossible.html Distributed Algorithms Contents Index Consensus Central Ideas (1) Importance of consensus (2) Impossibility of consensus in distributed systems with a faulty agent. Importance of Consensus Algorithms by which groups of agents come to a consensus are among the most fundamental problems in distributed computing. Why is consensus important? There are many problems in which messages are sent to groups of agents who collectively maintain a common consensus state. A bank may use a group of agents, rather than a single agent, to maintain bank balances. Multiple agents reduce the possibility of system-wide failure due to the failure of a single agent.  Managing replicated databases requires the replications to come to a consensus on the sequence of transactions that is applied to the database. Cryptocurrency transactions also require collections of agents to come to a consensus about sequences of the transactions. In a control system with multiple and actuators, the actuators have to come to a consensus about the state of the environment so that they can operate in concert. A vehicle would crash if some actuators caused the vehicle to accelerate while other actuators applied brakes.  In some applications, multiple agents have to elect a single leader. There are many problems in which a collection of agents have to come to a consensus about something. Consensus: Impossible with a faulty agent Consensus is impossible with even a single faulty agent. This was proved in a paper published by Fischer, Lynch and Patterson. You can get the idea of why consensus is not possible by considering the following problem in which when message delays are finite but arbitrarily long. A collection of 2N + 1 agents want to come to a consensus about a color. N of the agents pick blue and N+1 pick red. One of the red agents is arbitrarily slow. The 2N non-slow agents exchange messages among each other, and each of these 2N agents gets N votes for red and N votes for blue. Agents decide to take a majority vote, and in the event of a tie pick blue. Fig.1: Problem with a slow agent How long should they wait for the slow agent? Consider an algorithm in which agent waits until its local clock shows an elapsed time of T and then makes a decision based on the votes that it has.  An agent Y gets N red and N blue votes when its clock shows an elapsed time of T, and agent Y decides that the consensus is blue. Another agent Z has a slower clock and gets a red vote from the slow agent for a total of N+1 red votes, before Z's clock shows an elapsed time of T. So Z determines that the consensus is red. The algorithm fails because Y and Z have not come to a consensus. No algorithm is guaranteed to come to a consensus in finite time if messages can be arbitrarily slow or if agents can be arbitrarily slow. Systems with synchronized clocks don't have this particular problem. We'll look at consensus in such systems later. Best Effort Consensus The theorem says that there is no algorithm that guarentees that consensus can be reached in all scenarios; however, consensus can be reached in most practical situations. An idea to overcome the counterexample given above is: Agents keep trying repeatedly until they reach consensus. The theorem tells us that the agents may have to keep trying for ever. We expect, however, that in most practical situations their attempts will succeed at some point. What does keep trying mean? When does one trial end and the next one begin? If agents use timeouts to end a trial, then --- because clocks aren't synchronized --- the timeouts may complete at different times. We'll see that we can use the idea of time, even though clocks aren't synchronized. We've done that before with logical clocks. The Paxos algorithm shows how the idea of increasing values of timestamps (or ids) are used for best-effort consensus. Central Ideas: Review Many applications of distributed systems require agents to come to a consensus. Agents cannot come to a consensus if an agent is faulty. Concepts : Consensus -> impossibility with faulty agents Next Next look at Paxos an important consensus algorithm that may not terminate. Later look at Byzantine consensus and consensus using block chain . K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Paxos/ReadWriteLossyChannels.html ---
TITLE: Paxos/ReadWriteLossyChannels.html

Paxos/ReadWriteLossyChannels.html Distributed Algorithms Contents Index Serializable Computations in Faulty Systems In this webpage we develop algorithms for systems in which agents may halt or be arbitrarily slow, the same message may be delivered multiple times, messages may be delivered out of order, and messages may be lost.    A transaction consists of two steps: a client reads and the writes shared variables.    This page shows how a proxy for time can be used to develop algorithms in which computations can be serialized: each agent starts and completes a transaction before executing steps of another transaction. Overview In this webpage we develop algorithms for systems in which agents may halt or be arbitrarily slow, the same message may be delivered multiple times, messages may be delivered out of order, and messages may be lost. A system consists of a set of agents called clients and a set of agents called servers .    There is a channel from each server to each client, and from each client to each server. Clients execute transactions in which they send requests to servers to read and then write variables managed by servers.    We describe an algorithm in which computations are serializable which allows us to treat the sequences of steps at each agent as though exactly one transaction is executed at a time. Servers Each server q has a variable q.v .    Clients send requests to q to read or write q.v .    The only actions of a server are to respond to requests from clients. A server q replies to a read request from a client p by sending p a copy of q.v .    A write request includes the value v to be written.    A server q assigns v to q.v when q receives a write request containing value v . Clients Each client receives a sequence of clock tick messages.    The intervals between successive clock ticks are irrelevant for the correctness of the algorithm.    The intervals do, however, impact performance.    There are many ways of generating clock tick messages and we postpone discussion of them. A read request and a reply to the request may get lost or be delayed for an arbitrary time.    A client avoids waiting forever for a reply by only accepting replies that the client receives before it receives its next clock tick message.    Replies that arrive after the next clock tick are treated as lost. A transaction consists of a read step and a write step. Read Step of a Transaction A client p sends read requests to all servers.    Some requests may be lost.    A server that receives a read request from p sends a reply to p .    Some replies may be lost.    Let R be the set of servers from which p receives replies before p receives its next clock tick. If R has M or more elements, where M is a given constant, then p proceeds to the write step.    If R has fewer than M elements, then the transaction terminates without executing the write step. Write Step of a Transaction The list of replies that p gets before p receives its next clock tick is: [q.v for q in R] Client p sends a request to all servers to write: p.f(q.v for q in R) where p.f is a function of p . Write requests may get lost.    Let W be the set of servers that receive write requests. A transaction consists of the step in which a client p broadcasts read requests to all servers, the steps in which servers receive read requests and send replies, the steps in which p receives replies, the step in which p sends write requests, and the steps in which servers receive and execute write requests. Changes to server variables in a transaction are specified by the following statement in which p.f is a function executed by p . Transaction if len(R) >= M: for q in W: q.v = p.f(q.v for q in R) Transactions are tailored to a specific application by specifying M and p.f .    The selections of R and W are nondeterministic and they can be arbitrary sets of servers. Transactions executed concurrently by multiple clients can interfere with each other as illustrated by the following example. Example Let x be the amount of funds in an account and assume that x has $110.    Consider a computation in which clients p and p' both execute identical transactions concurrently.    In a transaction a client reads x and if x has at least $100 then the client transfers $100 out of x to an account y . Consider a computation in which both clients p and p' read x and verify that x has at least $100, and then both clients transfer $100 out of x and set the amount in x to $10.    The computation transfers $200 out of x but debits x by only $100. This situation does not occur if only one client executes a transaction at a time.    If p executes its transaction first then when p completes the transaction it sets the amount in x to $10. If p' executes its transaction next then p' finds that x has only $10 and so p' does not transfer $100 from x . Serializable Computations A system executes multiple transactions concurrently. A computation \(x\) is serializable exactly when there exists a sequence of transactions \(Z_{i}, i \geq 0\), such that in  \(x\): For all agents \(v\), for all \(i\): all steps of \(v\) in \(Z_{i}\) occur before any step of \(v\) in \(Z_{i+1}\). It is possible that in a serializable computation \(x\), an agent \(u\) takes a step in \(Z_{j}\) before a different agent \(v\) takes a step in \(Z_{i}\), where \(j > i\). Transactions and Serializability in Databases There is an extensive literature on transactions and serializability. Also see transaction processing systems and online transaction processing . In this webpage we provide a narrow definition of transactions and serializability that is adequate for describing algorithms such as Paxos . The Problem: Guarantee Serializability The problem is to develop a distributed algorithm, with multiple clients and servers, in which computations are serializable, and in which the system may be faulty. How Should You Solve The Problem? What method comes to mind to partition the sequence of steps at an agent into intervals where the agent completes all steps of exactly one transaction in each interval? Logical time partitions computations into a past and a future.    Let's use a mechanism, similar to logical time.    As with logical time, each step \(e\) in a computation is assigned a value \(t(e)\), called the epoch of \(e\). For any step \(e\), steps with epochs less than, equal to, or greater than, \(t(e)\) are in the past, current , and future, respectively. We specify epochs such that the steps in current consists of all the steps of exactly one transaction. Epochs and Logical Times Recall that the logical time of a step \(e\) is a value \(t(e)\) assigned to each step \(e\) in a computation such that for all edges \((e, e')\) of the dataflow graph: \(t(e) < t(e')\).    The epoch of a step \(e\) in a computation is defined as a value \(t(e)\) assigned to each step \(e\) in the computation such that for all edges \((e, e')\) of the dataflow graph: \(t(e) \leq t(e')\). Rules for Assigning Epochs to Steps The following rules ensure that the assignment \(t(e)\) to each step \(e\) in a computation satisfies the specification for epochs. For all steps \((e, e')\) of a computation for all steps \(e\) and \(e'\) at the same agent: if \(e'\) occurs after \(e\) then \(t(e) \leq t(e')\), and if \(e\) is a step in which a message is sent and \(e'\) is a step in which that message is received then \(t(e) \leq t(e')\). Observation If \(e\) and \(e'\) are steps at the same agent and \(t(e) < t(e')\) then \(e'\) occurs after \(e\). Theorem: A Sufficent Condition for Serializability A sufficient conditions for a computation to be serializable is: There exists epochs for all steps of a computation such that each transaction has a unique epoch, and all steps in a transaction have the epoch of the transaction. If a computation \(x\) satisfies this condition then let the epochs of transactions in \(x\) be \([T_{0}, T_{1}, T_{2}, \ldots]\) where \(T_{i} < T_{i+1}\), and let \(Z_{i}\) be the transaction with epoch \(T_{i}\). Then in \(x\), for all \(i\), for all agents \(v\): All steps of \(v\) in \(Z_{i}\) occur before any step of \(v\) in \(Z_{i+1}\). Proof Assume that the sufficient condition is satisfied for epochs of steps in a computation.    Let \(e\) and \(e'\) be steps in transactions with epoch \(T\) and \(T'\), respectively, and let \(T < T'\).    Let \(e\) and \(e'\) be steps at the same agent \(v\).    From the observation regarding epochs: \(e\) occurs before \(e'\).    Therefore all steps of a transaction with epoch \(T_{i}\) occur before any step of a transaction with epoch \(T_{i+1}\). An Algorithm Based on the Sufficent Condition Next, we describe an algorithm based on this idea.    Let's consider the two issues posed by the condition for serializability.    (1) How can the algorithm assign a unique epoch to each transaction?    (2) How can the algorithm assign epochs to steps so that all steps in a transaction have the epoch of the transaction? Uniqueness of a Transaction's Epoch A client p initiates a new transaction when p gets a clock tick message.    To ensure that the epoch of the transaction is unique, an  epoch t is a pair (n, p_id) where n is a number and p_id is the id of client p .    Transactions initiated by different clients have different epochs because their client ids are different.    A client sets the epoch of a new transaction that it initiates to be greater than epochs of all previous transactions that it initiated.    So, different transactions initiated by the same client have different epochs.    Therefore each epoch is unique. Client ids are totally ordered, and so epochs are also totally ordered.    For brevity we refer to an epoch by a single value t rather than a pair (n, p_id) . All Steps in a Transaction have the Transaction's Epoch We associate a field t with each agent -- client or server -- where t is the epoch of the step of the transaction that the agent is executing.    Likewise, we associate a field m.t with each message m between clients and servers where m.t is the epoch of the step in which the message is sent. A message sent in a step of a transaction is received in a step of the same transaction.    So, for a message m between clients and servers, m.t is also the epoch of the step in which the message is received. We design the algorithm so that all steps of a transaction, all messages sent in steps of the transaction, and all messages received in steps of the transaction have the epoch of the transaction. Next we give the algorithm for clients and then for servers. Algorithm for a Client When a client p gets a clock tick message it executes p.t = p.t + pos() where pos returns a positive value, and then p initiates a new transaction with epoch p.t .    Client p continues executing the transaction with epoch p.t until p gets its next clock tick message at which point it increases p.t and starts a new transaction. In the algorithm all steps of p , all requests sent by p to clients, and all replies received by p from clients, have epoch p.t . # Initialization p.t = 0    start() def receive(message, sender): if isinstance(message, ClockTick): # Received clock tick p.t = p.t + pos() # Start new transaction with epoch p.t # p.copy stores values in replies. p.copy = {} # Broadcast read request with epoch p.t for q in Q:  send(ReadRequest(p.t), q)    else: # received a reply to a read request if message.t == p.t: p.copy[sender] = message.v # send write requests if M replies received if len(p.copy) >= M: # Broadcast write request: value v, epoch t v, t = p.f(), p.t for q in Q: send(WriteRequest(v, t), q) Algorithm for a Server A server waits to get requests from clients. When a server q receives a request r from the transaction that the server is currently processing i.e. r.t \(=\) q.t , then the server responds to the request. When a server q receives a request r from a transaction with a smaller epoch than the transaction that the server is currently processing, i.e. r.t \(<\) q.t , then the server does not respond to the request. The request has the same effect as a request that is lost. What should server q do when it receives a request r from a transaction with a larger epoch than the server's epoch, i.e. r.t \(>\) q.t ? In this case, the server increases its epoch to the epoch of the request and then responds to the request.    The request, the step in which the server responds to the request, and the reply (to a read request), have the same epoch. # initialization q.v, q.t = init, 0    start() def receive(request, client): if request.t >= q.t q.t = request.t if isinstance(request, ReadRequest): send(Reply(q.v, q.t), client) else: // message is a WriteRequest q.v = request.v Correctness Next we prove that all computations are serializable in a system specified by these algorithms for clients and servers. Epoch of a step in a computation of the algorithm The epoch of a step taken by a client p or server q is the value of p.t or q.t (respectively) upon completion of the step. Theorem The assignment of epochs to steps satisfies the condition for epochs, i.e., For all steps \((e, e')\) of a computation if \(e\) and \(e'\) are steps at the same agent, and \(e'\) occurs after \(e\) then \(t(e) \leq t(e')\), and if \(e\) is a step in which a message is sent and \(e'\) is a step in which that message is received then \(t(e) \leq t(e')\). Proof From the algorithms for server p and client q it follows that p.t and q.t do not decrease in a computation.    Therefore the first condition is satisfied. Also, from the algorithm, the epoch for step in which a request or reply is received is equal to the epoch in which the message is sent.    So, the second condition is also satisfied.    Therefore the assignment of epochs to steps of a computation satisfy the specification of epochs. Theorem The sufficient condition for serializability is satisfied: (1) each transaction has a unique epoch, and (2) all steps in a transaction have the epoch of the transaction. Proof We have shown that each transaction initiated by a client p has a unique epoch p.t . All steps at p have epoch p.t .    Requests sent by p have epoch p.t .    When a client q gets a request with epoch p.t , the client  sets its own epoch to p.t and sends a reply with the same epoch.    So, all steps in a transaction have the epoch of the transaction.    Therefore the algorithm satisfies the sufficient condition for serializability. Corollary The algorithm satisfies specifications for serializability. Proof Follows because the algorithm satisfies the sufficient condition for serializability. Therefore, if the epochs of transactions in a computation \(x\) are \([T_{0}, T_{1}, T_{2}, \ldots]\) where \(T_{i} < T_{i+1}\), then in \(x\), for all \(i\), for all agents \(v\):    All steps of \(v\) in the transaction with epoch \(T_{i}\) occur before any step of \(v\) in the transaction with epoch \(T_{i+1}\). Equivalence of Distributed and Sequential Algorithms Let the sequence of increasing epochs in a computation \(x\) of the distributed algorithm be T[1], T[2], T[3], ... , and let p[i], R[i], W[i] be the values of p, R, W in the transaction with epoch T[i] . The sequence of values of agent variables in computation \(x\) of the distributed algorithm is the same as in the following nondeterministic sequential program by selecting p, R, W , on the i -th iteration to be p[i], R[i], W[i] respectively, and by selecting delta on the i -th iteration so that T[i] = T[i-1] + delta Equivalent nondeterministic sequential algorithm t = 0 while True: select positive delta, select client p t = t + delta    # p executes transaction with epoch t p.t = t p.copy = {}    # Read step select R for q in R: p.copy[q] = q.v    # Write step if len(p.copy) >= M: select W for q in W: q.v = p.f() We will prove properties of the sequential algorithm and show that these properties also hold for the distributed algorithm. Next Next we develop Paxos, a distributed consensus algorithm. We prove that Paxos satisfies the specifications for consensus by showing that Paxos is serializable. We prove properties of a nondeterministic sequential algorithm and show that properties of the sequential algorithm also hold for Paxos. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Paxos/StableMajority.html ---
TITLE: Paxos/StableMajority.html

Paxos/StableMajority.html Distributed Algorithms Contents Index Paxos: Consensus in Faulty Systems Algorithms by which agents reach a consensus on a value are central in many applications.    Paxos is an algorithm by which agents attempt to reach a consensus in distributed systems in which agents may halt, be arbitrarily slow, and messages may be duplicated, lost, and delivered out of order.    In this page we describe and prove a nondeterministic sequential representation of Paxos, and describe the distributed algorithm in the next page. Introduction Paxos is a consensus algorithm for systems in which messages may be lost; multiple copies of a message may be delivered; messages may not be delivered in the order sent; agents may be arbitrarily slow; and agents may stop.    From the FLP theorem ,    there is no algorithm that guarantees that consensus among agents will be reached in such systems.    Paxos may not terminate; however, if it does terminate then a consensus will have been reached at termination.    We will discuss ways to improve the likelihood that the algorithm does terminate. Consider the problem of maintaining a ledger consisting of a sequence of transfers of funds into and out of accounts.    To prevent a single point of failure the ledger may be implemented using copies at multiple agents.    The copies may not be synchronized; however, for a ledger to be useful there must exist a consensus.    We call the sequence of operations on the ledger a chain of operations and we call the the consensus value a consensus chain . Suppose two clients simultaneously request extensions to a consensus chain by transferring funds from an account x to two different accounts.    Account x may not have funds to allow both transfers, and so the consensus chain can be extended by at most one of the transfers.    Clearly, the system must maintain a consensus about the sequence of operations in the chain. Agents that propose extensions to consensus chains are called clients .    Copies of the chain are stored at agents called servers .    Clients determine consensus chains and propose extensions to the chains.    The system determines a consensus among proposals for extended chains. Before giving the specification of consensus we review the concept of prefix of a sequence. Notation: prefix of a sequence A prefix of a sequence S is an initial subsequence of S. For example, [A, B] is a prefix of [A, B, C] but [A, C] is not a prefix of [A, B, C]. The empty sequence is a prefix of all sequences. A sequence is a prefix of itself.    We use the notation \(\leq\) for prefix, as in: [A, B] \(\leq \) [A, B, C] Specification of Consensus 1. A consensus isn't changed. For all \(c\) and \(d\), if \(c\) is a consensus chain at any point in a computation and \(d\) is a consensus chain at a later point in the computation then \(c\) is a prefix of \(d\). Example For example, a consensus chain [A, B] can be extended to form a consensus chain [A, B, C], but [A, B] cannot be extended to form [A, C, B]. Chains [A, B] and [A, B, C] can both be consensus chains in the same computation; however, [A, B] and [A, C, B] cannot both be consensus chains in the same computation. 2. Every consensus chain is proposed by a client For all consensus chains \(c\) in a computation: There exists a client that proposed \(c\) in the computation. This part of the specification merely says that consensus chains cannot be arbitrary.    A client uses the algorithm to determine chain \(c\) that is a consensus of the servers and then proposes an extension to \(c\). The algorithm then reaches a consensus about extensions to \(c\) proposed by clients; the extensions must be proposed by clients.    Later, we define this part of the specification in terms of algorithm variables. A Nondeterministic Sequential Consensus Algorithm We will develop a consensus algorithm for the system described in the previous page Serializable Computations in Faulty Systems. A system has a sets of agents called servers and clients.    Each server q has a local variable q.v .    A client executes a transaction in which the client sends requests to each server q to read q.v ; waits to receive replies; then sends write requests to servers.    Read the previous page for details. A transaction is executed by exactly one client.    Client p sends read requests and gets replies from a set R of servers.    If R has at least M elements then p sends write requests to all servers asking each server q to assign p.f() to q.v . Some write requests may be lost. Let W be the set of servers that receive the write requests. The design of the distributed consensus algorithm is based on this key result. For each agent, the sequence of values of the agent in the distributed algorithm described in the previous page is the same as in an equivalent nondeterministic sequential algorithm. We now prove properties of the values of servers in the equivalent sequential algorithm; these properties also hold for the distributed algorithm.    The equivalent sequential program from the previous page is given below. The selections of delta, p, R, W in each iteration of the algorithm are nondeterministic. Equivalent Nondeterministic Sequential Algorithm t = 0 while True: select positive delta, select client p t = t + delta    # p executes transaction with epoch t p.t = t p.copy = {}    # Read step select R for q in R: p.copy[q] = q.v    # Write step if len(p.copy) >= M: select W for q in W: q.v = p.f() The Problem The problem is to define consensus in terms of variables of the sequential algorithm and specify parameters M and f of the algorithm so that the specification for consensus is satisfied. How Should You Solve The Problem? When is Consensus Reached? Let's assume that a consensus is reached when a sufficiently large number of servers write the same value in a transaction.    Equivalently, consensus is reached when the set W of servers that write the same value in an iteration of the sequential algorithm is large enough, and a consensus is the value written by all servers in W . How large is enough? We could require that W be the set of all servers, but then consensus is reached in an iteration only if write requests reach all servers.    The smaller the size of W required for consensus, the greater the likelihood of consensus being reached. A reasonable design choice is that W is a majority of servers.    Let N be the number of servers. A consensus is reached at the end of an iteration in which W is a majority of servers. Tagging assignments with the epochs in which they were assigned We need some mechanism to determine which servers were written in the same iteration, and which were written earlier.    So, we make variable q.v have two fields, (q.v.s, q.v.t) where q.v.s is the chain at q.v and q.v.t is the epoch in which q.v.s was assigned its value. In the sequential algorithm we replace the assignment step q.v = p.f() by q.v.s, q.v.t = p.f(), p.t We make the same change the distributed algorithm, replacing the following assignment in the algorithm for client p v, t = p.f(), p.t by v.s, v.t, t = p.f(), p.t, p.t A consensus is reached when the set W of servers in an iteration is a majority.    For all q in this majority, q.v.t is the epoch of the iteration.    Therefore, consensus is determined as follows: Consensus: Majority of Servers Agree on a Consensus Value s* is a consensus chain in a computation of seq if during the computation there exists a majority W* of servers and an epoch t* where: For all q in W* : (q.v.s = s*) and (q.v.t = t*) Specifying M : The Number of Replies Required to Proceed A client needs to receive at least M copies of chains to proceed to the write step.    What is a reasonable value of M ? The smaller the value of M the greater the likelihood of proceeding to the write step.    Again, a reasonable design choice is to require that the client receive replies from a majority of servers.    If that choice doesn't work we will try a larger value of M . A client must receive replies from a majority of servers to proceed to the write step. Specifying p.f : The Values to be Written Consider a single iteration of seq .    If R is not a majority then the iteration terminates without modifying server values.    Now we consider the case in which R is a majority.    We design the function so that it returns an extension to a consensus chain.    Consider two cases. Case 1: All replies are identical. Let each element q.v in R be s*, t* .    Because R is a majority of servers, from the definition of consensus it follows that s* is a consensus chain. A client proposes an extension of a consensus chain, So p.f returns the consensus, s* , appended with p.h() where p.h() is the extension proposed by p . Case 2: Not all replies are identical. p.f returns q*.v.s where q*.v is the reply with the largest epoch. The algorithm is given below. def p.f(): values_read = list(p.copy.values())    if all(values_read[0] == v for v in values_read): # All elements of values_read are identical # consensus is any element of values_read. consensus = values_read[0].s return consensus.append(h())    else: # Not all elements of values_read are identical # Compute max_v, the element with largest v.t max_v = values_read[0] for v in values_read: if v.t > max_v.t:  max_v = v return max_v.s Correctness of the Nondeterministic Sequential Algorithm Observation Part 2 of the specification -- every consensus chain is proposed by a client -- follows directly from the algorithm because the only assignment to q.v.s is p.f() . Next,  we prove part 1. We will show that if c is a consensus chain after an iteration and d is a consensus chain after a later iteration then c is a prefix of d . Theorem: The Sequential Algorithm is Correct Let s* be a consensus at some point in a computation of the sequential program.    Then, there exists a majority W* of servers and an epoch t* where: For all q in W*: (q.v.s = s*) and (q.v.t = t*) Let the iteration that executes the transaction with epoch t* be the n* -th iteration.    Because each assignment to q.v increases q.v.t we get the following. Equation 1 At the end of the n -th iteration, for all q in W* : For all n \(\geq\) n* : \(\quad\) q.v.t \(\geq\) t* For all n \(<\) n* : \(\quad\) q.v.t \(<\) t* Next we will prove that s* is a prefix of any assignment to any server variable in any iteration after iteration n* . This can be written as: at all points in the computation, : At all points in the computation, for all servers q : ( q.v.t \(<\) t* ) \(\; \vee \;\) ( s* \(\leq\) q.v.s ) Proof of the Invariant Base Case: n -th Iteration where n \(\leq\) n* The condition trivially holds for iteration n where n \(<\) n* because, from equation 1: q.v.t \(<\) t* . Next, consider the case where n \(=\) n* . If q.v is modified in the iteration then q.v.s \(=\) s* .    If q.v is not modified in the iteration then q.v.t \(<\) t* . Induction Step Assume that the condition holds before iteration n for n \(>\) n* and show that it holds after the iteration. From equation 1 and the induction hypothesis, the following holds before iteration n . For all q in W*: ( q.v.t \(\geq\) t* ) \(\; \wedge \; \) ( s* \(\leq\) q.v.s ) In any iteration, server variables are modified only if R is a majority of servers.    Any two majorities have at least one element in common. So there is an element that is in both R and W* .    Let this element be q* .    Because q* is an element of W* : ( q*.v.t \(\geq\) t* ) \(\: \wedge \;\) ( s* \(\leq\) q*.v.s ) This gives us the following: Equation 2 There exists a q* in R such that: ( q*.v.t \(\geq\) t* ) \(\: \wedge \;\) ( s* \(\leq\) q*.v.s ) Let d be the value returned by function p.f .    Consider the statements in p.f and two cases. Case 1: All values q.v for q in R are identical. In this case, from equation 2: For all q in R : s* \(\leq\) q.v.s . In function p.f , consensus is assigned q.v.s for some q in R . Therefore, s* \(\leq\) consensus . The function returns d = consensus.append(h()) . Therefore s* \(\leq\) d . Case 2: Not all values q.v for q in R are identical. The function returns q'.v.t where q' is in R and: For all q in R : \(\quad\) q'.v.t \(\geq\) q.v.t From equation 2: q'.v.t \(\geq\) q*.v.t \(\geq\) t* From the induction hypothesis, and q'.v.t \(\geq\) t* , it follows that s* \(\leq\) q'.v.t . Therefore s* \(\leq\) d . This completes the proof of the invariant. We have shown that s* is a prefix of all assignments made to server variables after iteration n* . Therefore, s* is a prefix of all consensus values reached in iterations after iteration n* . The Distributed Algorithm is Correct We showed the equivalence of the distributed and nondeterministic sequential algorithm: For every computation \(c\) of the distributed algorithm there exists a computation \(c'\) of the nondeterministic sequential algorithm -- with appropriate choices of nondeterministic selections -- such that for all servers q the sequence of values of q.v is the same in \(c\) and \(c'\). Therefore properties of the sequence of values of q.v for each server q in the sequential algorithm are also properties in the distributed algorithm. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/SelfStabilization/SelfStabilization.html ---
TITLE: SelfStabilization/SelfStabilization.html

SelfStabilization/SelfStabilization.html Distributed Algorithms Contents Index Self Stabilization: Mutual Exclusion in a Ring Self Stabilization This module describes one example of a self-stabilization system --- a system that recovers automatically from transient errors. A self stabilizing system recovers automatically from transient errors. If a self-stabilizing system enters an unsafe state then the system will correct itself and eventually enter a safe state. The literature on self stabilization is extensive. Let's look at one example of a self-stabilizing system to get an idea of its design. Self Stabilizing Token Passing A ring of agents passes a single token around the ring. An agent that holds the token knows that no other agent has the token at that point. So, the system can be used to implement mutual exclusion. Examples of errors are the disappearance of the single token and the creation of additional tokens. A self stabilizing algorithm ensures that eventually the system gets back to a safe state, i.e., one in which it has exactly one token. Let's begin with a model in which each agent in the ring can read the state of its predecessor in the ring. Later, we will modify the algorithm to work with message-passing. \(N\) agents, indexed \(j\), are organized in a ring where agent \((j+1) \: \textrm{mod} \: N\) can read the state of agent \(j\). Hereafter, we will not write "\(\textrm{mod} \; N\);" it is to be understood. An agent is either idle or active . The system is required to have exactly one active process. The active process can be thought of as having the single token in the system.  The token is passed from agent \(j\) to agent \(j+1\) when agent \(j\) becomes idle and agent \(j+1\) becomes active. For convenience in visualizing diagrams, let's assume that the state of an agent is a color. Next we describe the basic algorithm that assumes that errors do not occur; later we will modify the algorithm to obtain a self-stabilizing algorithm that recover from errors. The Algorithm The algorithm for agent \(0\) is different from that of the other agents. Agent \(0\) has the token exactly when its color is the same as that of its predecessor. Any other agent holds the token exactly when its color is different from that of its predecessor. An agent \(j\) passes the token to agent \(j+1\) when agent \(j\) changes its color. Agent \(0\) has the token when all the agents in the ring have the same color. The diagram below illustrates an example with 4 agents where an agent's color is either red or blue. The diagram shows how the token is passed from each agent to its sucessor. In the figure on the top left, all the agents are red; so agent 0 has the token. When agent 0 changes its color we get the diagram at the top center. In this diagram, agent 0 is blue and all the other agents are red. Agent 0 no longer has the token because its color is different from that of its predecessor; however agent 1 does have the token because its color is different from that of its predecessor. The sequence of diagrams shows what happens when the agent holding the token --- which is the only active agent --- changes its color. Fig.1: The token is passed by an agent changing color Faults Let's look at the state of a system after a fault occurs.  The next set of diagrams shows how errors --- once they occur --- can propagate for ever.  These diagrams show a system with three tokens whereas an error-free system should have exactly one.  The three agents holding tokens are shown with large yellow numbers and the agent that does not hold a token is shown with a smaller black number. Fig.2: Errors can propagate forever The figure on the top left of the above diagram shows agents 1, 2 and 3 with tokens because their colors are different from those of their predecessors. The next diagram, top right, shows agents 1 and 3 with tokens because their colors are different from those of their predecessors, and agent 0 with a token because its color is the same as that of its predecessor. The transition to the diagram on the top right from the one on the top left occurs when agent 3 changes its color. The sequence of state transitions gets the system to the figure on the bottom left which is the same as that on the top left with the colors reversed. This cycle of state transitions can repeat forever, with the same system always having three tokens. So, this system is not self stabilizing. A Self-Stabilizing Algorithm The solution: add more colors! We will modify the design to have as many colors as there are agents. In our example, we will have 4 colors because it has 4 agents. The algorithms for all agents, other than agent 0, remains unchanged. As before agent 0 has the token when its color is the same as that of its predecessor and agent 0 sends the token by changing agent 0's color. The difference in the self-stabilizing algorithm is the color to which agent 0 transits. Assume that the 4 colors are numbered 0, 1, 2, 3. If agent 0's color is \(k\) it makes a transition by changing its color to \(k \: \textrm{mod} \: N\). The diagram below gives an example of how agent 0's color changes. Its sequence of colors, 0, 1, 2, 3 are red, blue, green, yellow, respectively. The diagram on the top left shows a configuration in which agent 0 holds a token because its color (green --- number 2) is the same as that of its predecessor. Agent 0 passes the token by changing its color to 3 (yellow), as show on the diagram on the top right. The diagram in the middle left shows agent 0 with a token. It passes the token by changing its color from 1 (blue) to 2 (green), as shown in the diagram in the middle right. Fig.3: Changes in color of agent 0 Proof The proof has the following three ideas that we first describe informally. In all states at least one agent holds a token. All trajectories from all states lead to a state in which agent 0 holds a token. A trajectory from a system state in which agent 0's color is different from that of the other agents leads to a state in which all agents have the same color (in which case the system is in a safe state). Part 1 If all agents have the same color then agent 0 holds a token. If there is more than one color in the ring then there is at least one agent, other than agent 0, whose color is different from that of its predecessor's; so, that agent holds a token. Part 2 Agent 0 and agent \(n-1\) will get the same color at some point because agent 0's color will propagate all the way around the ring unless it gets to agent \(n-1\) sooner. Part 3 If agent 0's color is different from the colors of agents \(1, \ldots, n-1\) then the only trajectory that leads to agents 0 and agent \(n-1\) having the same color is for agent 0's color to propagate all the way around the ring. The system always reaches a safe state Let \(S\) be any state. Let the \(C\) be the set of agent colors in state \(S\). If \(C\) has all \(N\) colors, then the color of agent \(0\) is different from the colors of the other agents, and so the result follows from part 3. If \(C\) has fewer than \(N\) colors then the color of each agent remains a color in \(C\) until agent 0 gets a color that is not in \(C\). At this point agent 0's color is different from that of the other agents and the result follows. Review In this algorithm, does any agent detect that the system is in an unsafe state? Can we determine that the system is in an unsafe state based solely on the state of any one agent and the state of its predecessor? Why? Will this algorithm work if the number of colors is arbitrarily large, and more than the number of agents? Why? Will this algorithm work if the number of colors is less than the number of agents? Why? K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Byzantine/ByzantineWritten.html ---
TITLE: Byzantine/ByzantineWritten.html

Byzantine/ByzantineWritten.html Distributed Algorithms Contents Index Byzantine Consensus: Written Messages This module introduces Byzantine consensus algorithms in which agents reach consensus in a sequence of synchronized rounds even though some agents don't follow the protocol . In this module we study algorithms by which a collection of agents reach a consensus among alternative values. The Paxos algorithm is an example of how agents reach consensus. Agents cannot reach consensus if message delays or agent operations are arbitrarily slow. Next, we study a consensus algorithm in which message delays are bounded and in which agents are guaranteed to come to a consensus even though some agents do not follow the protocol. The algorithm operates in a sequence of steps called rounds . All messages sent in a round are delivered in the next round. Agents execute actions in each round after receiving messages sent in the previous round; these actions may include sending messages. So, the Byzantine algorithm is synchronous. Byzantine Generals Problem: Overview A general has \(N\) army units each of which is led by a lieutenant general, herafter referred to merely as lieutenant. We refer to the general and the lieutenants, collectively, as agents. An agent may be either loyal or disloyal. A loyal general gives the same command to all lieutenants. A loyal general's command is either attack or retreat .  A disloyal general may give different commands to different lieutenants and may give no commands to some. The lieutenants receive commands from the general and then communicate among themselves to reach a consensus.  Loyal lieutenants follow an algorithm while disloyal lieutenants may or may not. The figure below illustrates the difference between loyal and disloyal generals. Fig.1: Loyal and disloyal general behavior Byzantine Generals Problem: Specification A loyal general sends attack messages to all lieutenants or sends retreat messages to all lieutenants.    A disloyal general sends arbitrary messages to lieutenants. Validity : Loyal lieutenants must obey a loyal general. If a loyal general gives the command to attack then all loyal lieutenants must attack. Likewise, if a loyal general gives the command to retreat then all loyal lieutenants must retreat. Consensus : Loyal lieutenants come to a consensus: either all of them attack or all of them retreat. The specification does not require that traitors be discovered. For example, the algorithm doesn't have to determine whether the general or a lieutenant is loyal or disloyal. If the only requirement is validity, and consensus isn't required, then the solution is trivial: all loyal lieutenants obey the general whether the general is loyal or disloyal. If the only requirement is consensus then the solution is trivial: all loyal lieutenants agree on a predefined value, say retreat, regardless of the command issued by the general. The conjunction of both requirements makes the problem difficult. Oral and Written Messages There are two versions of the problem. Written Messages : In this version an agent may send copies of messages that it receives to other agents but cannot modify the messages. Also, an agent cannot forge signatures. So, an agent can receive a message M signed by lieutenant \(A\) only if \(A\) sent M to some agent. Oral Messages : In this version an agent can modify messages and forge signatures.So, an agent can receive a message M signed by agent \(A\) even if \(A\) never sent M to any agent. The algorithm for written messages is simpler and requires fewer messages. Algorithm with Written Messages A reliable lieutenant who does not get a message from in round 0 treats the absence of the message as the same as receiving a retreat message. Likewise, if a loyal lieutenant gets a message that is not an attack or a retreat message then the lieutenant treats the message as a retreat message.    (We use retreat as a default. We could just as well have used attack as the default.) Next, we give an overview of the algorithm. Commit to Attack At each round in the algorithm, a loyal lieutenant has either committed to attack or not.    A lieutenant that has not committed to attack on a round may commit to attack on a later round.    If any loyal lieutenant commits to attack in any round then it remains committed to attack thereafter. A loyal lieutenant retreats if it has not committed to attack at the end of the last round. Messages A message is an attack message from the general or a commitment to attack by a lieutenant. We call commitment messages attack messages. An attack message is identified by the agent (general or lieutenant) that created the message. Evidence for Attack A loyal lieutenant commits to attack on round \(r \geq 1 \), for the first time, if the lieutenant has received an attack message from the general and at least \(r - 1\) lieutenants. When the lieutenant commits to attack it sends copies of these messages, and its own attack message, to all other lieutenants. So, in round \(r+1\), each lieutenant receives an attack messages from the general and at least \(r\) lieutenants. And so, all loyal lieutenants commit to attack in this round. The Algorithm We will use the tactic that is helpful in analyzing distributed algorithms that operate in rounds. We will prove properties of a sequential algorithm and then show the equivalence of the sequential and distributed algorithms. The sequential algorithm is given next. Local Variables Associated with each lieutenant C are local variables C.received and C.sent which are sets of agents (general or lieutenants). C.received is the set of agents from which C has received attack messages (or their copies). C sends attack messages (or copies) from agents in C.sent .    The symbol g represents the general. Initialization: Round 0 A.sent = {} for all lieutenants A . If the general is loyal and sends attack messages then the set of agents from which a lieutenant has received attack messages is the singleton set consisting of the general. So, for all lieutenants A : A.received = {g} If the general is loyal and sends retreat messages then for all lieutenants A : A.received = {} If the general is disloyal, then A.received = {g} for some lieutenants A , and A.received = {} for the others. The algorithm operates in a sequence of rounds with round-number r stepping from 1 to t+1 . The r -th iteration for loyal agent c consists of the following two steps. Round r > 0 Step 1 if (|C.received| >= r) AND  (g in C.received): C.commit = True C.sent = C.received UNION {C} If C.received has messages that show that:  (1) the number of agents that have committed to attack on round r is at least r , and (2) the general has sent an attack message, then C commits to attack and sends these messages as well as an additional message that C has committed to attack. Step 2 C.received = ( (UNION over all loyal agents B of B.sent) UNION an arbitrary subset of disloyal agents) C receives the messages sent by loyal lieutenants and messages sent by disloyal lieutenants.    A disloyal lieutenant, A , can send messages to some lieutenants that A is committed to attack, and not send these messages to other lieutenants.    Lieutenant C receives attack messages from an arbitrary subset of disloyal lieutenants. Lieutenant C does not know which agents are loyal and which are disloyal. C.received is the set of all messages sent to C regardless of whether the senders are loyal or disloyal. Proof of Correctness Case 1: General is loyal and sends attack messages In this case, at the start round 1, C.received = {g} .    So, the if-clause in step 1 of round 1 is True, and therefore all loyal lieutenants commit to attack at the end of round 1. Case 2: General is loyal and sends retreat messages A disloyal lieutenant cannot forge the general's signature, and so it is impossible for any lieutenant to have a copy of an attack message from the general. Therefore the if-clause of step 1 is never satisfied, and so no loyal lieutenant commits to attack in any step. Case 3: General is disloyal Part 1 We first show that if any loyal lieutenant commits on round r then all loyal lieutenants commit by the end of round r+1 . A loyal lieutenant C commits on round r exactly when the set C.received has at least r attack messages including one from the general. So, in round r , C.sent has at least r+1 attack messages including one from the general. Therefore, the if-clause of step 1 evaluates to True in round r+1 , and so all loyal lieutenants commit by the end of round r+1 . Therefore, if any loyal lieutenant commits by the end of round t-1 then all loyal lieutenants commit by the end of round t . Part 2 We next show that if no loyal lieutenant has committed by the end of round t-1 then no loyal lieutenant commits in round t . C.sent = {} at the end of round t-1 if no loyal lieutenant has committed to attack. Therefore in round t , C.received is an arbitrary subset of disloyal lieutenants. There are at most t-1 disloyal lieutenants because there are at most t disloyal agents, and the general is disloyal. So, on round t , the if-clause of step 1 evaluates to False. Part 3 From parts 1 and 2, by the end of round t , either all loyal lieutenants commit, or no loyal lieutenant commits. Example The figure below illustrates a situation in which a loyal lieutenant C commits to attack on round 3, if it hasn't already committed to attack on rounds 1 and 2. The figure shows C getting attack messages (red boxes) signed by the general and lieutenants A and B on round 2. The general and lieutenants A and B may be disloyal or loyal. Fig.2: Example of a lieutenant committing to attack Because C is loyal it follows the algorithm, and C commits to attack at the end of round 3 because C receives a signed attack message from the general and signed attack messages from two different lieutenants. So, in round 3, C broadcasts copies of attack messages signed by the general and attack messages signed by A and B and attack messages, and also an attack message signed by C itself. All loyal lieutenants commit to attack in round 4 because they receive attack messages signed by the general and 3 different lieutenants (A, B, C). Review Assume that you are explaining the algorithm to someone who hasn't taken a course on distributed computing. How would you explain to this person that even if the general and 999 lieutenants are disloyal, and only 2 lieutenants are loyal, the loyal lieutenants reach a consensus after round 100? (Remember the first round is round 0.) Will the algorithm work if at most one lieutenant could modify written messages, and all the other lieutenants followed the protocol, i.e. these lieutenants could copy but not modify messages. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Byzantine/ByzantineOral.html ---
TITLE: Byzantine/ByzantineOral.html

Byzantine/ByzantineOral.html Distributed Algorithms Contents Index Byzantine Consensus: Oral Messages This module describes a Byzantine consensus algorithm in which messages are not encrypted. An agent x that receives a message signed by an agent y cannot tell whether y signed the message or whether some other agent forged y 's signature and corrupted the message. This module describes solutions to the Byzantine problem with oral messages whereas the previous module studied the problem with written messages.  For convenience we repeat the problem specification next. An agent is a general or a lieutenant. An agent may be loyal or disloyal. Let \(N\) be the number of agents and \(t\) the number of disloyal agents.    The general sends a command to each lieutenant where the command is either attack or retreat. A loyal general sends the same command to all lieutenants whereas a disloyal general may send different commands to different lieutenants. Each lieutenant decides to attack or retreat at the end of the algorithm. If all loyal lieutenants get the same command then each loyal lieutenant obeys the commands that it received; if the command is attack then each loyal lieutenant attacks, and if the command is retreat then each loyal lieutenant retreats. Even if loyal lieutenants receive different commands, all loyal lieutenants make the same the decision; either all loyal lieutenants attack or all loyal lieutenants retreat. Notation We use indices \(i, j, k\) for loyal agents; \(x, y\) for generic agents who may be loyal or disloyal; and \(e\) for disloyal agents. Nothing in an agent's id or data identifies the agent as loyal or disloyal. Moreover, the algorithm does not have to discover which agents act disloyally. For a nonempty list \(L\), we use the Python notation \(L_{*}\) to refer the last element of the list. For example, if \(L = [5, 6]\), then \(L_{*} = 6\). For a list \(L\) and an element \(x\), the notation \(L , x\) represents a list consisting of \(x\) appended to the tail of \(L\). For example, if \(L\) is the list \([1, 2]\) then \(L , 3\) is the list \([1, 2, 3]\), and \(L, 3, 4\) is the list \([1, 2, 3, 4]\). The general is the agent with index \(0\), and the lieutenants have indices \(1, \ldots, N-1\). Let \(m[x]\) be the message that the general sends lieutenant \(x\), and let \(a[x]\) be the decision the lieutenant \(x\) makes. Specification The specification has two parts, validity and consensus. Validity: Loyal lieutenants obey a loyal general. If all loyal lieutenants get the same message then each loyal lieutenant obeys the message that it receives. \( (\forall i, j: m[i] = m[j]) \quad \Rightarrow \quad (\forall i: a[i] = m[i]) \) Consensus: Loyal lieutenants make the same decision. \( \forall i, j: a[i] = a[j] \) Assumptions The oral Byzantine version makes fewer assumptions than the written version. The assumptions made are as follows: Synchrony: The algorithm operates in a synchronous fashion in a sequence of rounds or synchronous steps. If an agent \(x\) does not send a message to an agent \(y\) in a given round then \(y\) can detect that \(x\) did not send a message to it in that round. Reliability: If an agent \(y\) sends a message \(m\) to an agent \(y\) in a given round then \(z\) receives \(m\) in that round. Receiver knows sender: An agent that receives a message knows which agent sent it. If an agent \(z\) receives a message \(m\) from an agent \(y\) in a round then \(z\) knows that \(y\) sent \(m\) in that round. Why oral messages are harder In the written version of the problem, if an agent \(z\) receives a message \(m\) from any agent where \(m\) is signed by the general then \(z\) knows that the general did send \(m\). An agent cannot forge the general's signature and send a false message. By contrast, in the oral, or unencrypted version, any agent can forge any agent's signature and send corrupted messages. Byzantine Generals Algorithm Messages in the algorithm are either attack or retreat messages.  If an agent \(x\) does not receive a message from an agent \(y\) on a round then \(x\) treats the absence of the message from \(y\) in the same way as if \(x\) received a retreat message from \(y\). So, the algorithm only deals with attack and retreat messages and does not deal with steps that an agent takes if it does not receive a message. First we describe the flow of message in the algorithm and then describe the algorithm Message Flow Messages flow along a tree of height \(t + 1\).    The root node is \(m[0]\) which represents the general's command. Each node of the tree is of the form \(m[L]\) where \(L[0] = 0\) and \(L[1, \ldots, ]\) is a list of lieutenants where each lieutenant appears at most once. The next figure illustrates a part of the messaging tree for \(N = 7, t = 2\). (There is insufficient space to show the complete tree.) Fig.1: A Part of the Message Tree for General and 6 Lieutenants Each non-leaf node \(m[L]\) in the tree has a child \(m[L, x]\) for each lieutenant \(x\) that is not in \(L\). For example, \(m[0]\) has children \(m[0,1], m[0,2], \ldots, m[0, N-1]\). \(m[0,x]\) is the message that lieutenant \(x\) receives from the general. \(m[0, x_{0}, \ldots, x_{k}]\) is the message that lieutenant \(x_{0}\) receives from the general and forwards to lieutenant \(x_{1}\), ... which in turn forwards the message to lieutenant \(x_{n-1}\), which in turn forwards the message to lieutenant \(x_{n}\). If the general is loyal then it sends the same message to all lieutenants: \(m[0,x] = m[0]\) for all \(x\). Loyal lieutenants forward the messages that they receive; however, disloyal lieutenants may send arbitrary messages. Example The diagram below shows a situation in which the general is loyal and sends attack messages to all lieutenants. Lieutenant 1 is disloyal (shown as a dashed circle). Lieutenant 1 sends retreat messages to some lieutenants and attack messages to others. Lieutenant 2 is loyal, and so it broadcasts the message that it receives. Fig.2: Edges Aggregation Dataflow Trees Aggregating Phase Messages received by a lieutenant are processed by the lieutenant in steps that are also represented by a tree called the aggregation tree . The aggregation tree has a node \(a[L]\) for each node \(m[L]\) of the message tree. The diagram below shows a part of the aggregation tree for \(N=7, t=2\); these are the processing steps of lieutenant 1. Fig.3: Aggregation Tree: Steps for Lieutenant 1 Each node \(a[L, i]\) of the tree has a child \(a[L, x, i]\) for each \(x\) that is not in \([L, i]\). For example, \(a[0, 1]\) has children \(a[0, 2, 1], a[0, 3, 1], \ldots a[0, 6, 1]\). Connections from Messaging to Aggregating Nodes There is an edge directed from each message node \(m(L)\) to the aggregation node \(a(L)\). For example, there are edges from \(m[2, 3, 1]\) to \(a[2, 3, 1]\), and from \(m[2, 1]\) to \(a[2, 1]\), and from  \(m[1]\) to \(a[1]\). Output of Aggregating Nodes The output of an aggregation node is the majority of its inputs. For example: \( a[2, 1] = \textrm{majority}(m[2, 1], a[2, 3, 1], a[2, 4, 1], \ldots, a[2, 6, 1]) \) If there are an equal number of attack and retreat inputs, then the majority value is defined to be any default value. Example The next diagram shows the data flow -- messaging and aggregation trees, and the connections between them -- for a system where \(N=4, t=1\). Fig.4: Dataflow for 4 agents 1 of which is disloyal Inductive Generation of the Data Flow The basic unit of data flow, which is replicated many times, is shown in the top diagram of the figure below. The input to the unit is a node \(m[L]\) of the message tree; this unit is specified by \(L\),and the message \(m[L]\). The output of the unit are nodes \(a[L, x]\) of the aggregation tree, for all lieutenants \(x\) not in \(L\). The base case of the induction is a node at depth \(t\). The input for the base case is \(m[L]\) where \(L\) is a list starting with \(0\) and followed by \(t\) lieutenants. For the base case, \(a[L, x] = m[L, x]\) for all \(x\). The base case is illustrated in the lower diagram. Fig.5: Structure of Dataflow The data flow connecting a message node \(m[L]\) at depth \(d < t\) to aggregation nodes \(a[L,x]\) is shown below. Fig.6: Structure of Dataflow Message node \(m[L]\) feeds message nodes \(m[L,x]\). The connections between \(m[L,x]\) and aggregation nodes \(a[L,x,y]\) are specified by the data flow connecting nodes of depth \(d + 1\), shown in the diagram by blue dotted lines. The value of an aggregation node is the majority of its inputs. \( a[L,i] = \textrm{majority}(m[L,i], [\forall x \notin [L, i]: a[L, x, i]]) \) For example, \( a[0, 1, 2] = \textrm{majority}(m[0,1,2], a[0, 1, 3, 2], a[0, 1, 4, 2], a[0, 1, 5, 2], \ldots) \) Proof of Validity We prove that for all nodes \(m[L]\) of the message tree, if \(L_{*}\) is loyal then for all \(i\) not in \(L\): \( a[L, i] = m[L] \) The proof is by induction. The base case is for message nodes at depth \(t\). We prove that if validity holds for message nodes at depth \(d > 0\) then it holds for message nodes at depth \(d-1\). Base Case See the lower diagram of figure 5. For a message node \(m[L]\) at depth \(t\), \( a[L, i] = m[L, i] \) If \(L_{*}\) is loyal then \(m[L, i] = m[L]\). and the result follows. Inductive Step See figure 6. A node \(L\) at depth \(d\) consists of \(d+1\) agents. Therefore, there are at least \(3t+1 - (d+1)\) lieutenants that are not in \(L\). Because \(d \leq t\) there are at least \(2t\) not in \(L\). So, at least \(t\) lieutenants not in \(L\) are loyal and at most \(t\) of them are disloyal. Because \(L_{*}\) is loyal, \(m[L,i] = m[L]\). By the induction assumption, for each loyal lieutenant \(j\) not in \(L\), and for each loyal lieutenant \(i\) not in \([L, j]\): \( a[L, j, i] = m[L, i] = m[L] \) \( a[L, i] = \textrm{majority}(m[L,i], [\forall j \notin [L, i]: a[L, j, i]]) \) The majority is taken over at least \(t + 1\) values equal to \(m[L]\), and at most \(t\) values that are different from it. And therefore \(a[L, i] = m[L]\) Example The next illustrates the proof of validity. Message \(m[L]\) is shown in red, and the flow of correct messages is shown in red edges and red nodes. For example, nodes \(m[L, i], m[L, j], m[L, i, j], m[L, j, i]\) are red because agents \(i, j\) are loyal. A disloyal agent is represented by the symbol \(e\). The output of a disloyal agent is unknown and is shown in black. Node \(a[l. i]\) gets more than \(2t\) red inputs and at most \(t\) black inputs, and hence the majority of its inputs is red. Fig.7: Illustration of Validity Proof of Consensus We will prove consensus for nodes at depth \(d\) if the number of faulty nodes is at most \(t-d\). Base Case \(d = t\) In this case there are no disloyal lieutenants. For each \(i, j\), \(m[L,i]\) and \(m[L,j]\) are arbitrary; however \(m[L, i] = m[L, j]\). \(a[L, i, j] = m[L, i]\) and \(a[L, j, i] = m[L, j]\). Therefore the inputs to \(a[L,i]\) and to \(a[L,j]\) are identical and the result follows. Inductive Step \(d < t\) If the general is loyal, then consensus follows from validity. There are at most \(t - d\) faulty nodes. If the general is disloyal then there at most \(t-d-1 = t -(d+1)\) disloyal lieutenants. Therefore, the induction assumption holds for \(m[L, x]\). Therefore \(a[L, i, k] = a[L, i, j]\) K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Crypto/CryptoCurrencyIntroduction.html ---
TITLE: Crypto/CryptoCurrencyIntroduction.html

Crypto/CryptoCurrencyIntroduction.html Distributed Algorithms Contents Index Cryptography: Introduction Bitcoin Introduction to Cryptography for Cryptocurrency This module contains a review of elementary cryptographic operations and introduces a simple cryptocurrency managed by a trusted agent. The next module discusses the algorithm underlying Bitcoin; the Bitcoin algorithm doesn't require agents to be trusted. This Princeton University book is a superb description of Bitcoin. Review: Cryptographic Hash Function A  hash function, \(H\), maps input strings of arbitrary size to outputs of fixed size. Collision Resistance Input values \(x, y\) of a hash function \(H\) are said to collide when \(H(x) = H(y)\). A hash function \(H\) is said to be collision resistant if the only known ways of finding collisions using the hash are intractable. Let's look at the following problem: Given \(H\), find any colliding pair \(x, y\). Consider a hash function \(H\) that outputs \(n\)-bit numbers and whose input is \(m\) bit strings. As a specific example lets assume that \(m\) is a large number and \(n = 4\). We can find a collision in the following way. Let \(D\) be an array of size \(2^{n} = 16\). Initially \(D\) contains null values. Repeat the following iteration until a collision is found. Pick a random input \(x\). If \(D[H(x)]\) is null then set \(D[H(x)] = x\) else there is a collision between \(H(x)\) and \(x\). By the pigeon-hole principle, we will find a collision in at most \(2^{n} + 1 = 17\) iterations.    This  brute-force algorithm uses space \(2^{n}\) and finds a collision in at most  \(2^{n} + 1\) steps.    From the Birthday Paradox a collision will be found with high probability in \(2^{n/2}\) iterations though the worse-case time is \(2^{n}+1\). If \(n = 256\) then a collision will be found with high probability in \(2^{128}\) iterations; however, executing \(2^{128}\) steps is still intractable. For \(H\) to be collision resistant the output of \(H\) must be \(n\)-bits for large \(n\). For example \(n = 256\) in the SHA-256 hash function. Commitment using Hashes You bet that your soccer friend, Megan, cannot predict the winner of the 2022 World Cup. Megan puts the name of the predicted winner, \(W\), in an envelope and gives it to a trusted third party. After the World Cup is over, the third party reveals Megan's prediction, and at that point you can find out whether Megan's prediction was accurate. The trusted third party provides two services: Hiding : You can't find out Megan's prediction until the third party reveals it. Binding : Megan can't change her prediction after giving it to the third party. Can we use a hash function instead of a trusted third party? Hiding Let's try the following idea. Megan commits to \(W\) in the following way. She announces a hash function, \(H\), and the hash, \(y\), where \(y = H(W)\). You know \(H\) and \(y\). After the World Cup is over, she reveals her prediction, \(W\). At this point you can verify that \(y = H(W)\). Does the hash function provide the services of the third party? Can you discover Megan's prediction before she reveals it? It's easy. There are only 32 teams playing. Compute \(H(x)\) where \(x\) runs over each of the 32 teams. One of those teams has to be \(W\). You can discover her prediction in at most 210 steps. Let's try another algorithm.  Megan selects a secret value \(r\) which she keeps to herself. Instead of giving you \(H(W)\), she gives you \(y\) where \(y = H(r + W)\) and where \(+\) indicates concatenation of strings. Can you discover \(W\) from \(H\) and \(y\) without knowing \(r\)? A brute-force solution is to try every combination of \(r\) and \(W\). If \(r\) is obtained from a distribution that is spread out, then finding \(W\) without knowing \(r\)  take so much time that it is practically impossible. Hiding: Given \(H, y\), where \(y = H(r + W)\) and \(r\) is a secret, discovering \(W\) is intractable. Binding Does the hash function \(H\) and the secret \(r\) provide both services of the trusted third party? Is Megan bound to her prediction or can she change her "prediction" after knowing the winner of the World Cup? Suppose Megan has values \(r\) and \(r'\) such that H(r + 'Brazil') = H(r' + 'Italy'). After the World Cup is over, she can announce that her secret is \(r\) if Brazil wins, and announce that it is \(r'\) if Italy wins. A hash function \(H\) is binding if finding pairs \((x,y)\) and \((x',y')\) where \(y \neq y'\) such that: \(H(x + y) = H(x' + y')\) is intractable. Suppose you give Megan a hash function that is binding. Then she cannot find (in reasonable time) values \(r_{j}\) to match country \(C_{j}\) such that \(H(r_{0} + C_{0}) = H(r_{1} + C_{1})  = H(r_{2} + C_{2})  = \ldots\). and so she can't wait for the winner \(C_{j}\) to be announced before announcing her secret \(r_{j}\). In summary, we can use a hash function that is hiding and binding to play the role of a trusted third party in a commitment. Puzzle Friendly The concept of puzzle friendly is related to hiding . Let \(r\) be a value picked from a spread-out distribution. Let \(H\) map arbitrary length strings to \(n\)-bit strings. Consider the following problem: Given \(H\), \(r\), and an \(n\)-bit value \(y\), compute any \(x\) such that \(H(r+x) = y\). In this problem, as opposed to the hiding problem, we are given \(r\) and not \(x\), The hash function \(H\) is said to be puzzle friendly exactly when any algorithm to solve this problem is about as slow as a brute-force algorithm which checks \(H(r+x) = y\) for random values of \(x\). The number of steps taken by any algorithm that solves this problem is not significantly lower than \(2^{n}\). Now, let's look at the following related problem.  Given \(H\), \(r\), and a set \(Y\) of \(n\)-bit strings, compute any \(x\) such that \(H(r+x) \in Y\).  If \(Y\) consists of a single element \(y\) then this problem is the same as that in the previous paragraph.  If \(Y\) is a set of all \(n\)-bit strings then this problem is trivial because any \(x\) solves the problem.  The probability that a random value hashes to an element of \(Y\) is proportional to the cardinality of \(Y\).  The cardinality of \(Y\) controls the expected time to solve the puzzle. The hash function \(H\) is puzzle friendly when given \(H\), \(r\), and a set \(Y\) of \(n\)-bit values, the time required to compute any \(x\) such that \(H(r+x) \in Y\) is not significantly lower than \(2^{n} / |Y|\), where \(|Y|\) is the cardinality of \(Y\). A Cryptographic Hash Function A cryptographic hash function is one that is collision resistant, hiding and puzzle-friendly. Hashing Inputs of Arbitrary Length Let \(f\) be a function that operates on input strings of fixed length and produces output strings of fixed length. Let the input and output strings of \(f\) have lengths \(M + N\) and \(M\), respectively. We look at functions where \(N > 0\), and since the output is smaller than the input, \(f\) is called a compression function. We can use function \(f\) to define a function \(g\) whose inputs are strings of arbitrary lengths and whose outputs are strings of length \(M\). Example code for \(g\) is given below where InitialValue is a given constant string of length \(M\). def g(y): output = InitialValue    // pad y so that it's length is a multiple of N if len(y)%N > 0:  y = y + "0"*(N - len(y)%N)    // partition y into blocks of size N blocks = [y[i: i+N] for i in range(0, len(y), N)]    // Apply function f to the concatenation of the // previous output (length M) with each block // (length N) to get the next output (length M). for block in blocks: output = f(output+block) return output Hash Pointers A hash pointer to an item \(D\) of data is a pair \((ptr, H(D))\) where \(ptr\) is a pointer that points to \(D\), and \(H\) is a cryptographic hash function. Any data structure with pointers can be converted into a data structure with hash pointers: merely replace a pointer \(ptr\) to \(D\) by \((ptr, H(D))\). Tamper-Evident Data Structures Single Block A simple example of a tamper-evident structure is a single block of data D which is pointed to by a hash pointer consisting of a regular pointer and a hash H(D). Fig.1: Hash Pointer points to a Tamper-Evident Block of Data Assume that a malicious agent cannot modify both the hash pointer and the data that it points to. If an agent changes D to D' then the tampering can be discovered because the hash pointer won't match the data that it is pointing to: \(H(D') \neq H(D)\). Tamper-Evident Linked List Let's look at linear linked list to which elements can be appended but not deleted. The \(i\)-th element appended to the list points to the \((i-1)\)-th element. Let's replace the pointers in the list by hashed pointers. Fig.2: Hash Pointer points to a Tamper-Evident List of Data The \(j\)-th element of the list, \(j > 0\), consists of data, \(D_{j}\), and a hash pointer that points to the \(j - 1\)-th element of the list. The hash pointer in the \(j\)-th element consists of a regular pointer, \(ptr_{j}\), which points to the \(j - 1\)-th element of the list, and a hashed value, \(HA_{j}\), which is a cryptographic hash of the entire \(j-1\)th element consisting  of \(D_{j-1}\), \(ptr_{j-1}\) and \(HA_{j-1}\).    The \(0\)-th element is called the genesis element and has default values. The list is accessed by a hash pointer that points to the last element of the list; let this pointer be \(ptr_{n}, HA_{n}\). Assume that agents cannot modify \(ptr_{n}, HA_{n}\). Then, can any agent determine whether the list has been tampered with? Suppose the agent modifies \(D_{j}\), \(ptr_{j}\) or \(HA_{j}\) for any \(j < n\). Any agent can detect this tampering because the hash value \(HA_{j+1}\) will no longer match the \(j\)-th element of the list. If the malicious agent also modifies \(HA_{j+1}\) then hash value \(HA_{j+2}\) will no longer match the \(j+1\)-th element. By induction on \(j\), any agent can detect tampering with the list provided malicious agents do not also modify the hash pointer to the last element of the last. Tamper-Evident Acyclic Graphs and Merkle Trees The idea described in the previous paragraph to convert linear linked lists can be used to convert directed acyclic graphs, in which nodes are connected by pointers, into tamper-evident graphs. A specific case of a directed acyclic graph is a rooted tree. A Merkle tree is a special case of a binary balanced tree in which data items are stored only in the leaves. Nodes that are not leaves contain only hash pointers to nodes in the next level down. To prove that an element at the leaf is a member of the tree we need only the \(log_{2}(n)\) hash pointers on the path from the root to that leaf. By contrast, to prove that an element is a member of a linear list we need to inspect \(O(n)\) elements, on average. Keys and Signed Messages You can create a random public-key, private-key pair by calling a function on your computer. With high probability, nobody else has this specific pair of keys. Each individual's private key is a secret held by that individual. Public keys are accessible by everybody. Sending messages securely Keys are used to send messages securely. Kamala sends a secure message to Joe by encrypting the message with Joe's public key; Joe decrypts the message using Joe's private key. An agent cannot decrypt the encrypted message without Joe's private key. Signing messages Suppose Kamala needs to send a signed message to Joe while ensuring that nobody can forge her signature. She encrypts the message M with her private key to get an encrypted message M' , and sends the pair (M, M') securely to Joe, i.e., she encrypts (M, M') with Joe's public key, and sends the resulting encrypted message to Joe.  When Joe receives the message, Joe decrypts it using his private key to get (M, M') . Then Joe decrypts M' using Kamala's public key to get the decrypted message M'' . If M'' = M then Joe knows that Kamala sent M because only an agent with Kamala's private signature could have sent that message. Cryptocurrency Managed by a Trusted Agent Let's start with a digital currency managed by a trusted agent that we will call a bank. Later, we will look at a consensus algorithm --- very different from Paxos and Byzantine Generals --- which will allow cryptocurrencies without trusted agent. The bank maintains a tamper-evident linear list L of transactions that we call a tamper-evident ledger . Any agent can get a copy of the ledger. This tamper-evident ledger is the foundation of the currency. A transaction is one of two types: create or pay . In a pay transaction, payers give coins that they possess to payees . An agent can be both a payer and payee of the same transaction. In a create transaction the bank creates coins that it gives to agents --- the payees of the transaction; the bank acts as the payer. For this system to be trusted the bank must follow some protocol that determines how and when the bank creates coins. We won't discuss these protocols. A pay transaction is signed by all payers of the transaction. A create transaction is signed by the bank. We discussed digital signatures and keys earlier. Each element of the tamper-evident ledger has: a unique id; the type of the transaction, either create or pay; list of payers : only for pay transactions --- a list indicating the agents who pay coins into the transaction and the amounts that they put in; array of value-payee pairs : for both create and pay transactions --- an array of pairs (value, payee public key) , where each pair in the array indicates that coins of the specified value are given to the payee with the specified public key. Example of a create transaction An example of a create transaction is: (3146, create,  [(2.1, 7xxxx...), (3.2, 8xxxx)]). The id of this transaction is 3146, the type of the transaction is create, and the array of value-payee pairs is [(2.1, 7xxxx...), (3.2, 8xxx)] In this transaction the bank creates a coin of value 2.1 and gives it to the agent with public key 7xxxx..., and the bank also creates a coin of value 3.2 and gives it to the agent with public key 8xxxx... The pair: (transaction id, index into array of value-payee pairs) uniquely identifies a (value, payee) tuple. For example (3146, 0) --- transaction id 3146, and array index 0 --- identifies value-payee[0] of transaction 3146 which is specified by the 2-tuple: (2.1, 7xxxx...). So, the transaction id and index, (3146, 0), tells everybody that the agent with public key 7xxxx received 2.1 units of coin in transaction 3146. When this transaction is in a tamper-evident ledger, every agent from that point onwards knows that agent 7xxxx received 2.1 coins. Any modifications of this record can be detected. Likewise, (3146, 1) --- transaction id 3146, and array index 1 --- identifies value-payee[1] which is the 2-tuple (3.2, 8xxxx...). Pay transaction Coins are transferred from payers to payees in a pay transaction. Coins flowing into a pay transaction from payers The payers are identified by a list of 2-tuples, where each 2-tuple is (transaction id, index into array of value-payee pairs) where transaction id is the id of the transaction in the tamper-evident ledger. As we said earlier, this pair uniquely identifies an agent and a value that this agent acquired in this transaction. For example the pair --- transaction id, index --- such as (3146, 0) identifies the 2-tuple (2.1, 7xxxx...); this 2-tuple asserts that the agent with public key 7xxxx received 2.1 units of coin in transaction 3146. The entire amount specified in the 2-tuple (2.1 in our example) is value that flows into this pay transaction from the agent with public key 7xxxx. Suppose the payers in a pay transaction are identified by the list: [(3146, 0), (7359, 3)] and suppose pair 3 in transaction 7359 is (3.2, 8xxxx). Then the total amount of coins flowing into this pay transaction is 2.1 + 3.2, and this amount is disbursed to payees. Fig.3: Coins flowing into and out of a pay transaction. Coins flowing out of a pay transaction to payees The outflow of coins is specified by an array of value-payee pairs, exactly as in a create transaction. The transaction clears all coins: the total inflow from payers is equal to the total outflow to payees in a transaction. The system may provide incentives, such as payment of coins, to managers (e.g. banks) of cryptocurrencies. In this case, one of the payees is the bank itself. Managing amounts spent in a transaction A transaction-id, index pair --- such as (3146, 0) identifies a 2-tuple such as (2.1, 7xxxx...); this 2-tuple asserts that the agent with public key 7xxxx received 2.1 units of coin in transaction 3146. The entire amount specified in the 2-tuple (2.1 in our example) is value that flows into the transaction. What should this agent do if it wants to put in more than 2.1 coins into the transaction? Or less than 2.1 coins? To put in more value, the bank identifies other transaction-id, index pairs in which this agent received coins. For example, say that (4539, 2) identifies a 2-tuple (3.2, 7xxxx), and assume that the payers in this transaction are specified by the pairs (3146, 0) and (4539, 2). The pair (3146, 0) asserts that agent (7xxxx) received 2.1 coins and the pair (4539, 2) asserts that the same agent received 3.2 coins. So the total amount of coins flowing into this transaction from this agent (7xxxx) includes 2.1 + 3.2. To put in less value, the agent acts as both payer and payee; the net value that this agent pays out to other agents is the difference between the amount that this agent puts in and takes out. For example, if agent with public key 7xxxx wants to put in 1.9 coins into this transaction its payer information can be given by the transaction-id, index pair (3146, 0) which asserts that the agent received 2.1 coins and the same agent is a payee that withdraws 0.2 coins. Preventing Double Spending How does the system prevent an agent from using the same coin twice? For example, the transaction id, index pair (3146, 0) identifies the 2-tuple (2.1, 7xxxx...); this tuple asserts that the agent with public key 7xxxx received 2.1 units of coin in transaction 3146. Why can't the agent with public key 7xxxx use the 2.1 coins that it received to buy items from Amazon and later use the same 2.1 coins to buy more items from Walmart? The bank checks that the agent hasn't already spent the coin that it is putting into a transaction. Before permitting the transaction that double-spends the 2.1 coins with Walmart, the bank inspects the tamper-evident ledger for all transactions after transaction 3146 and before the Walmart transaction to ensure that the agent (7xxxx) hasn't already spent the 2.1 coins that it got in transaction 3146. The transaction that spends the coins at Amazon will show up in the ledger, and so the transaction with Walmart will not be allowed. Every agent that has the bank's hash pointer to the end of the tamper-evident ledger can inspect the ledger to check that double-spending hasn't occurred. The bank signs a valid transaction and appends it to the tamper-evident ledger. All agents can see the bank's signature and verify that nobody (not even the bank) has tampered with the tamper-evident ledger. Example of a pay transaction An example of the specification of a pay transaction is: (9431, pay, [(3146, 0), (4731, 2)], [(0.7, 7xxxx...), (4.6, 9xxxx...)] ). The id of this transaction is 9431; the type of the transaction is pay; the payers into the transaction are identified by the pairs of (transaction-id, index): (3146, 0), and (4731, 2); and the payee array is [(0.7, 7xxxx...), (4.6, 9xxxx...)]. Transaction validity The bank appends a transaction to L if and only if the transaction is valid. The bank checks for validity by carrying out the following steps: The bank verifies that the payers into the transaction signed the transaction. The bank checks that the total value of coins paid out from the transaction does not exceed the total value paid in to the transaction. (If the value paid in exceeds the value paid out then the bank takes the difference as a transaction fee. More about fees later.) The bank verifies that the payers' claims to have received coins in previous transactions is genuine. For example, if the agent with public key 7xxxx... claims to have received coins worth 2.1 in the transaction with id 10, and payee array index 0, then the bank verifies this claim by that transaction. The bank ensures that coins paid into the transaction haven't already been spent. Optimizations: Blocks and Block Chain Verifying large numbers of small transactions requires more computation than verifying small numbers of blocks of many transactions. A block chain is a tamper-evident ledger in which each element of the ledger is a block consisting of many transactions. A block of transactions can be aggregated into a single large transaction by aggregating all the payers and payees of the smaller transactions. The amount of computation decreases as the number of transactions in a block increases. The time required to fill a block with transactions is larger when the number of transactions to fill the block increases. Checking the Trusted Agent Consider a system in which the trusted agent broadcasts its current copy of the tamper-evident ledger to all agents. Every agent can inspect its copy of the tamper-evident ledger to determine whether the ledger has been tampered with. So, every agent can validate its trust in the trusted agent; however, this validation suffers from a crucial problem: Agents may only have copies of old, stale versions of the ledger. By the time that an agent receives a copy of the ledger, the trusted agent may have added more transactions to the ledger. Fig.4: Old Copy is a Prefix of the Block Chain An old copy of the ledger can differ from the current copy in only one way: the current copy may have transactions appended to the end of the old copy. So all agents can validate past behavior of the trusted agent. An agent cannot, however, treat its copy of the ledger as the master copy because the agent may not have the transactions added most recently to the ledger. In the next module we will see how the Bitcoin algorithm addresses this problem. Advantages of this cryptocurrency Any agent can get a copy of the tamper-evident ledger and verify that all transactions in the ledger are valid. Any agent can verify that the only way in which the ledger is modified is that elements are append to its tail; all that the agent needs to do is to check that the pointer to the tail is modified only by appending elements. Because the ledger is tamper-evident, an agent can check that the ledger doesn't change while the hash pointer to the end of the ledger doesn't change. The bank can't forge a transaction because all payers sign the transaction. Agents can remain anonymous because an agent's only public information is the agent's public key, and an agent can create multiple public keys. Every agent can verify the correctness of every transaction. Disadvantages of this cryptocurrency Users may not trust the bank. Transactions are not private because the bank has a record of all transactions. And the bank is a single point of failure. Next we'll look at Bitcoin's algorithms for implementing a cryptocurrency without trusted agents. Review What is collision resistance ? Why is it relevant to cryptocurrencies? Consider the example of hiding in which Megan hides her predictions for the winner of the World Cup. Suppose you could choose two different random number generators for creating the secret \(r\); in one case the bits of \(r\) are uncorrelated, and in the other they are highly correlated. Which generator would you use and why? What is binding ? Why is it relevant to hiding information? What is puzzle friendly ? What is a tamper-evident data structure ? How would you implement a tamper-evident linear list? A tamper-evident tree? Describe the algorithm for cryptocurrency with a trusted agent to someone who knows absolutely nothing about cryptocurrency. How could the algorithm for cryptocurrency be used for a collection of distributed agents to keep track of a sequence of events, other than buying/selling currency? K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Crypto/BitCoin.html ---
TITLE: Crypto/BitCoin.html

Crypto/BitCoin.html Distributed Algorithms Contents Index Cryptography: Introduction Bitcoin Introduction to Bitcoin This module introduces the algorithm underlying BitCoin. Bitcoin is based on cryptography and distributed consensus. We discussed aspects of cryptography required for Bitcoin in an earlier module. Next, we study the distributed consensus algorithm used by BitCoin. This Princeton University book has a superb (and longer) description of consensus in Bitcoin. We discussed distributed consensus in the modules on Paxos and Byzantine Generals with written and oral messages. The specification of consensus is weaker in Bitcoin and the algorithm used to obtain consensus is different from those used in Paxos and Byzantine Generals written and oral algorithms. The Byzantine Generals algorithms assumes that the algorithm operates in rounds, whereas the Bitcoin algorithm doesn't require synchronous rounds in which all agents participate. The Paxos algorithm does not guarantee progress whereas Bitcoin requires progress with high probability; you wouldn't want to use coins if you had to wait a long time to buy anything. No trusted agent In an earlier module we described an algorithm that had many of the features that we expect from a cryptocurrency. That algorithm had, however, a characteristic which is problematic to some: It relies on a trusted agent. The trusted agent could be the Federal Reserve in the US or a central bank that manages a currency. Two of many reasons given for mistrusting banks are that (1) people may want to execute transactions in secret giving only their public keys, and (2) central banks may be able to print money whereas some cryptocurrencies, such as Bitcoin, limit the total amount of coins that can ever exist. The Bitcoin algorithm is a modification that eliminates the trusted agent from the algorithm given in the previous module. No assumptions about numbers of agents The Byzantine Generals algorithm uses an upper bound on the number of faulty agents. Paxos assumes that the total number of agents is known. The Bitcoin algorithm makes no assumptions about numbers of faulty and non-faulty agents other than that there are a large number of agents. Incentives and transaction fees When a currency is managed by a single trusted agent, such as a bank, we assume that the bank gets some reward for its service or is paid by a government to carry out this service. The Bitcoin algorithm pays agents with Bitcoins for checking the validity of transactions. This payment consists of new coins that are "mined". More about mining later A First Proposal for an Algorithm How can we modify the algorithm we described earlier so that it works without a trusted agent? Let's try this modification: Select random agents to play the role of the trusted manager. A step of the algorithm is as follows: A single agent is chosen randomly to play the role of the trusted manager. This agent receives and validates transactions, gathers some of the transactions into a block, appends the block to the block chain, and broadcasts the updated block chain. The other agents update their copies of the block chain when they receive this value. The system waits for all agents to update their copies and then executes the next step. Challenges of the Proposed Algorithm This algorithm has several challenges. Selecting a single agent. How can the collection of agents select a single agent to add a block to the block chain? The selection of a single agent requires all agents to reach a consensus about which agent to select. So solving the problem this way would require solving another consensus problem. The Bitcoin algorithm does not select a unique agent to add a block to the block chain; however, it uses an ingenious mechanism to ensure that multiple agents don't attempt to add blocks at about the same time. Synchronization : How can the collection of agents wait long enough to ensure that all agents have updated their copies of the ledger to the most recent version before the ledger is modified again? Consider the following example scenario.  All agents have the same copy x of the ledger at some point t. Agent B, selected randomly to act as the trusted agent, appends transaction y to the ledger at a later point t' at which point B's copy is [x, y].  Then, agent C, selected randomly to act as the trusted agent, appends transaction z to the ledger at a later point t''. If C's copy is still [x], because it has not as yet been updated to [x, y], then after C appends z to the ledger, C's copy becomes [x, z]. A key property of the algorithm with the trusted agent is that two copies of the ledger are either identical or the longer copy consists of additional transactions appended to the shorter copy. With this property, two copies of the ledger are either identical or the shorter copy can eventually "catch up" to the longer copy by merely by appending more values. In the example, B may receive information about transaction z after receiving information about transaction y, whereas C may receive this information in the reverse order, which leaves B's copy as [x, y, z] and C's copy as [x, z, y]. In this case, the copies remain different forever. The Bitcoin algorithm does not guarantee synchronization ; however, its mechanism helps to make many agents append blocks in the same order. Incentives : Why should an agent chosen to play the role of trusted agent agree to play that role? What's the incentive? Why wouldn't the trusted agent do nothing at all execute its step slowly? Untrustworthy Agents : The randomly-chosen trusted manager may not be trustworthy. You can imagine what may go wrong in the previous algorithm if the bank was dishonest. Next, let's look at how the Bitcoin algorithm addresses challenges 1 and 2. We'll look at challenges 3 and 4 later. Selecting a Single Random Agent How can an arbitrary set of agents, some of whom may be malicious, and where the size of the set is unknown, pick a random agent? Using Puzzles to Select a Single Agent Let's look at a simple situation: several people solve puzzles in the same room. When a person solves her puzzle, she yells "I won!". When a person hears that somebody else has won she stops solving her puzzle. If everybody starts at the same instant and take the same time then there will be collisions --- many will claim to win at the same time. If, however, the time to solve a puzzle is a random variable with a flat distribution then collisions are unlikely. Bitcoin uses the puzzle-friendly property of cryptographic hash functions discussed in the previous module . Now, instead of people being all in the same room, assume that they are competing across a network. When a person solves a puzzle, she broadcasts a "I won" message. When a person working on a puzzle gets a "I won" message from somebody else, she stops working on her puzzle. Collisions are likely if the expected time to solve the puzzle is small (say a millisecond) compared with the expected time (say a minute) for a message broadcast by one person to reach others. Message delays may cause multiple people to solve their puzzles before receiving "I won" messages. Collisions are unlikely when times to solve puzzles are much greater than message delays. We could attempt to use timestamps: When a person solves her puzzle she broadcasts a "I won" message and the time at which she finished solving the puzzle. If a person gets a "I won" message with an earlier timestamp then she concedes. This approach is problematic because a devious agent may not solve the puzzle, or may set her timestamp to an earlier value. Puzzles in Bitcoin Next let's look at the puzzles used in Bitcoin. Each agent has its own copy of the block chain. An agent \(A\) collects a set \(trans\) of transactions that haven't as yet been added to \(A\)'s copy of the block chain. Agent \(A\) proposes to append a block to the chain where the block consists of the set \(trans\) in the following way. Let \(ptr\) be the pointer to agent \(A\)'s copy of the block chain. Agent \(A\) can add a block containing \(trans\) to the chain only if it proves that it has solved the following problem --- the "puzzle." Find a number, called \(nonce\), such that: \(H(nonce + ptr + trans) < target \) where \(+\) is the concatenation operator , and target is a given value. For the time being assume that target is a constant; later, we'll see that it decreases very slowly over time. The smaller the value of target the greater the expected time to solve the puzzle. The time to solve a Bitcoin puzzle is a random variable with a flat distribution. Each proposer of a block is probably solving a different puzzle because the block of transactions that it is aggregating is likely to be different from that of other proposers. Agents have different amounts of computing capacity, and the time to solve a puzzle decreases with capacity. Agents are unlikely to start solving their puzzles at the same instant. For these reasons, it is possible, but unlikely, that many agents will solve their puzzles at the same time. Using puzzles to identify a single random agent leaves us with at least three challenges: (1) Collisions will occur; (2) agents may be devious --- they may claim to have solved puzzles when they haven't; and (3) agents with computing power that far exceeds those of others will solve their puzzles faster than others do --- and so though agents are selected randomly, those with large computing power are likely to be selected more often. Attempts at Synchronization When an agent \(A\) appends a new block \(B\) to a block chain \(L\) it broadcasts the new chain \(L + B\). This is analogous to a person shouting "I won" in the example given earlier. When a (non-devious) agent \(A'\), which proposes to extend chain \(L\), gets a message saying that \(L\) has already been extended to \(L + B\) then \(A'\) stops attempting to append a block to \(L\). Instead, \(A\) starts again with a new set of transactions that it proposes to append to the extended chain \(L + B\). If the message delay between agents \(A\) and \(A'\) is small compared to the time to solve puzzles, then a collision between \(A\) and \(A'\) is unlikely, but still possible. So, it is possible that \(A\) broadcasts \(L + B\) while \(A'\) broadcasts \(L + B'\) at about the same time. So different agents may have different copies of the block chain. What is the equivalent of the "true" system-wide block chain when different agents have different copies? The Bitcoin algorithm does not use synchrony to deal with this issue. The problem of different copies of the block chain extant at the same time is handled in an ingenious asynchronous way that we describe later. Managing Concurrent Updates A key step of the Bitcoin algorithm that updates local copies of block chains is as follows. After an agent creates a block and appends the newly created block to its local copy it broadcasts its copy of the block chain. When an agent \(A\) gets a message containing a copy of another agent's block chain, agent \(A\) sets its local copy to the block chain in the message if and only if the length of the block chain in the message exceeds the length of \(A\)'s local copy. Let's look at a scenario. For this scenario, \(X\) and \(Y\) are single blocks. Assume that agent \(A\)'s copy of the block chain is \(L\) when \(A\) receives a message containing the block chain \(L + X\). Because the length of the block chain \(L + X\) is bigger than \(A\)'s copy, \(A\) sets its copy to \(L + X\). Now suppose agent \(A\) gets a message containing the block chain \(L + Y\); what does \(A\) do? Agent \(A\) ignores the message because the length of \(L + Y\) does not exceed that of \(A\)'s current copy, \(L + X\). Continuing Collisions Let's continue the above scenario. Can block \(Y\) become part of \(A\)'s chain, or will it remain forever an "orphan" block as far as \(A\) is concerned? Here's a possible scenario. An agent with a block chain copy \(L + X\), solves its puzzle and appends a block \(X_{1}\) to get a new copy \(L + X + X_{1}\) of the block chain which the agent broadcasts. At the same time, another agent with a block chain copy \(L + Y\), solves its puzzle and appends a block \(Y_{1}\) to get a new copy \(L + Y + Y_{1}\) which is broadcast. If \(A\) receives \(L + Y + Y_{1}\) before receiving \(L + X + X_{1}\) then \(A\) will set its chain to \(L + Y + Y_{1}\), and then reject \(L + X + X_{1}\). You can construct a scenario with a sequence of collisions between agents appending blocks \(X_{i}\) and other agents appending blocks \(Y_{j}\) so that \(A\)'s chain switches back and forth between \(X\) and \(Y\) values. Long sequences of collisions are unlikely, and the longer the sequence the less the probability of continuing collisions. So how can an agent determine whether a block is in the chain? And so how can an agent find out if a transaction has been executed? You sell your used bicycle to somebody for coins, but how do you know if that transaction becomes part of the block chain when different agents have different copies? And so how do you know that you can spend those coins that you should have received for your bicycle? Confidence that a Block is in the Chain In this section we discuss the behavior of non-devious agents; we will show how the algorithm handles devious agents later.    Suppose an agent's copy of the block chain is \(X + X_{1} + X_{2} + \ldots + X_{K}\), and another agent's copy is \(Y + ? + ? + \ldots\), where \(?\) represents arbitrary values. What is the likelihood that \(Y \neq X\)? \(Y\) can be different from \(X\) only if there are a sequence of \(K\) or more collisions. And the likelihood of a sequence of collisions decreases with \(K\). Likewise, the likelihood that an agent never receives a block chain containing \(X\) decreases with time, and so decreases with \(K\). So, if \(K\) is large then with very high probability, \(X\) is part of every agent's block chain. Now suppose an agent's copy of the block chain is \(L + X + X_{1} + X_{2} + \ldots + X_{K}\). What is the likelihood that another agent's copy is \(L + Y + ? + \ldots\) where \(L\) is an arbitrary sequence? By the same argument, when if \(K\) is large then with very high probability, \(X\) is part of every block chain. For practical purposes, many agents assume that if \(K > 6\) then \(L + X\) is a prefix of most agents' block chains. See the Princeton Bitcoin book. Suppose agent \(A\) gets \(N\) Bitcoins in transaction \(X\). If \(K = 0\) then an agent can't be confident that \(A\) ever received these coins because this transaction may not persist in the block chain. As \(K\) increases agents become more confident that the transaction is in the block chain and that \(A\) did, indeed, receive these coins. Fig.1: More Confidence in Older Blocks in the Chain What happens to Orphan Transactions? An agent may append a block \(Y\) to its chain, and this block may be dropped from the chains of all agents and never reappear after some point. We saw a scenario in which this happens. Such a block is an "orphan," because no agent has a record of that transaction after some time. If an orphan block contains the transaction in which you sold your bicycle in exchange for coins, then will you ever be able to spend your coins? Yes, you will get your coins as we see next. Agents aggregate transactions that have not appeared in the agent's block chain into blocks and propose to append these blocks to the chain. A transaction that does not appear in block chains will be agrregated eventually by some agent and inserted into a block in the chian. Though the orphan block disappears the transactions in the block do not. Incentives Next, looks look at challenge number 3. Why should an agent create blocks of validated transactions? Because the agent gets paid! Payment is from either a block reward or transaction fees. Block rewards An agent that creates a block gets a specified number of Bitcoins for itself as a reward called a block reward . The Bitcoins in a block reward are created by making the block; these Bitcoins don't exist until the block is created. The process of making blocks and acquiring block rewards is called "mining." Mining is the only way of creating new Bitcoins. When Bitcoin started the reward for creating a block was 50 Bitcoins. The reward halves after the creation of a certain number (210,000) of blocks. The reward was reduced to 25 in 2013 and to 12.5 in 2018. Block rewards will vanish at some point in the future. The total number of Bitcoins that can ever be created has an upper bound: about 21 million. (Bitcoins can be lost. An agent may lose the hash pointer to the transaction that gave the agent ownership of the coin, or an agent may lose its private key.) Even when block rewards vanish, miners will continue to mine provided that they get paid transaction fees. A transaction fee is a payment by payers and payees to miners. Transaction fees are voluntary. A high-fee for a transaction is an incentive to miners to put this transaction into a block quickly. So, it's possible that agents that offer no fee or low fees may have to wait longer for their transactions to enter the block chain. Incentives are critical for Bitcoin. Miners get paid to get their blocks into the long-term "consensus" block chain. Miners have an incentive to police the block chain because they don't get paid for appending erroneous blocks. If a miner appends an erroneous block to the chain then other miners won't extend chains containing the erroneous block, and so the erroneous block will become an orphan. Any agent can check whether its copy of the block chain is valid; however, agents making ordinary transactions don't need to do so because there are many miners each of whom has an incentive to ensure that the block chain is legitimate. Attacks Next, looks look at challenge number 4. Stealing coins Can an agent steal a coin from an agent \(X\) by appending a block to the chain where the block contains a transaction in which \(X\) gives coins to \(Y\)? No, this can't happen thanks to cryptography. A transaction into which \(X\) puts coins is valid only if \(X\) signs the transaction.  \(Y\) cannot forge \(X\)'s signature, and so \(Y\) cannot create blocks that contain such fraudulent transactions. Double spend Can an agent spend the same coin twice? Can an agent buy something without paying for it? Consider the following transaction using conventional checks issued by banks. A buyer gives a seller a check for $\(100,000\) for a house. The house is put in escrow.  When the check clears and the seller receives the payment the buyer gets possession of the house. The legal process that includes notaries, real estate agents, and banks, helps ensure that the transaction concludes correctly or is aborted correctly. Next, let's look at a transaction in which a person buys a video online by paying the seller Bitcoins. The buyer and seller know each other by their public keys and by their online addresses. The buyer broadcasts the transaction in which the buyer gives the seller the payment in Bitcoins. The amount is specified as a pair (transaction id, array index) described in the section pay transactions in the module introducing crypto currencies. A miner puts the transaction into a block \(X\); appends the block to its copy \(L\) of the block chain; and broadcasts the extended block chain \(L + X\). When the seller gets a copy of the block chain \(L + X\), the seller concludes that it has received the payment from the buyer because the transaction has been recorded in a block chain. So the seller gives the video to the buyer. The buyer cheats. The buyer creates a transaction in which the buyer transfers the same Bitcoins  to the buyer itself. A miner creates a block \(Y\) that includes this transaction. A miner who has only received block chain \(L\) (and hasn't yet received chain \(L + X\)) appends \(Y\) to \(L\) to get a chain \(L + Y\), and broacasts \(L + Y\). Now we have a situation in which one miner broadcasts a legitimate block chain \(L + X\) and a different miner broadcasts a legitimate block chain \(L + Y\). Both chains have the same length. A miner with chain \(L + X\) does not know at this point that another minder has chain \(L + Y\). So, miners will extend both block chains. (Note that the algorithm will not permit chains \(L + X + Y\) or \(L + Y + X\).) We've seen this situation before:  look at block collisions described earlier in this module. Both block chains will be extended, but eventually, with very high probability, one of the blocks \(X\) or \(Y\) will drop out of chain. How should sellers protect themselves? What is the equivalent of the buyer's check clearing in the bank? A seller should give the item to the buyer only after the transaction appears with high confidence in a block in the chain --- see Figure 1. The seller listens to block chains broadcast by miners. If the seller gets a block chain \(L + X + L'\) where \(L'\) is itself a long block chain then the seller has high confidence that the transaction is in the permanent record. The seller waits to get block chains in which its transaction appears in a block which is then followed by \(m\) blocks, for large \(m\). The larger the value of \(m\), the greater the seller's confidence, but the longer the buyer has to wait to get paid. length of the extension \(L'\). A value of \(m = 6\) gives adequate confidence in most cases. Fraudulent miners A miner gets paid for every block the miner creates; so, why shouldn't the miner create fraudulent blocks and get paid for them? The answer is the same as that for the double-spending attack. A miner may have created a block and appended it to the chain; however, a suspicious agent (and we hope that all agents are suspicious!) will not accept the block until many blocks have been appended to the chain after it. Other miners won't append their blocks to an invalid one. The invalid blocks will become permanent orphans, and so the fraudulent miner won't be able to spend the coins in these blocks. Fifty One Percent Attacks A 51% attack can be carried out by an agent that has more mining power (e.g. 51% or more) than all other agents combined. The higher the proportion of mining power of a single agent, the greater the chances that attacks by that agent will succeed. You can see the danger of a single agent having predominant mining power by thinking about an agent with say, 99% of the total mining power. This agent can mine so much faster than others that it can manipulate the block chain in many ways. It can create double-spend transactions and deny services to some transactions. A group of miners can collude to gain predominant mining power. Also, miners can rent Cloud-based systems for mining --- as opposed to having to own huge data centers. An attacker can rent a large system for the specific purpose and duration of an attack. The public may not know if and when such attacks are successful because cryptocurrencies do not have an incentive to publish such attacks. Denial of service Can agents collude so that an agent \(X\)'s transactions never get into blocks and so never get processed? An agent's identity does not appear in a transaction, only a public key does. An agent can create new public keys at will. So let's ask another question: can agents collude so that transactions with a specific public key do not get into blocks? Only an agent that can solve puzzles in reasonable time can make blocks. These agents have significant computational power. One can concoct a situation where many agents with significant computation power collude to avoid transactions from a specific public key. This could have the effect of slowing processing of certain transactions. However, such a situation isn't likely to arise because agents have an incentive to create blocks and so they compete --- rather than collude --- with each other. Colluding agents, with massive computing power, may help to deny or slow service to a public key but not to another agent because agents can create public keys at will. Further Reading There are many issues that we have not covered. This material only covers the basics from the point of view of distributed algorithms. Review What is a block chain ? How does the algorithm deal with the situation in which one agent receives a message to extend its copy of the block chain with a block \(X\) while another agent receives a message to extend its copy of the block chain with a different block \(Y\)? Could there be an infinite sequence of collisions? Is that likely? What is mining for cryptocurrency? Suppose only a small number (say two organizations) mined most (say 99%) of Bitcoins. Would that be a problem? Why is double spending unlikely to be successful? K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/Knowledge/Knowledge.html ---
TITLE: Knowledge/Knowledge.html

Knowledge/Knowledge.html Distributed Algorithms Contents Index What Agents Know & How they Learn Agent Knowledge: Example Agent Knowledge: Self Test What Agents Know This module gives a formal definition for the frequently used informal phrase: "An agent knows something about other agents and and channels." Key Ideas We sometimes use anthropmorphic arguments in reasoning about systems --- we invest digital agents with human characteristics. For example, a programmer may say "an agent knows that another agent is idle." Endowing software with human capabilities can be dangerous when terms are ambiguous. In this module we define a predicate "agent \(x\) knows \(P\)" where \(P\) is a predicate on states of a system. In later modules, we will use this definition to discuss algorithms. This module presents theorems about what agents know. The proofs of these theorems follow from the definition of consistent cuts . What an Agent Knows Let \(x\) be an agent, \(P\) a predicate on system states, and \(Q\) a predicate on states of \(x\). \(P\) can be a global predicate , i.e., a predicate on states of all agents and channels. \(Q\) is a local predicate of \(x\) because it is a predicate only on the states of agent \(x\) and is independent of other agents and only channels. Let \(init\) be the predicate that defines the initial condition of the system. We define the predicate "\(x\) knows \(P\)" as follows. \(x\) knows \(P\) is the weakest local predicate \(Q\) of \(x\) such that: \( [init \; \Rightarrow \; always([Q \; \Rightarrow \; P])] \) \(x\) knows \(P\) holds in a local state \(s_{x}\) of agent \(x\) exactly when \(P\) holds in all states of all trajectories (that start from an initial state) when the local state of agent \(x\) is \(s_{x}\). Explanation For any predicate \(R\): \( [init  \; \Rightarrow \; always(R)] \) means that \(R\) holds in every state of every trajectory that starts in an initial state. So, \( [init  \; \Rightarrow \; always([Q \Rightarrow P])] \) means that in \([Q \Rightarrow P]\) holds in every state of every trajectory that starts in an initial state. So, if local predicate \(Q\) of agent \(x\) holds in any state of any trajectory that starts from an initial state then global predicate \(P\) also holds in that state. Example A system consisting of agents \(0, \ldots,  N\) has two indivisible tokens which are not created or destroyed. "Agent \(0\) knows no other agent holds a token" is a predicate on the states of agent \(0\); this predicate holds for a local state \(s_{0}\) of agent \(0\) if and only if no other agent holds a token when agent \(0\) is in state \(s_{0}\). So, "agent \(0\) knows P" holds exactly when agent \(0\) holds both tokens. Example This example deals with a system consisting of two agents \(x\) and \(y\) and channels in both directions between the agents. The system has a single indivisible token that is not created or destroyed. Let \(P\) be the predicate: "\(y\) does not hold the token." Agent \(x\) knows \(P\) when \(x\) holds the token. \(\neg\) (\(x\) knows \(P\)) is a predicate too, and sometimes programmers refer to this predicate as "\(x\) does not know \(P\)." Example In the previous example, let \(Q\) be the predicate: "\(y\) holds the token." In what local states of agent \(x\) does \(x\) know that "\(y\) holds the token?" There are no local states of agent \(x\) in which \(x\) knows that "\(y\) holds the token." Even when \(x\) does not hold the token, \(x\) does not know that \(y\) holds the token because the token could be in a channel. When \(x\) does not hold the token, \(x\) does not know that \(y\) holds the token and \(x\) does not know that \(y\) does not hold the token. "NOT(x knows Q)" AND "NOT(x knows NOT Q)" is a predicate which holds in the state which \(x\) does not hold the token. Notation "\(x\) knows \(P\) at a point \(T\)" in a timeline means that at point \(T\) agent \(x\) is in a state where the predicate "\(x\) knows \(P\)" holds. Theorem: Knowledge and Consistent Cuts Let \(P\) be a predicate on the states of a system. If  \(x\) knows \(P\) at a point \(T\) in \(x\)'s timeline then \(P\) holds in every consistent cut through that point. Proof The states corresponding to all consistent cuts that pass through the same point on \(x\)'s timeline have the same common value for \(x\)'s local state. Example > Fig. 2. Agent A knows P in all consistent cuts that cross point T The top figure in both diagrams above show a time T at which agent A knows that P holds. This implies that P holds in all consistent cuts through point T. The lower figures in the diagrams show consistent cuts which passes point T on A's timeline; the theorem says that P holds for the state at these cuts too. Theorem: A Silent Agent retains Knowledge An agent that sends no information between a point \(T\) and a later point \(T'\) retains all the knowledge it has at \(T\) at \(T'\). Let \(x\) be an agent in a system, and let \(P\) be a predicate on a subsystem that does not include \(x\). Let \(T\) and \(T'\) be points on \(x\)'s timeline with \(T < T'\). If \(x\) knows \(P\) at point \(T\) and \(x\) sends no messages in the interval \([T, T']\) then \(x\) knows \(P\) at \(T'\). Proof Let \(c'\) be any consistent cut through point \(T'\) on \(x\)'s timeline. We will prove that \(P\) holds for the state at cut \(c'\). Let \(c\) be the cut that is identical to \(c'\) except that it passes through point \(T\) on \(x\)'s timeline. \(c\) is consistent because there are no outgoing edges from \(x\)'s timeline between cuts \(c\) and \(c'\). Because \(x\) knows \(P\) at \(T\), \(P\) holds at \(c\). Since \(c\) and \(c'\) are identical except for the intersection with \(x\)'s timeline, it follows that \(P\) holds \(c'\). Example > Fig. 3. Illustration of Proof of Silent Agents Consequence of the Theorem An agent doesn't lose knowledge by getting information from other agents. An agent can only lose knowledge by sending information to other agents. This seems counterintuitive; we'll look at the reasoning underlying this in a later theorem. Theorem: Agents who don't listen remain Ignorant An agent that receives no information between a point \(T\) and a later point \(T'\) learns no new knowledge between \(T\) and \(T'\). Let \(x\) be an agent in a system, and let \(P\) be a predicate on a subsystem that does not include \(x\). Let \(T\) and \(T'\) be points on \(x\)'s timeline with \(T < T'\). If \(x\) knows \(P\) at point \(T'\) and \(x\) received no messages in the interval \([T, T']\) then \(x\) knows \(P\) at \(T\). The proof has exactly the same structure as the proof of the previous theorem. Consequence of the Theorem \(x\) didn't learn anything in the interval  \([T, T']\); everything \(x\) knows at the later point \(T'\) is knowledge it already had at the earlier point \(T\). The only way for an agent to gain knowledge is to receive messages. An agent cannot learn about other agents by only sending messages or making internal state transitions. Theorem: Knowledge implies Control Let \(x\) and \(y\) be agents in a system, and let \(P\) be a predicate on the states of \(y\). Let \(T\) and \(T'\) be instants in a trajectory with \(T < T'\). If \(x\) knows \(P\) at  \(T\), and \(\neg P\) holds at \(T'\), then there is a path in the timeline diagram from point \(T\) on \(x\)'s timeline to point \(T'\) on \(y\)'s timeline. Proof: If there is no path from point \(T\) on \(x\)'s timeline to point \(T'\) on \(y\)'s timeline then there exists a consistent cut which crosses \(x\)'s timeline at \(T\) and crosses \(y\)'s timeline at \(T'\). Example In the figure below, agent \(A\) at point \(T\) knows that agent \(C\) holds no tokens. At a later point \(T'\) agent \(C\) holds a token. What must happen between points \(T\) and \(T'\)? > Fig. 4. What must happen between T and T'? There must be a path in the timeline diagram from point \(T\) on agent \(A\)'s timeline to point \(T'\) on agent \(C\)'s timeline. This path is represented by edges that show time elapsing on a timeline and message edges between timelines. > Fig. 5. There must be a path from A at T to C at T'? Consequence of the Theorem Suppose you and your friend communicate only by means of messages that are delayed by arbitrary (finite) amounts. Consider a situation where your friend knows that you are in the library at 9 pm. Then, from our definition of knowledge, because agents only know truth, you must be in the library at 9 pm. Moreover, you can't leave the library until you receive a message from your friend; this message may go through intermediate agents. In one of the exercises we'll look at knowledge when agents have clocks that may drift from each other but are not more than a some constant \(M\) units apart. If your friend knows that you will be in the library till her watch reads 9:00 pm, and your watches may drift apart by a minute, then you can leave the library at 9:01 pm. Clocks are useful even if they aren't perfect. More about clocks later. Theorem: Communication to learn about Change This theorem is similar to the "knowledge is control" theorem. Let \(x\) and \(y\) be agents in a system, and let \(P\) be a predicate on the states of \(y\). Let \(T\) and \(T'\) be instants in a trajectory with \(T < T'\). If \(\neg P\) holds at \(T\) and \(x\) knows \(P\) at \(T'\) then there is a path in the timeline diagram from point \(T\) on \(y\)'s timeline to point \(T'\) on \(x\)'s timeline. Example In the figure below, agent \(C\) holds a token at point \(T\). At a later point \(T'\) agent \(A\) knows that agent \(C\) holds no tokens. What must happen between points \(T\) and \(T'\)? > Fig. 6. What must happen between T and T'? There must be a path in the timeline diagram from point \(T\) on agent \(C\)'s timeline to point \(T'\) on agent \(A\)'s timeline. This path is represented by edges that show time elapsing on a timeline and message edges between timelines. > Fig. 7. There must be a path from C at T to A at T'? What Agents Know about Channel States Next, let's look at systems in which messages are acknowledged. For a pair of agents \(x, y\), let \(ms\) and \(mr\) be the number of messages that \(x\) has sent to \(y\), and  the number of messages that \(y\) has received from \(x\), respectively. Let \(as\) and \(ar\) be the number of acknowledgements that \(y\) has sent to \(x\), and the number of acknowledgements that \(x\) has received from \(y\), respectively.    The following is an invariant: \(ms \geq mr \geq as \geq ar \) The number of messages in the channel from \(x\) to \(y\) is \(ms - mr\). Because \(ms\) and \(ar\) are variables of agent \(x\), agent \(x\) knows an upper bound,\(\; ms - ar\), on the number of messages in channel \((x, y)\). So, \(x\) knows that the channel is empty when \(\; ms = ar\). What an agent cannot know An agent cannot know that there are exactly \(n\) messages in a channel, for \(n > 0\). You can prove this result using the concept of consistent cuts. Intuitively, the agent cannot know whether a message is in the channel or has been received. Chains of Knowledge Let \(x, y, z\) be agents of a system and \(P\) be a predicate on states of the system. Then the following are all predicates: \(z\) knows \(P\) \(y\) knows that \(z\) knows \(P\) \(x\) knows that \(y\) knows that \(z\) knows \(P\) The theorems given earlier apply to any predicate. For example, if \(x\) knows that \(y\) knows that \(z\) knows \(P\) at a point \(t\) in a trajectory, and \(\neg P\) holds at a later point \(t'\) then there must be path in the timeline diagram from point \(t\) on \(x\)'s timeline to point \(t'\) on \(z\)'s timeline. Concurrent Systems with Shared Variables The theorems and proofs given in this module apply to systems with shared variables, and indeed any system with trajectories that are representable by timeline diagrams and with consistent cuts. Summary Many people working on distributed systems use the phrase "an agent knows." This module gives a definition of the concept that is consistent with intuitive definitions of knowledge. The central idea in this module is the relationship between what agents know and consistent cuts of timelines. We presented several theorems about agent knowledge which are intuitive when applied to human agents. The proofs are straightforward and are all based on consistent cuts of timelines. Review Is the following true? Why? (\(z\) knows \(P\)) and (\(z\) knows \(Q\)) \(\equiv\) \(z\) knows \(\(P \wedge Q\)) Is the following true? Why? (\(z\) knows \(P\)) or (\(z\) knows \(Q\)) \(\equiv\) \(z\) knows \(\( P \vee Q\)) Suppose you and your friend communicate only using messages sent in channels, just as agents do in our model of distributed systems. When you know that your friend is wearing a cap does that mean that (a) your friend is wearing a cap, and (b) your friend can't take the cap off until the friend hears from you? K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DiffusingComputations/DiffusingComputations.html ---
TITLE: DiffusingComputations/DiffusingComputations.html

DiffusingComputations/DiffusingComputations.html Distributed Algorithms Contents Index Diffusing Computations: Text Diffusing Computations: Slides Applications of Diffusing Computation Applications of Diffusing Computation: Example Diffusing Computation: Self Test Applications of Diffusing Computation: Self Test Diffusing Computations This module describes diffusing computation algorithms by which an agent can learn about the structure of the  network in which the agent operates. This module describes diffusing computations. An agent can use diffusing computations to learn about the structure of the  network in which the agent operates. For example, an agent can use diffusing computations to determine the number of agents in the network or to determine if the system is deadlocked. Data Structures in Distributed Algorithms The module shows how data structures play critical roles in distributed algorithms just as they do in sequential algorithms. The algorithm maintains the invariants that define the data structure --- in this case a tree --- even though the structure is modified concurrently by multiple agents. Nondeterministic Iteration in Sequential and Distributed Algorithms This module shows how nondeterministic iteration is used in exactly the same way for reasoning about sequential and distributed algorithms. Whether the algorithm operates across multiple agents and channels or is a sequential program is immaterial to reasoning about its correctness. The Problem In this module we deal with systems in which an agent is either idle or active . An idle agent remains idle until it receives a message at which point it becomes active. An idle agent does not send messages. An active agent may send messages. An active agent may become idle at any time. Initially, the system has a single active agent. This agent is called the initiator . Initially all channels are empty.    The computation terminates exactly when all agents are idle and all channels are empty. The computation may never terminate. Our first problem is to design an algorithm that enables the initiator to determine that the computation has terminated if it terminates. Later, we will extend this algorithm to enable the initiator to learn about the network. In this system, for every channel from an agent \(x\) to an agent \(y\), there is a channel from \(y\) to \(x\). For any pair \(x, y\) of agents there exists at most one channel from \(x\) to \(y\), and at most one channel from \(y\) to \(x\). An agent \(y\) sends an ack (acknowledgment) along channel \((y, x)\) after receiving a message along channel \((x, y)\). An ack is different from a message; so acks aren't acked. Initially all channels are empty: there are no messages or acks in transit along channels. Let \(x.num\_unacked\) be the number of \(x\)'s unacknowledge messages, i.e, the number of messages that \(x\) has sent minus the number of acks that \(x\) has received. We can prove the invariant that there are no messages in any of \(x\)'s outgoing channels when \(x.num\_unacked = 0\). A Rooted Tree For an agent to become active there must be a chain of messages from the initiator to the agent. A data structure with paths between the initiator and active agents is a tree, rooted at the initiator, and which spans active agents. For each agent \(x\) let \(x.parent\) be either \(null\) or an agent which is \(x\)'s parent in the tree. Agent \(x\) is not on the tree exactly when \(x.parent = null\). We will prove the following invariants. Invariants The tree is rooted at the initiator, i.e. if \(x.parent \neq null\) then the initiator is an ancestor of \(x\). An agent is off the tree exactly when the agent is idle and the agent has no unacknowledged messages: \( (x.parent = null) \quad \equiv \quad x.idle \wedge (x.num\_unacked = 0) \) If \(x\)'s parent is not \(null\) then \(x\)'s parent has at least one unacknowledged message. \( x.parent \neq null \quad \Rightarrow \quad x.parent.num\_unacked > 0 \) From invariant 3, it follows that an agent has no children if it has no unacknowledged messages. So, from invariant 1, if the initiator has no unacknowledged messages then all agents, apart from the initiator, are idle and have no messages in outgoing channels. Therefore computation has terminated when \( initiator.idle \wedge (initiator.num\_unacked = 0) \) So, the initiator detects that the computation has terminated when the initiator is idle and no unacknowledged messages. Next we give an algorithm that maintains the above invariants. Program for an agent Next we propose a program for an agent \(x\) other than the initiator. Program 0: initially: x.parent = null x.idle = True x.num_unacked = 0    1. When x sends a message: x.num_unacked = x.num_unacked + 1    2. When x receives a message from y: x.idle = False if x.parent = null: x.parent = y else send ack to y    3. When x receives an ack: x.num_unacked = x.num_unacked - 1 if (x.num_unacked == 0) and x.idle: send ack to x.parent x.parent = null    4. When x becomes idle: x.idle = True if x.num_unacked == 0: send ack to x.parent x.parent = null The Initiator The program for the initiator is the same except that initially the initiator is active. Also, to keep the exposition uniform for the initiator and the other agents, we assume that the initiator has a parent which is not one of the agents of the network. We call the initiator's parent \(external\). This agent plays no role other than to keep the proofs identical for the invariant and other agents. initiator.parent = external initiator.idle = False initiator.num_unacked = 0 external.num_unacked = 1 Proof of Correctness Safety The proof that the invariants are satisfied is carried out by showing that they hold initially and then verifying that each of the four commands maintains the invariants. The verification step is straightforward if a bit laborious. Progress If all agents are idle and there are no messages in channels then the underlying computation has terminated. We will prove that if the underlying computation does terminate then the detection algorithm terminates as well, i.e. the tree vanishes, and at that point the initiator detects that the computation has terminated. After the underlying computation terminates, the only action that executes is action 3: receiving an ack. A variant function is the following graph. A vertex \(x\) is in the graph exactly when \(x.parent\) is not null or there is an ack in transit along the channel from \(x\) to its parent. Define a partial order \(<\) between graphs as \(G \leq G'\) when \(G\) is a subgraph of \(G'\). This graph is a tree because the only pending acks are from a vertex to its parent (rule 3). Next we prove that every execution of an action while the variant function is not the empty graph reduces the variant function. When all acks are delivered to \(y\), it sends an ack to its parent. So while the tree is not empty there is an ack in some channel. When \(y\) receives an ack from \(x\), the edge \((x, y)\) is deleted from the tree. Therefore every execution of action 3 reduces the variant function. Review Show that when an idle agent becomes active the agent is added to the rooted tree if it is not already part of it. The variant function used to prove progress in this module is a graph. Every action (execution of a guarded command with a true guard) must reduce the variant function. What does reducing the graph mean? This module says that if the underlying computation has terminated and the tree hasn't vanished then there exists some channel that has an ack in it. Why is that true? K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DistributedCollaboration/DiningPhilosophers/DiningPhilosophers.html ---
TITLE: DistributedCollaboration/DiningPhilosophers/DiningPhilosophers.html

DistributedCollaboration/DiningPhilosophers/DiningPhilosophers.html Distributed Algorithms Contents Index Mutual Exclusion: Distributed Dining Philosophers Distributed Resource Management: Drinking Philosophers Multi Agent Rendezvous: Committee Coordination. Work In Progress Dining Philosophers This module describes algorithms for "The Distributed Dining Philosophers Problem," a problem that exemplifies mutual exclusion of critical operations among agents in a distributed setting. This and following modules describe algorithms by which agents manage conflicts among themselves. This module describes an algorithm for a distributed mutual exclusion problem called The Distributed Dining Philosophers Problem . Key Concepts 1. Mutual Exclusion The distributed dining philosophers is a generalization of the mutual exclusion problem to distributed systems.  A mutual exclusion or mutex problem is one in which only one agent can carry out some activity such as executing a critical section of a program. Mutex algorithms ensure that all agents that want to carry out such activities do so eventually. 2. Priorities among Agents Distributed conflict-resolution algorithms ensure that when multiple agents are in a conflict that only one of them can win, every agent wins eventually. A standard way of managing conflicts is to have agents agree on relative priorities among themselves; the agent with higher priority wins. Distributed algorithms often use a good-neighbor policy to ensure that all agents win conflicts eventually: An agent that wins a conflict makes its priority lower than the priorities of all the agents with which it competes. 3. Tokens and What Agents Know An agent can resolve a conflict with other agents only if it knows something about the states of other agents. For example, what agents want to enter a critical section and what are their priorities? What agents know is defined in this module. We used the concept of tokens to illustrate what agents know.  A system has a fixed number of indivisible tokens which are neither created nor destroyed. An agent that holds a token knows that no other agent holds that token.  This knowledge is at the core of many conflict resolution algorithms. The Problem Agent States in a Mutual Exclusion Problem Fig.2: States in Mutual Exclusion An agent in a mutual exclusion problem is in one of three states: Outside critical section : The agent is executing outside its critical section. An agent can remain in this state for ever, or it may transit after finite time to the next state: waiting to enter its critical section. Waiting to enter critical section : The agent waits to enter critical section until it is given permission to do so by the operating system. In critical section : The agent executes in its critical section.  An agent does not remain in its critical section forever. It does so for only finite time after which it transits to the state, outside critical section. Clients determine transitions from outside critical section to waiting to enter critical section , and from in critical section to outside critical section .    The operating system determines transitions from waiting to enter critical section to outside critical section . Agent States in the Dining PhilosophersProblem Fig.3: States in Dining Philosophers The name "Dining Philosophers" is an example of CS humor (an oxymoron?). Philosophers may think for ever, but eat for only finite time. The algorithm must ensure that hungry philosophers don't starve --- they get to eat eventually . The problem and its name were proposed by Edsger W. Dijkstra, a CS pioneer. The states "Thinking", "Hungry", and "Eating" correspond exactly to Outside critical section , Waiting to enter critical section , and In critical section , respectively. Agent Communication Structure Fig.4: Communication among Agents The commununication structure among agents is represented by an undirected graph in which the nodes are agents and each edge represents two channels, one in each direction. The agents are either OS or client agents. There is one client agent associated with each OS agent. Clients are shown as squares and OS agents as circles. For example client agent \(w\) is associated with OS agent \(w\). The diagram does not show all clients so as not to make the diagram too crowded. A pair of OS agents are neighbors when there is an edge between them. A pair of client agents are neighbors when the OS agents with which they are associated are neighbors. For example, in the figure, \(w\) and \(y\) are neighbors. Specification Safety: Neighbors do not eat at the same time Let \(safe\) be the predicate Neighboring clients are not eating , and let \(init\) be a predicate that holds initially. The safety part of the specification is that \(safe\) holds in every state in every path from every initial state: \([init \Rightarrow A(safe)]\) Progress: Hungry agents eat eventually The progress part of the specification is that every hungry agent transits to eating state eventually. For every agent \(v\): \( v.state = hungry \quad \leadsto \quad v.state = eating \) Example of Safety Fig.5: Diagrams illustrating Safety Figure 5 shows a client eating as a red node depicting the client and its OS agent. An uncolored node represents a client that is thinking or hungry. The diagram on the left shows the system in a safe state: there are no edges between red vertices. The diagram on the right shows an unsafe state because there are edges between red vertices. The Client's Program We use two tokens that move between a client and its OS agent. The tokens are called the resource token and the request token . The client's states are represented by which tokens the client holds. Thinking State : A thinking client holds the request token but not the resource token. Transition: Thinking to Hungry : Send the request token to the OS. Hungry State : The client holds neither the request nor the resource token. Transition Hungry to Eating : The client transits to eating when it receives both the request and resource token. Eating : The client holds both the request and resource tokens. Transition from Eating to Thinking : The client holds sends the resource token to the OS and continues to hold the request token. The figure below illustrates the states of the client. The request token is shown as a square and the resource token as a circle. Fig.6: Client's Program Initially all clients are thinking; all resource tokens are with OS agents; and all request tokens are with clients. What the OS Knows While the OS agent holds the request token it knows that its client is hungry. While the OS agent holds the resource token it knows that its client is not eating. Fig.7: OS Agent's Program When a client transits from thinking to hungry it sends its request token to the agent. When the OS receives the request token, the OS also has the resource token; so the OS knows that its client is hungry. There is an interval after the client sends the request token and before the OS receives it during which the client is hungry but the OS doesn't know that. An OS agent does not need to know what state its client is in at every point. Likewise, a client does not need to know its OS agent's state at every point. A client is hungry leads-to its OS agent knowing that its client is hungry. The leads-to captures the fact that the OS doesn't know the client's state at the instant that the client transitions from thinking to hungry. Introduction of Tokens We introduce a token on each edge of the agent communication graph, see figure 4. The token on an edge \(v, w\) is in one of four states: held by \(v\), in the channel from \(v\) to \(w\), held by \(w\), or in the channel from \(w\) to \(v\). Therefore while \(v\) holds this token it knows that \(w\) doesn't hold it. Likewise, while \(w\) holds this token it knows that \(v\) doesn't. Fig.7: Fork on each edge of the agent communication graph These tokens are called forks . (They are called chopsticks in some papers.) An agent eats only if it holds forks for all the edges incident on it. Therefore, while an agent eats none of its neighbors do, and so the safety specification is satisfied. Key Question: When does a hungry agent yield forks? An eating philosopher holds on to all its forks until it finishes eating. A thinking philosopher can give a fork to a neighbor that requests it. So the key question is: Under what conditions should a hungry neighbor give a fork that it holds to a neighbor that requests it? Suppose every hungry agent gives a fork to a neighbor that requests it. Then we can get the scenario shown in the figure below. Fig.8: Scenario when hungry agents yield forks The figure shows a system with 3 agents indexed 0, 1, 2. The forks are shown as small colored circles. The state on the left shows agent \(j\) holding the fork that it shares with agent \((j+1)\:\textrm{mod}\:3\). If each agent yields the fork to its neighbor we get the state on the right in which agent \(j\) holds the fork that it shares with agent \((j-1)\:\textrm{mod}\:3\). So, if all hungry agents yield forks, the states can alternate for ever between the one on the left and the one on the right. In this case hungry agents starve: they remain hungry forever. If hungry agents don't yield forks then the state on the left persists for ever. In this case too, hungry agents starve. Creating a Partial Order of Priorities Let's assign priorities to agents so that a hungry agent \(v\) releases a fork to a neighbor \(w\) only if \(v\) has lower priority than \(w\). If there is a cycle of agents, all with the same priority, then we get the situation shown in figure 8. So, we will ensure that priorities form a partial order in all states in all transitions. Priorities form a partial order exactly when the priority graph is acyclic. The graph has an edge from \(v\) to \(w\) exactly when \(v\) has higher priority over \(w\). In the figure below, the diagram on the left shows an acyclic priority graph while the one on the right shows a graph with a cycle. Fig.9: Priority Graph must be Acyclic How should Priorities Change? Fig.10: How should priorities change when \(v\) eats? How should priorities change when an agent eats so that the priority graph remains acyclic? For example, consider the priority graph shown in figure 10. Assume agent \(v\) has all its forks and is about to eat. Should the directions of edges incident on \(v\) be flipped? Or should \(v\) have lower priority than all its neighbors, i.e. all edges incident on \(v\) point towards \(v\)? What happens if we flip the directions of the edges incident on \(v\)? After the flip, the edges are directed from \(w\), \(x\) and \(y\) towards \(v\), and from \(v\) to \(u\). But now we have a cycle: \(y\) to \(v\) to \(u\) to \(w\) to \(y\). So, flipping edge directions doesn't work. What happens if agents adopt the good neighbor policy? The winner of a conflict gives itself lower priority than all the agents with which it competes. So, an agent that starts eating gives itself lower priority than all its neighbors. All edges point towards an eating agent. Fig.11: Winner gets lower priority than its neighbors When all edges incident on a vertex point towards the vertex then there is no cycle through that vertex. So, directing all edges incident on an eating vertex towards the eating vertex maintains acyclicity of the graph. For example, in the figure directing all edges incident on vertex \(v\) towards \(v\) ensures that no new cycle is created. Agent's priority does not decrease until the agent eats. How an Agent knows its Priority We assign an attribute clean / dirty to forks. A fork is either dirty or clean . The forks held by an eating agent are dirty . When an agent receives a fork from another agent, the receiving agent cleans the fork. So the receiver holds a clean fork, and the fork remains clean until an agent next eats with it. (This is the "hygenic solution:" Another - sad? - attempt at CS humor.) An agent holding a dirty fork knows that it has lower priority than the agent with which it shares the fork. Likewise, an agent holding a clean fork knows that it has higher priority than the agent with which it shares the fork. If an agent does not hold the fork that it shares with a neighbor then the agent does not know its priority with respect to that neighbor. Example of a Fork's Lifecycle The diagram below shows states of a fork shared by agents \(u\) and \(v\). The red arrow shows priority, and the black arrows show channels. The blue dot represents the fork. In the figure on the top left, agent \(u\) is hungry and holds a clean fork. So, \(u\) knows that it has priority over \(v\). At this point \(v\) does not know whether \(v\) has priority over \(u\) or not. The next figure, at the top right, shows that when \(u\) transits from hungry to eating, the fork becomes dirty, and \(u\) has lower priority than \(v\). Agent \(u\) continues to hold the fork while it eats. The next figure, bottom right, shows the situation after \(u\) gets a request for the fork from \(v\). Because \(u\) got the request from \(v\) and \(u\) hasn't sent the fork to \(v\), agent \(u\) knows that \(v\) is hungry. Since the fork is dirty, \(u\) sends the fork to \(v\). The figure shows the fork in the channel from \(u\) to \(v\). While the fork is in the channel it doesn't matter whether the fork is clean or dirty; however, merely for convenience, let's assume that \(u\), being hygenic, cleans the fork before sending it to its partner. While the fork is in a channel the priority doesn't change but neither \(u\) nor \(v\) knows what the priority is. The next figure, bottom left, shows the situation when \(v\) receives the fork.  Receiving the fork doesn't change the priority. At this point \(v\) is hungry and the fork is clean and so \(v\) knows that it has higher priority. \(v\) holds on to the fork until it next eats. Fig.12: How an Agent knows its Priority Algorithm Properties of Reachable States Here is a list of some of the properties of states in all trajectories. The priority graph is acyclic. \(u\) has priority over a neighbor \(v\) exactly when \(u\) holds the fork that it shares with \(v\) and the fork is clean, or the fork is in the channel from \(v\) to \(u\), or \(v\) holds the fork and the fork is dirty. Eating philosophers hold the forks for all edges incident on them, and these forks are dirty. All forks held by thinking philosphers are dirty. Thinking philosophers never send requests and never receive forks. Thinking philosophers respond to request for forks by sending the requested forks. Initial States Initially all philosophers are thinking; all forks are dirty; and all channels are empty. The forks are placed so that the priority graph is acyclic. The initial assignment of forks is as follows. Given an arbitrary acyclic graph, for any edge directed from \(v\) to \(w\), the fork shared by \(v\) and \(w\) is initially at \(w\) and the fork is dirty. Algorithm Commands The algorithm is specified by the following commands. When a thinking philosophers gets a request for a fork that it holds it sends the fork. (A fork held by a thinking philosopher is dirty.) When a thinking philosopher transits to hungry it sends requests for all forks that it does not hold. When a hungry philosopher receives a fork, it records the fork as being clean. If the hungry philosopher holds all its forks, and if it has no request for any dirty fork that it holds, then it transits to eating, and records all the forks that it holds in the eating state as dirty. When a hungry philosopher receives a request for a fork that it holds, it sends the fork if the fork is dirty, and holds on to the fork if it is clean. When an eating philosopher receives a request for a fork it registers the request in memory, and continues eating while holding the fork. When an eating philosopher transits to thinking it sends forks for all requests that it received. What could go wrong? The proof of safety is straightforward: Neighbors aren't eating because neighbors can't hold the same fork at the same time. Before we look at the proof of progress, let's see what may go wrong. Could a group of philosophers exchange forks with each other so that members of the group eat repeatedly, and starve a philosopher who is not in the group? For example, in the figure below, could philosophers \(u, v, w\) exchange forks so that they each eat in turn, and starve \(y\)? Fig.13: Potential Problems: What could go wrong? Could the system enter a deadlock state in which each hungry philosopher in a group holds only some --- but not all --- of the forks that it needs to eat, while other members of the group hold the remaining forks? Proof of Correctness The algorithm is correct. We are required to prove that every hungery philosopher eats eventually: \( \forall v: \quad v.h \leadsto v.e \) where for a philosopher \(v\), \(v.h\) holds exactly when \(v\) is hungry and \(v.e\) holds exactly when \(v\) is eating. Variant Function To prove this progress property we find a variant function that satisfies the following two conditions: Safety : The variant function does not increase while \(v\) remains hungry. progress : The following predicate does not hold forever: The variant function remains unchanged and \(v\) remains hungry. We propose a variant function which is a pair of integers \(nT, nH\),  which are the number of thinking and hungry philosophers, respectively, of higher priority than \(v\). In terms of the priority graph, \(nT, nH\) are the numbers of thinking and hungry philosophers (i.e. vertices) with paths to \(v\). Example of Variant Function The figure below shows a portion of the priority graph in a state of the system. The figure only shows philosophers with higher priority than philosopher \(v\), i.e., it only shows vertices in the graph with paths to \(v\). Since eating philosophers have lower priority than their neighbors, eating philosophers don't appear in this graph. A hungry philosopher is marked with an "H" and a thinking philosopher with a "T." In the diagram, philosophers \(v, w, x, y\) are hungry and \(u\) is thinking. Forks are located at philosophers and are shown as small colored circles. A dirty fork is colored red and clean one is blue. For example the fork shared by \(v\) and \(y\) is at \(y\) and is clean. Fig.15: A Variant Function: Numbers of higher priority thinking, hungry agents Example of Changes to Variant Function The next figure is an example of changes to the variant function. The diagram on the top left shows the higher priority vertices in the state of the previous figure. If agent \(x\) eats next the priority graph transits to the diagram on the top right, and the variant function \((nT, nH)\) changes from \((1, 3)\) to \((1, 2)\). Fig.16: Example of Values of the Variant Function If agent \(y\) eats next the priority graph transits to the diagram on the bottom right, and the variant function \((nT, nH)\) changes from \((1, 2)\) to \((1, 1)\).    If agent \(w\) eats next the priority graph transits to the diagram on the bottom left, and the variant function \((nT, nH)\) changes from \((1, 1)\) to \((0, 0)\). Proof that the variant function does not increase while \(v\) remains hungry If a philosopher of higher priority than \(v\) transits from thinking to hungry then \(nT\) decreases. Though \(nH\) increases, the variant function \((nT, nH)\) decreases because ordering of function values is done lexicographically. If a philosopher of higher priority than \(v\) transits from hungry to eating then \(nH\) decreases,  and so the variant function \((nT, nH)\) decreases. Proof that the following predicate does not hold forever: The variant function remains unchanged and \(v\) remains hungry. Let \(w\) be a highest-priority hungry philosopher, i.e. a philosopher with no hungry philosopher with priority higher than \(w\). (Note: \(w\) may be the same as \(v\).) All philosophers with priority higher than \(w\) are thinking. In the next paragraph we show that either \(w\) gets all its forks and then transits from hungry to eating, or the variant function decreases. From the algorithm, a hungry philosopher \(w\) requests forks from its neighbors. From the algorithm, \(w\) eventually gets forks from all its lower priority neighbors. A higher priority neighbor \(x\) of \(w\) is thinking. So when \(x\) gets a request for a fork from \(w\) either (1) \(x\) sends the requested fork to \(w\) or (2) \(x\) transits from thinking to hungry in which case the variant function \((nT, nH)\) decreases. Summary: Key Ideas of this Module This module introduced the problem of distributed mutual exclusion; showed how the good neighbor policy --- a winning agent reduces its priority to be lower than all the agents that it competes with -- solves this conflict resolution problem; introduced tokens and what agents know about other agents holding tokens; and showed a proof pattern that is one of the most common patterns for proving progress. Review What is the meaning of mutual exclusion among neighboring philosophers? An invariant of the algorithm is that each token is in exactly one place: an agent or a channel. How does this invariant help in designing the algorithm? An invariant of the algorithm is that the relative priorities among agents forms a partial order --- the priority graph is acyclic. What can go wrong if the priority graph has cycles? An agent that has a request for a fork releases the fork if the fork is dirty, and holds on to the fork if the fork is clean. What could go wrong if an agent releases a fork when it gets a request, regardless of whether the fork is clean or dirty? K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

--- Content from https://kmchandy.github.io/DistributedCollaboration/DrinkingPhilosophers/DrinkingPhilosophers.html ---
TITLE: DistributedCollaboration/DrinkingPhilosophers/DrinkingPhilosophers.html

DistributedCollaboration/DrinkingPhilosophers/DrinkingPhilosophers.html Distributed Algorithms Contents Index Mutual Exclusion: Distributed Dining Philosophers Distributed Resource Management: Drinking Philosophers Multi Agent Rendezvous: Committee Coordination. Work In Progress Resource Management: Drinking Philosophers This module describes algorithms for "The Distributed Drinking Philosophers Problem," by which distributed agents share indivisible resources, such as exclusive access to files. Key Ideas This module describes algorithms by which distributed agents share indivisible resources, such as exclusive access to files, in a fair way. The module shows how to use a total ordering of priorities to share resources fairly. The dining philosophers algorithm, given in an earlier module, uses a partial ordering. We show how time --- readings from local clocks of agents --- is used to obtain priorities that are totally ordered. The description of the algorithm in this module is not as detailed as that given for dining philosophers. You can define a formal specification and carry out a detailed proof for this algorithm in almost exactly the same was as for dining philosophers. The Problem A set of agents shares a set of indivisible resources. Exclusive access to a file is an example of an indivisible resource. The lifecycle of an agent is the same as in Dining Philosophers: (1) executing outside the critical section, (2) waiting to enter a critical section, and (3) executing in the critical section. The problem is identical to Dining Philosophers except for the transition to the critical section. An  agent executes outside the critical section without holding any resources. An agent may execute outside critical sections for ever, or it may start waiting to enter a critical section. When an agent starts waiting to enter a critical section it waits to get exclusive access to a nonempty subset of the resources. It continues waiting until it gets all the resources for which it waits. While it waits it does not change the subset of resources for which it waits. The agent continues to hold these resources when it executes in the critical section. An agent remains in a critical section for only a finite number of steps and then starts executing outside the critical section at which point it no longer needs resources. For example, an agent needs exclusive access to a set of files for it to execute in its next critical section, and it waits until it is given this access. While it is in the critical section it continues to have exclusive access to these files. When it is executing outside the critical section it does not need access to these files. Each time an agent starts to wait it may wait for a different set of files. Fig.1: Agent Lifecycle The ideas in this module can be used to manage agents that require read or write access to files. Multiple agents can have read access to a file concurrently. While an agent has write access to a file no other agent can have access to the file. A homework problem deals with read/write access. Drinking Philosophers The drinking philosophers name is another example of an attempt at CS humor. A philosopher is in one of three states: tranquil , thirsty or drinking . A philosopher may remain tranquil for ever, or it may become thirsty for one or more beverages. It remains thirsty until it gets all the beverages for which it waits. Only when a thirsty philosopher gets all the beverages for which it waits does it start drinking. It continues to drinking all these beverages until it becomes tranquil again. Philosophers drink for only finite time. A philosopher that enters the tranquil state remains in that state for at least a constant \(\gamma\) amount of time. So, a philosopher can't go from drinking to thirsty instantaneously or in an arbitrarily small amount of time. Fig.1: Drinking Philosophers A beverage can be held by at most one philosopher. Imagine there's only one bottle of each beverage in the system, and philosophers send bottles to each other. One philosopher can drink vodka and cola while another philosopher drinks gin and tonic. However, one agent cannot drink vodka and cola while another drinks vodka and orange juice. An Algorithm There are many algorithms for this problem; here we discuss one. Each beverage is an indivisible unique token. A token is exchanged between agents and a manager of the token. We assume that each token has its own manager --- this assumption is merely for convenience of exposition. Messages request : An agent sends a request for a beverage to a manager. A request is a pair \(agent\_id, request\_priority\), the id of the requestor and the priority of the request. beverage : A manager sends a beverage to a requesting agent, and agents send beverages back to managers. A beverage is uniquely identified by its name. demand : A manager sends a demand to an agent for the beverage that the manager manages and that the agent holds. Agent Actions When an agent becomes thirsty it sends requests to managers for all the beverages that it needs to drink. If a thirsty agent gets a demand to return a beverage to a manager then the agent returns the beverage and sends another request for the beverage. The priority of this new request is the same as the priority of this agent's last request. If a thirsty agent gets all the beverages that it needs to drink then it starts drinking. When an agent finishes drinking it returns all the beverages that it holds to the managers of the beverages. Manager Actions A manager has local variable \((hr, hp)\),  which is the id of the agent to which the manager has most recently sent the beverage, and the priority of the request made by that agent. \(hr\) is an acronym for h andling r equestor, and \(hp\) is an acronym for h andling p riority. If the manager holds the beverage then this variable is empty (\(Null\)). A manager also maintains a priority queue of pending requests ordered by priority. The actions of a manager are as follows. If a manager gets a request \((r, p)\) while it holds a beverage then it sends the beverage to the requestor \(r\), and sets \(hr, hp  = r, p\). If a manager gets a request \((r, p)\) while it does not hold the beverage and \(hp > p\) then the manager inserts the request \((r, p)\) into the priority queue of pending requests. If a manager gets a request \((r, p)\) while it does not hold the beverage and \(hp < p\) then: the manager sends a demand to \(hr\) to return the beverage, if the manager has not already sent that demand, and the manager inserts the request \((r, p)\) into its priority queue of pending requests. If a manager gets a beverage and it has no pending requests then the manager holds the beverage and sets the handling requestor and priority to empty. If a manager gets a beverage and it has pending requests then let \((r, p)\) be the request at the head of the priority queue (i.e. the request with the highest priority). It sends the beverage to requestor \(r\), removes \((r, p)\) from the queue of pending requests, and sets \(hr, hp  = r, p\). Example The example shows a scenario. The system has two agents, Maya and Liu both of whom are tranquil in the initial state. There are three beverages: Tea, coffee and milk. Initially, these beverages are with their managers. The next diagram, stage 1, shows the state after Maya gets thirsty for tea and milk. So she sends requests to the managers of tea and milk. The priority of this request is 2. (We will discuss how priorities are obtained later.) Fig.3: Stage 1 The next diagram, stage 2, shows the situation after the managers of tea and milk get requests from Maya, and respond by sending the beverages to Maya because there are no pending requests for these beverages. The beverages, tea and milk, are in the channel to Maya. Fig.4: Stage 2 The stage 3 diagram shows a state after Liu becomes thirsty for coffee and milk. So she sends requests for coffee and milk to the managers of these beverages. The priority of the request is 5. Maya has received the milk beverage but tea is still in the channel. So, Maya remains thirsty. Fig.5: Stage 3 The stage 4 diagram shows a state in which the coffee manager receives Liu's request and sends coffee to Liu because there are no pending requests for coffee. When the milk manager gets Liu's request, the manager puts the request on the priority queue of pending requests. At this point the queue has only Liu's request.    The milk manager demands milk back from Maya because her request has priority 2 whereas Liu's request has priority 5. Maya is still thirsty because the tea hasn't arrived yet. Fig.6: Stage 4 Next, Maya receives the demand for milk and responds by sending the milk back to the milk manager. Maya also resends its original request for milk, with priority 2, to the milk manager. Then Maya receives tea. Maya continues to be thirsty because she has only one of the two beverages that she needs to drink. Liu has coffee, but she remains thirsty because milk is in the channel from Maya to the milk manager. Fig.7: Stage 5 In stage 6, the milk manager has received Maya's request for milk with priority 2 and received milk. So, the milk manager sends the milk to respond to the highest priority request in the priority queue; this request is from Liu. The milk manager puts Maya's request into the queue of pending requests. Fig.8: Stage 6 In stage 7, Liu has received both milk and coffee, and so she is drinking. Maya is still thirsty, holding tea, while Maya's request for milk is in the queue of pending requests for milk. Fig.9: Stage 7 How Priorities Change If priorities don't change then the agents with high priorities may continue to go rapidly through the tranquil, thirsty, drinking cycle while other agents remain thirsty for ever. One way to assign priorities is as follows. Associated with each request is a timestamp which is the time read from the requestor's local clock at the instant at which the request is made. A request's timestamp does not change after the request is created. A request's priority is a pair (timestamp, requestor's id), with priorities compared lexicographically, and lower values having higher priority. So, requests made earlier have higher priority than requests made later. The requestor's id is used to break ties. What are the requirement's of agents' local clocks that ensure that all thirsty philosophers drink eventually? A Minimum Requirement on Clocks An agent's clock must tick forward between successive requests by the agent. If the agent's clock remained stuck at the same value for ever then the agent using that clock may get the highest priority for ever, and go through tranquil, thirsty, drinking cycles infinitely which makes other agents remain tranquil for ever. Assume that each clock reading is an integer: for example, the number of picoseconds since January 1, 1900. (NTP units are \(2^{-32}\) of a second.) The clock ticks forward between successive requests by the same philosopher because the philosopher remains in tranquil state for at least \(\gamma\) units of time where \(\gamma\) is a positive constant. Treat each agent's clock tick as an event. Local clocks of agents may drift apart, but let's assume that the magnitude of the difference between clock readings of different agents is bounded. Even if the philosopher makes a new request when its clock ticks forward by one unit, eventually the timestamp of a request from that philosopher will exceed \(T\) for any value of \(T\). This ensures that while a philosopher is thirsty, another philosopher cannot overtake it for ever. Proof of Correctness The proof of safety --- multiple philosophers don't hold the same beverage at the same time --- is straightforward. It follows because a token is at exactly one agent or in exactly one channel. Let's prove that a thirsty philosopher \(v\) with a request with timestamp \(T\) drinks eventually. Let \(t[i]\) be the reading of philosopher \(i\)'s clock. Each agent's clock reading eventually exceeds \(T\) We observe that each agent's clock ticks forward: \( \forall i, \tau: (t[i] = \tau) \leadsto (t[i] \geq \tau + 1) \) Therefore, each \(i\)'s clock eventually reads a value greater than \(T\), using transitivity of \(\leadsto\). \( \forall i, \tau: (t[i] = \tau) \leadsto (t[i] > T) \) From the previous formula, and taking disjunction over all values of \(\tau\): \( \forall i:  \quad true \leadsto (t[i] > T) \) Because clock readings never go back in time, \(t[i] > T\) is stable, and therefore: \( \forall i:  \quad true \leadsto always(t[i] > T) \) Let \(Q\) be the predicate that all clocks read values that exceed \(T\): \(Q = \forall i: t[i] > T\). From the above formula and because \(X \leadsto always(Y)\) and \(X \leadsto always(Y')\) allows us to deduce \(X \leadsto always(Y \vee Y')\) \( true \leadsto always(Q) \) The number of pending requests with timestamps less than \(T\) decreases From the above formula: \( v.thirsty \; \leadsto \; (v.drinking \wedge Q) \vee (v.thirsty \wedge Q) \) Next we will prove that if \(v\) is thirsty and all clocks read values that exceed \(T\), then \(v\) will drink eventually: \( (v.thirsty \wedge Q) \leadsto v.drinking \) Let \(req\) be the number of pending requests with timestamps less than \(T\). We will prove \( (v.thirsty \wedge Q \wedge (req = k) \; \leadsto \; v.drinking \vee (v.thirsty \wedge Q \wedge (req < k)) \) This proof is straightforward: The request with the lowest timestamp gets all the resources it needs. \( (v.thirsty \wedge Q \wedge (req = 0) \; \leadsto \; v.drinking \) The result follows using the rules for variant functions. Review In the algorithm, each manager of a resource maintains a priority queue of requests for the resource. Is the algorithm correct if managers maintain first-come-first-served queues rather than priority queues? Show that the proposed variant function is correct: show that it does not increase while an agent remains thirsty, and show that it decreases eventually. K. Mani Chandy, Emeritus Simon Ramo Professor, California Institute of Technology

